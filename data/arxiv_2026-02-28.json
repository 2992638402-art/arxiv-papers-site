{
  "date": "2026-02-28",
  "total": 171,
  "papers": [
    {
      "id": "2602.23360v1",
      "title": "Model Agreement via Anchoring",
      "summary": "Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies. We develop a simple general technique for proving bounds on independent model disagreement based on $\\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss.",
      "authors": [
        "Eric Eaton",
        "Surbhi Goel",
        "Marcel Hussing",
        "Michael Kearns",
        "Aaron Roth",
        "Sikata Bela Sengupta",
        "Jessica Sorrell"
      ],
      "published": "2026-02-26T18:59:32Z",
      "updated": "2026-02-26T18:59:32Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23360v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23359v1",
      "title": "SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation",
      "summary": "We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.",
      "authors": [
        "Vaibhav Agrawal",
        "Rishubh Parihar",
        "Pradhaan Bhat",
        "Ravi Kiran Sarvadevabhatla",
        "R. Venkatesh Babu"
      ],
      "published": "2026-02-26T18:59:05Z",
      "updated": "2026-02-26T18:59:05Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23359v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23353v1",
      "title": "SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport",
      "summary": "The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.",
      "authors": [
        "Simon Roschmann",
        "Paul Krzakala",
        "Sonia Mazelet",
        "Quentin Bouniot",
        "Zeynep Akata"
      ],
      "published": "2026-02-26T18:55:06Z",
      "updated": "2026-02-26T18:55:06Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23353v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23349v1",
      "title": "FlashOptim: Optimizers for Memory Efficient Training",
      "summary": "Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory. We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half. Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.",
      "authors": [
        "Jose Javier Gonzalez Ortiz",
        "Abhay Gupta",
        "Chris Renard",
        "Davis Blalock"
      ],
      "published": "2026-02-26T18:52:22Z",
      "updated": "2026-02-26T18:52:22Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23349v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23335v1",
      "title": "Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset",
      "summary": "AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation.",
      "authors": [
        "Dany Haddad",
        "Dan Bareket",
        "Joseph Chee Chang",
        "Jay DeYoung",
        "Jena D. Hwang",
        "Uri Katz",
        "Mark Polak",
        "Sangho Suh",
        "Harshit Surana",
        "Aryeh Tiktinsky",
        "Shriya Atmakuri",
        "Jonathan Bragg",
        "Mike D'Arcy",
        "Sergey Feldman",
        "Amal Hassan-Ali",
        "Rubén Lozano",
        "Bodhisattwa Prasad Majumder",
        "Charles McGrady",
        "Amanpreet Singh",
        "Brooke Vlahos",
        "Yoav Goldberg",
        "Doug Downey"
      ],
      "published": "2026-02-26T18:40:28Z",
      "updated": "2026-02-26T18:40:28Z",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23335v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23334v1",
      "title": "Bitwise Systolic Array Architecture for Runtime-Reconfigurable Multi-precision Quantized Multiplication on Hardware Accelerators",
      "summary": "Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc. Previous works have explored the quantization technologies in related lightweight accelerator designs to reduce hardware resource consumption. However, low precision leads to high accuracy loss in inference. Therefore, mixed-precision quantization becomes an alternative solution by applying different precision in different layers to trade off resource consumption and accuracy. Because regular designs for multiplication on hardware cannot support the precision reconfiguration for a multi-precision Quantized Neural Network (QNN) model in runtime, we propose a runtime reconfigurable multi-precision multi-channel bitwise systolic array design for QNN accelerators. We have implemented and evaluated our work on the Ultra96 FPGA platform. Results show that our work can achieve 1.3185 to 3.5671 times speedup in inferring mixed-precision models and has less critical path delay, supporting a higher clock frequency (250MHz).",
      "authors": [
        "Yuhao Liu",
        "Salim Ullah",
        "Akash Kumar"
      ],
      "published": "2026-02-26T18:40:02Z",
      "updated": "2026-02-26T18:40:02Z",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23334v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23331v1",
      "title": "Utilizing LLMs for Industrial Process Automation",
      "summary": "A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.",
      "authors": [
        "Salim Fares"
      ],
      "published": "2026-02-26T18:38:00Z",
      "updated": "2026-02-26T18:38:00Z",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23331v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23330v1",
      "title": "Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks",
      "summary": "The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings.",
      "authors": [
        "Kunihiro Miyazaki",
        "Takanobu Kawahara",
        "Stephen Roberts",
        "Stefan Zohren"
      ],
      "published": "2026-02-26T18:37:36Z",
      "updated": "2026-02-26T18:37:36Z",
      "categories": [
        "cs.AI",
        "q-fin.TR"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23330v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23329v1",
      "title": "LLM Novice Uplift on Dual-Use, In Silico Biology Tasks",
      "summary": "Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.",
      "authors": [
        "Chen Bo Calvin Zhang",
        "Christina Q. Knight",
        "Nicholas Kruus",
        "Jason Hausenloy",
        "Pedro Medeiros",
        "Nathaniel Li",
        "Aiden Kim",
        "Yury Orlovskiy",
        "Coleman Breen",
        "Bryce Cai",
        "Jasper Götting",
        "Andrew Bo Liu",
        "Samira Nedungadi",
        "Paula Rodriguez",
        "Yannis Yiming He",
        "Mohamed Shaaban",
        "Zifan Wang",
        "Seth Donoughe",
        "Julian Michael"
      ],
      "published": "2026-02-26T18:37:23Z",
      "updated": "2026-02-26T18:37:23Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CY",
        "cs.HC"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23329v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23318v1",
      "title": "Generalized Rapid Action Value Estimation in Memory-Constrained Environments",
      "summary": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.",
      "authors": [
        "Aloïs Rautureau",
        "Tristan Cazenave",
        "Éric Piette"
      ],
      "published": "2026-02-26T18:25:59Z",
      "updated": "2026-02-26T18:25:59Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23318v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23315v1",
      "title": "Invariant Transformation and Resampling based Epistemic-Uncertainty Reduction",
      "summary": "An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces. Once designed and well trained, the AI model is applied for inference. However, even optimized AI models can produce inference errors due to aleatoric and epistemic uncertainties. Interestingly, we observed that when inferring multiple samples based on invariant transformations of an input, inference errors can show partial independences due to epistemic uncertainty. Leveraging this insight, we propose a \"resampling\" based inferencing that applies to a trained AI model with multiple transformed versions of an input, and aggregates inference outputs to a more accurate result. This approach has the potential to improve inference accuracy and offers a strategy for balancing model size and performance.",
      "authors": [
        "Sha Hu"
      ],
      "published": "2026-02-26T18:22:40Z",
      "updated": "2026-02-26T18:22:40Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23315v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23312v1",
      "title": "Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction",
      "summary": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.",
      "authors": [
        "Rafael R. Baptista",
        "André de Lima Salgado",
        "Ricardo V. Godoy",
        "Marcelo Becker",
        "Thiago Boaventura",
        "Gustavo J. G. Lahr"
      ],
      "published": "2026-02-26T18:20:26Z",
      "updated": "2026-02-26T18:20:26Z",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.SY"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23312v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23302v1",
      "title": "The logic of KM belief update is contained in the logic of AGM belief revision",
      "summary": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $&gt;$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a single axiom, which deals exclusively with unsurprising information, that is, with formulas that were not initially disbelieved.",
      "authors": [
        "Giacomo Bonanno"
      ],
      "published": "2026-02-26T18:09:02Z",
      "updated": "2026-02-26T18:09:02Z",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23302v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23296v1",
      "title": "Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity",
      "summary": "Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.",
      "authors": [
        "Quang-Huy Nguyen",
        "Jiaqi Wang",
        "Wei-Shinn Ku"
      ],
      "published": "2026-02-26T18:07:45Z",
      "updated": "2026-02-26T18:07:45Z",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23296v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23286v1",
      "title": "SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables",
      "summary": "Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.",
      "authors": [
        "Sungho Park",
        "Jueun Kim",
        "Wook-Shin Han"
      ],
      "published": "2026-02-26T17:59:51Z",
      "updated": "2026-02-26T17:59:51Z",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23286v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23285v1",
      "title": "ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks",
      "summary": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.",
      "authors": [
        "Haohui Jia",
        "Zheng Chen",
        "Lingwei Zhu",
        "Rikuto Kotoge",
        "Jathurshan Pradeepkumar",
        "Yasuko Matsubara",
        "Jimeng Sun",
        "Yasushi Sakurai",
        "Takashi Matsubara"
      ],
      "published": "2026-02-26T17:59:10Z",
      "updated": "2026-02-26T17:59:10Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23285v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23276v1",
      "title": "CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays",
      "summary": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.",
      "authors": [
        "Hyungyung Lee",
        "Hangyul Yoon",
        "Edward Choi"
      ],
      "published": "2026-02-26T17:51:21Z",
      "updated": "2026-02-26T17:51:21Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23276v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23271v1",
      "title": "Evaluating Stochasticity in Deep Research Agents",
      "summary": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.",
      "authors": [
        "Haotian Zhai",
        "Elias Stengel-Eskin",
        "Pratik Patil",
        "Liu Leqi"
      ],
      "published": "2026-02-26T17:46:42Z",
      "updated": "2026-02-26T17:46:42Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23271v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23259v1",
      "title": "Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving",
      "summary": "With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.",
      "authors": [
        "Jiangxin Sun",
        "Feng Xue",
        "Teng Long",
        "Chang Liu",
        "Jian-Fang Hu",
        "Wei-Shi Zheng",
        "Nicu Sebe"
      ],
      "published": "2026-02-26T17:32:30Z",
      "updated": "2026-02-26T17:32:30Z",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23259v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23258v1",
      "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
      "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.",
      "authors": [
        "Yutong Wang",
        "Siyuan Xiong",
        "Xuebo Liu",
        "Wenkang Zhou",
        "Liang Ding",
        "Miao Zhang",
        "Min Zhang"
      ],
      "published": "2026-02-26T17:31:43Z",
      "updated": "2026-02-26T17:31:43Z",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23258v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23248v1",
      "title": "Mitigating Legibility Tax with Decoupled Prover-Verifier Games",
      "summary": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.",
      "authors": [
        "Yegon Kim",
        "Juho Lee"
      ],
      "published": "2026-02-26T17:25:22Z",
      "updated": "2026-02-26T17:25:22Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23248v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23242v1",
      "title": "A Model-Free Universal AI",
      "summary": "In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models. This paper introduces Universal AI with Q-Induction (AIQI), the first model-free agent proven to be asymptotically $\\varepsilon$-optimal in general RL. AIQI performs universal induction over distributional action-value functions, instead of policies or environments like previous works. Under a grain of truth condition, we prove that AIQI is strong asymptotically $\\varepsilon$-optimal and asymptotically $\\varepsilon$-Bayes-optimal. Our results significantly expand the diversity of known universal agents.",
      "authors": [
        "Yegon Kim",
        "Juho Lee"
      ],
      "published": "2026-02-26T17:21:16Z",
      "updated": "2026-02-26T17:21:16Z",
      "categories": [
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23242v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23239v1",
      "title": "Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive",
      "summary": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains. RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations. Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument.",
      "authors": [
        "Radha Sarma"
      ],
      "published": "2026-02-26T17:16:17Z",
      "updated": "2026-02-26T17:16:17Z",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23239v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23235v1",
      "title": "Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents",
      "summary": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.",
      "authors": [
        "Zhou Xu",
        "Bowen Zhou",
        "Qi Wang",
        "Shuwen Feng",
        "Jingyu Xiao"
      ],
      "published": "2026-02-26T17:12:40Z",
      "updated": "2026-02-26T17:12:40Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23235v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23234v1",
      "title": "Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments",
      "summary": "Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels.",
      "authors": [
        "Evangelia Christakopoulou",
        "Vivekkumar Patel",
        "Hemanth Velaga",
        "Sandip Gaikwad"
      ],
      "published": "2026-02-26T17:11:26Z",
      "updated": "2026-02-26T17:11:26Z",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23234v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23358v1",
      "title": "A Dataset is Worth 1 MB",
      "summary": "A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstrate that our approach can transfer task knowledge with a payload of less than 1 MB while retaining high classification accuracy, offering a promising solution for efficient dataset serving.",
      "authors": [
        "Elad Kimchi Shoshani",
        "Leeyam Gabay",
        "Yedid Hoshen"
      ],
      "published": "2026-02-26T18:59:03Z",
      "updated": "2026-02-26T18:59:03Z",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23358v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23341v1",
      "title": "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms",
      "summary": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...]",
      "authors": [
        "Alkis Kalavasis",
        "Anay Mehrotra",
        "Manolis Zampetakis",
        "Felix Zhou",
        "Ziyu Zhu"
      ],
      "published": "2026-02-26T18:47:06Z",
      "updated": "2026-02-26T18:47:06Z",
      "categories": [
        "cs.LG",
        "cs.DS",
        "math.ST",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23341v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23336v1",
      "title": "Differentiable Zero-One Loss via Hypersimplex Projections",
      "summary": "Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.",
      "authors": [
        "Camilo Gomez",
        "Pengyang Wang",
        "Liansheng Tang"
      ],
      "published": "2026-02-26T18:41:31Z",
      "updated": "2026-02-26T18:41:31Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23336v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23321v1",
      "title": "Deep ensemble graph neural networks for probabilistic cosmic-ray direction and energy reconstruction in autonomous radio arrays",
      "summary": "Using advanced machine learning techniques, we developed a method for reconstructing precisely the arrival direction and energy of ultra-high-energy cosmic rays from the voltage traces they induced on ground-based radio detector arrays. In our approach, triggered antennas are represented as a graph structure, which serves as input for a graph neural network (GNN). By incorporating physical knowledge into both the GNN architecture and the input data, we improve the precision and reduce the required size of the training set with respect to a fully data-driven approach. This method achieves an angular resolution of 0.092° and an electromagnetic energy reconstruction resolution of 16.4% on simulated data with realistic noise conditions. We also employ uncertainty estimation methods to enhance the reliability of our predictions, quantifying the confidence of the GNN's outputs and providing confidence intervals for both direction and energy reconstruction. Finally, we investigate strategies to verify the model's consistency and robustness under real life variations, with the goal of identifying scenarios in which predictions remain reliable despite domain shifts between simulation and reality.",
      "authors": [
        "Arsène Ferrière",
        "Aurélien Benoit-Lévy",
        "Olivier Martineau-Huynh",
        "Matías Tueros"
      ],
      "published": "2026-02-26T18:29:48Z",
      "updated": "2026-02-26T18:29:48Z",
      "categories": [
        "astro-ph.IM",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23321v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23320v1",
      "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
      "summary": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents.",
      "authors": [
        "Tianjun Yao",
        "Yongqiang Chen",
        "Yujia Zheng",
        "Pan Li",
        "Zhiqiang Shen",
        "Kun Zhang"
      ],
      "published": "2026-02-26T18:28:04Z",
      "updated": "2026-02-26T18:28:04Z",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23320v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23305v1",
      "title": "A Proper Scoring Rule for Virtual Staining",
      "summary": "Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot.",
      "authors": [
        "Samuel Tonks",
        "Steve Hood",
        "Ryan Musso",
        "Ceridwen Hopely",
        "Steve Titus",
        "Minh Doan",
        "Iain Styles",
        "Alexander Krull"
      ],
      "published": "2026-02-26T18:09:49Z",
      "updated": "2026-02-26T18:09:49Z",
      "categories": [
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23305v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23303v1",
      "title": "Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications",
      "summary": "Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores the union of chemical theory, biological theory, probability theory and causality that will correct current causal flaws of machine learning in the natural sciences. This paper, Part 1 of the series, provides the formal framework of the foundational causal structure of phenomena in chemical biology and is extended to machine learning through the novel concept of focus, defined here as the ability of a machine learning algorithm to narrow down to a hidden underpinning mechanism in large data sets. Initial proof of these principles on a family of Akt inhibitors is also provided. The second paper containing Part 2 will provide a formal exploration of chemical similarity, and Part 3 will present extensive experimental evidence of how hidden causal structures weaken all machine learning in chemical biology. This series serves to establish for chemical biology a new kind of mathematical framework for modeling mechanisms in Nature without the need for the tools of reductionism: inferential mechanics.",
      "authors": [
        "Ilya Balabin",
        "Thomas M. Kaiser"
      ],
      "published": "2026-02-26T18:09:16Z",
      "updated": "2026-02-26T18:09:16Z",
      "categories": [
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23303v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23295v1",
      "title": "ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation",
      "summary": "In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework.",
      "authors": [
        "Ayush Roy",
        "Wei-Yang Alex Lee",
        "Rudrasis Chakraborty",
        "Vishnu Suresh Lokhande"
      ],
      "published": "2026-02-26T18:07:10Z",
      "updated": "2026-02-26T18:07:10Z",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23295v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23280v1",
      "title": "Physics Informed Viscous Value Representations",
      "summary": "Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.",
      "authors": [
        "Hrishikesh Viswanath",
        "Juanwu Lu",
        "S. Talha Bukhari",
        "Damon Conover",
        "Ziran Wang",
        "Aniket Bera"
      ],
      "published": "2026-02-26T17:53:46Z",
      "updated": "2026-02-26T17:53:46Z",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23280v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23277v1",
      "title": "Zeroth-Order Stackelberg Control in Combinatorial Congestion Games",
      "summary": "We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other combinatorial strategies) and settle at a congestion equilibrium. The leader minimizes a system-level objective (e.g., total travel time) evaluated at equilibrium, but this objective is typically nonsmooth because the set of used strategies can change abruptly. We propose ZO-Stackelberg, which couples a projection-free Frank--Wolfe equilibrium solver with a zeroth-order outer update, avoiding differentiation through equilibria. We prove convergence to generalized Goldstein stationary points of the true equilibrium objective, with explicit dependence on the equilibrium approximation error, and analyze subsampled oracles: if an exact minimizer is sampled with probability $κ_m$, then the Frank--Wolfe error decays as $\\mathcal{O}(1/(κ_m T))$. We also propose stratified sampling as a practical way to avoid a vanishing $κ_m$ when the strategies that matter most for the Wardrop equilibrium concentrate in a few dominant combinatorial classes (e.g., short paths). Experiments on real-world networks demonstrate that our method achieves orders-of-magnitude speedups over a differentiation-based baseline while converging to follower equilibria.",
      "authors": [
        "Saeed Masiha",
        "Sepehr Elahi",
        "Negar Kiyavash",
        "Patrick Thiran"
      ],
      "published": "2026-02-26T17:52:08Z",
      "updated": "2026-02-26T17:52:08Z",
      "categories": [
        "cs.GT",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23277v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23219v1",
      "title": "Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime",
      "summary": "Generalization measures have been studied extensively in the machine learning community to better characterize generalization gaps. However, establishing a reliable generalization measure for statistically singular models such as deep neural networks (DNNs) is difficult due to their complex nature. This study focuses on Takeuchi's information criterion (TIC) to investigate the conditions under which this classical measure can effectively explain the generalization gaps of DNNs. Importantly, the developed theory indicates the applicability of TIC near the neural tangent kernel (NTK) regime. In a series of experiments, we trained more than 5,000 DNN models with 12 architectures, including large models (e.g., VGG-16), on four datasets, and estimated the corresponding TIC values to examine the relationship between the generalization gap and the TIC estimates. We applied several TIC approximation methods with feasible computational costs and assessed the accuracy trade-off. Our experimental results indicate that the estimated TIC values correlate well with the generalization gap under conditions close to the NTK regime. However, we show both theoretically and empirically that outside the NTK regime such correlation disappears. Finally, we demonstrate that TIC provides better trial pruning ability than existing methods for hyperparameter optimization.",
      "authors": [
        "Hiroki Naganuma",
        "Taiji Suzuki",
        "Rio Yokota",
        "Masahiro Nomura",
        "Kohta Ishikawa",
        "Ikuro Sato"
      ],
      "published": "2026-02-26T17:01:14Z",
      "updated": "2026-02-26T17:01:14Z",
      "categories": [
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23219v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23214v1",
      "title": "Plug-and-Play Diffusion Meets ADMM: Dual-Variable Coupling for Robust Medical Image Reconstruction",
      "summary": "Plug-and-Play diffusion prior (PnPDP) frameworks have emerged as a powerful paradigm for solving imaging inverse problems by treating pretrained generative models as modular priors. However, we identify a critical flaw in prevailing PnP solvers (e.g., based on HQS or Proximal Gradient): they function as memoryless operators, updating estimates solely based on instantaneous gradients. This lack of historical tracking inevitably leads to non-vanishing steady-state bias, where the reconstruction fails to strictly satisfy physical measurements under heavy corruption. To resolve this, we propose Dual-Coupled PnP Diffusion, which restores the classical dual variable to provide integral feedback, theoretically guaranteeing asymptotic convergence to the exact data manifold. However, this rigorous geometric coupling introduces a secondary challenge: the accumulated dual residuals exhibit spectrally colored, structured artifacts that violate the Additive White Gaussian Noise (AWGN) assumption of diffusion priors, causing severe hallucinations. To bridge this gap, we introduce Spectral Homogenization (SH), a frequency-domain adaptation mechanism that modulates these structured residuals into statistically compliant pseudo-AWGN inputs. This effectively aligns the solver's rigorous optimization trajectory with the denoiser's valid statistical manifold. Extensive experiments on CT and MRI reconstruction demonstrate that our approach resolves the bias-hallucination trade-off, achieving state-of-the-art fidelity with significantly accelerated convergence.",
      "authors": [
        "Chenhe Du",
        "Xuanyu Tian",
        "Qing Wu",
        "Muyu Liu",
        "Jingyi Yu",
        "Hongjiang Wei",
        "Yuyao Zhang"
      ],
      "published": "2026-02-26T16:58:43Z",
      "updated": "2026-02-26T16:58:43Z",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23214v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23201v1",
      "title": "Tell Me What To Learn: Generalizing Neural Memory to be Controllable in Natural Language",
      "summary": "Modern machine learning models are deployed in diverse, non-stationary environments where they must continually adapt to new tasks and evolving knowledge. Continual fine-tuning and in-context learning are costly and brittle, whereas neural memory methods promise lightweight updates with minimal forgetting. However, existing neural memory models typically assume a single fixed objective and homogeneous information streams, leaving users with no control over what the model remembers or ignores over time. To address this challenge, we propose a generalized neural memory system that performs flexible updates based on learning instructions specified in natural language. Our approach enables adaptive agents to learn selectively from heterogeneous information sources, supporting settings, such as healthcare and customer service, where fixed-objective memory updates are insufficient.",
      "authors": [
        "Max S. Bennett",
        "Thomas P. Zollo",
        "Richard Zemel"
      ],
      "published": "2026-02-26T16:50:52Z",
      "updated": "2026-02-26T16:50:52Z",
      "categories": [
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23201v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23200v1",
      "title": "InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models",
      "summary": "Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\\%$ speedup over previous work and up to $88\\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both the most recent tokens and the attention sink tokens to mitigate outlier leakage; and (iii) per-channel normalization of the key cache, computed once during prefill and folded into the query to avoid runtime overhead. Our evaluation experiments on Llama models shows that InnerQ maintains a few-shot GSM8K performance comparable to non-quantized KV caches and surpasses prior KV cache quantization methods.",
      "authors": [
        "Sayed Mohammadreza Tayaranian Hosseini",
        "Amir Ardakani",
        "Warren J. Gross"
      ],
      "published": "2026-02-26T16:50:36Z",
      "updated": "2026-02-26T16:50:36Z",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23200v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23197v1",
      "title": "Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models",
      "summary": "Transformer-based large language models exhibit in-context learning, enabling adaptation to downstream tasks via few-shot prompting with demonstrations. In practice, such models are often fine-tuned to improve zero-shot performance on downstream tasks, allowing them to solve tasks without examples and thereby reducing inference costs. However, fine-tuning can degrade in-context learning, limiting the performance of fine-tuned models on tasks not seen during fine-tuning. Using linear attention models, we provide a theoretical analysis that characterizes how fine-tuning objectives modify attention parameters and identifies conditions under which this leads to degraded few-shot performance. We show that fine-tuning all attention parameters can harm in-context learning, whereas restricting updates to the value matrix improves zero-shot performance while preserving in-context learning. We further show that incorporating an auxiliary few-shot loss enhances in-context learning primarily on the target task, at the expense of degraded in-context learning ability on tasks not seen during fine-tuning. We empirically validate our theoretical results.",
      "authors": [
        "Chungpa Lee",
        "Jy-yong Sohn",
        "Kangwook Lee"
      ],
      "published": "2026-02-26T16:49:15Z",
      "updated": "2026-02-26T16:49:15Z",
      "categories": [
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23197v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23192v1",
      "title": "FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification",
      "summary": "Compressing neural networks by quantizing model parameters offers useful trade-off between performance and efficiency. Methods like quantization-aware training and post-training quantization strive to maintain the downstream performance of compressed models compared to the full precision models. However, these techniques do not explicitly consider the impact on algorithmic fairness. In this work, we study fairness-aware mixed-precision quantization schemes for medical image classification under explicit bit budgets. We introduce FairQuant, a framework that combines group-aware importance analysis, budgeted mixed-precision allocation, and a learnable Bit-Aware Quantization (BAQ) mode that jointly optimizes weights and per-unit bit allocations under bitrate and fairness regularization. We evaluate the method on Fitzpatrick17k and ISIC2019 across ResNet18/50, DeiT-Tiny, and TinyViT. Results show that FairQuant configurations with average precision near 4-6 bits recover much of the Uniform 8-bit accuracy while improving worst-group performance relative to Uniform 4- and 8-bit baselines, with comparable fairness metrics under shared budgets.",
      "authors": [
        "Thomas Woergaard",
        "Raghavendra Selvan"
      ],
      "published": "2026-02-26T16:44:47Z",
      "updated": "2026-02-26T16:44:47Z",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23192v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23188v1",
      "title": "Efficient Real-Time Adaptation of ROMs for Unsteady Flows Using Data Assimilation",
      "summary": "We propose an efficient retraining strategy for a parameterized Reduced Order Model (ROM) that attains accuracy comparable to full retraining while requiring only a fraction of the computational time and relying solely on sparse observations of the full system. The architecture employs an encode-process-decode structure: a Variational Autoencoder (VAE) to perform dimensionality reduction, and a transformer network to evolve the latent states and model the dynamics. The ROM is parameterized by an external control variable, the Reynolds number in the Navier-Stokes setting, with the transformer exploiting attention mechanisms to capture both temporal dependencies and parameter effects. The probabilistic VAE enables stochastic sampling of trajectory ensembles, providing predictive means and uncertainty quantification through the first two moments. After initial training on a limited set of dynamical regimes, the model is adapted to out-of-sample parameter regions using only sparse data. Its probabilistic formulation naturally supports ensemble generation, which we employ within an ensemble Kalman filtering framework to assimilate data and reconstruct full-state trajectories from minimal observations. We further show that, for the dynamical system considered, the dominant source of error in out-of-sample forecasts stems from distortions of the latent manifold rather than changes in the latent dynamics. Consequently, retraining can be limited to the autoencoder, allowing for a lightweight, computationally efficient, real-time adaptation procedure with very sparse fine-tuning data.",
      "authors": [
        "Ismaël Zighed",
        "Andrea Nóvoa",
        "Luca Magri",
        "Taraneh Sayadi"
      ],
      "published": "2026-02-26T16:43:28Z",
      "updated": "2026-02-26T16:43:28Z",
      "categories": [
        "cs.LG",
        "physics.flu-dyn"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23188v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23182v1",
      "title": "Closing the gap on tabular data with Fourier and Implicit Categorical Features",
      "summary": "While Deep Learning has demonstrated impressive results in applications on various data types, it continues to lag behind tree-based methods when applied to tabular data, often referred to as the last \"unconquered castle\" for neural networks. We hypothesize that a significant advantage of tree-based methods lies in their intrinsic capability to model and exploit non-linear interactions induced by features with categorical characteristics. In contrast, neural-based methods exhibit biases toward uniform numerical processing of features and smooth solutions, making it challenging for them to effectively leverage such patterns. We address this performance gap by using statistical-based feature processing techniques to identify features that are strongly correlated with the target once discretized. We further mitigate the bias of deep models for overly-smooth solutions, a bias that does not align with the inherent properties of the data, using Learned Fourier. We show that our proposed feature preprocessing significantly boosts the performance of deep learning models and enables them to achieve a performance that closely matches or surpasses XGBoost on a comprehensive tabular data benchmark.",
      "authors": [
        "Marius Dragoi",
        "Florin Gogianu",
        "Elena Burceanu"
      ],
      "published": "2026-02-26T16:40:23Z",
      "updated": "2026-02-26T16:40:23Z",
      "categories": [
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23182v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23179v1",
      "title": "Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models",
      "summary": "Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.",
      "authors": [
        "Gal Kesten-Pomeranz",
        "Yaniv Nikankin",
        "Anja Reusch",
        "Tomer Tsaban",
        "Ora Schueler-Furman",
        "Yonatan Belinkov"
      ],
      "published": "2026-02-26T16:39:04Z",
      "updated": "2026-02-26T16:39:04Z",
      "categories": [
        "cs.LG",
        "q-bio.BM"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23179v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23351v1",
      "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
      "summary": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.",
      "authors": [
        "Amita Kamath",
        "Jack Hessel",
        "Khyathi Chandu",
        "Jena D. Hwang",
        "Kai-Wei Chang",
        "Ranjay Krishna"
      ],
      "published": "2026-02-26T18:54:06Z",
      "updated": "2026-02-26T18:54:06Z",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23351v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23300v1",
      "title": "A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations",
      "summary": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.",
      "authors": [
        "Soumya Dutta",
        "Smruthi Balaji",
        "Sriram Ganapathy"
      ],
      "published": "2026-02-26T18:08:40Z",
      "updated": "2026-02-26T18:08:40Z",
      "categories": [
        "cs.CL",
        "eess.AS"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23300v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23266v1",
      "title": "Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems",
      "summary": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction.",
      "authors": [
        "Siyuan Liu",
        "Jiahui Xu",
        "Feng Jiang",
        "Kuang Wang",
        "Zefeng Zhao",
        "Chu-Ren Huang",
        "Jinghang Gu",
        "Changqing Yin",
        "Haizhou Li"
      ],
      "published": "2026-02-26T17:39:56Z",
      "updated": "2026-02-26T17:39:56Z",
      "categories": [
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23266v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23225v1",
      "title": "Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?",
      "summary": "Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at https://github.com/pixeli99/NAP.",
      "authors": [
        "Pengxiang Li",
        "Dilxat Muhtar",
        "Lu Yin",
        "Tianlong Chen",
        "Shiwei Liu"
      ],
      "published": "2026-02-26T17:04:57Z",
      "updated": "2026-02-26T17:04:57Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23225v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23184v1",
      "title": "MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations",
      "summary": "We present MTRAG-UN, a benchmark for exploring open challenges in multi-turn retrieval augmented generation, a popular use of large language models. We release a benchmark of 666 tasks containing over 2,800 conversation turns across 6 domains with accompanying corpora. Our experiments show that retrieval and generation models continue to struggle on conversations with UNanswerable, UNderspecified, and NONstandalone questions and UNclear responses. Our benchmark is available at https://github.com/IBM/mt-rag-benchmark",
      "authors": [
        "Sara Rosenthal",
        "Yannis Katsis",
        "Vraj Shah",
        "Lihong He",
        "Lucian Popa",
        "Marina Danilevsky"
      ],
      "published": "2026-02-26T16:41:17Z",
      "updated": "2026-02-26T16:41:17Z",
      "categories": [
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23184v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23163v1",
      "title": "A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring",
      "summary": "Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \\textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.",
      "authors": [
        "Usman Anwar",
        "Julianna Piskorz",
        "David D. Baek",
        "David Africa",
        "Jim Weatherall",
        "Max Tegmark",
        "Christian Schroeder de Witt",
        "Mihaela van der Schaar",
        "David Krueger"
      ],
      "published": "2026-02-26T16:27:24Z",
      "updated": "2026-02-26T16:27:24Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.IT",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23163v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23136v1",
      "title": "Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs",
      "summary": "Multimodal LLMs can process speech and images, but they cannot hear a speaker's voice or see an object's texture. We show this is not a failure of encoding: speaker identity, emotion, and visual attributes survive through every LLM layer (3--55$\\times$ above chance in linear probes), yet removing 64--71% of modality-specific variance improves decoder loss. The decoder has no learned use for these directions; their presence is noise. We formalize this as a mismatched decoder problem: a decoder trained on text can only extract information along text-aligned directions. Accessible information is bounded by the Generalized Mutual Information (GMI), with degradation scaling with distributional distance and decoder sensitivity. The bound is a property of the decoder's scoring rule, not of any particular architecture; it applies whether non-text inputs arrive through a learned projection, a discrete codebook, or no explicit adapter at all. We validate this across five models spanning speech and vision. A controlled experiment (two Prismatic VLMs differing only in encoder text-alignment) confirms the bottleneck is the decoder's scoring rule, not the encoder or projection. A LoRA intervention demonstrates the fix: training with an emotion objective improves emotion accessibility ($+$7.5%) without affecting other attributes, confirming that the training objective determines what becomes accessible.",
      "authors": [
        "Jayadev Billa"
      ],
      "published": "2026-02-26T15:52:48Z",
      "updated": "2026-02-26T15:52:48Z",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23136v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23079v1",
      "title": "Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent",
      "summary": "The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.",
      "authors": [
        "Boyang Zhang",
        "Yang Zhang"
      ],
      "published": "2026-02-26T15:05:13Z",
      "updated": "2026-02-26T15:05:13Z",
      "categories": [
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23079v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23075v1",
      "title": "CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery",
      "summary": "Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity and intellectual property, and (3) protection of information privacy. In this work, we present CiteLLM, a specialized agentic platform designed to enable trustworthy reference discovery for grounding author-drafted claims and statements. The system introduces a novel interaction paradigm by embedding LLM utilities directly within the LaTeX editor environment, ensuring a seamless user experience and no data transmission outside the local system. To guarantee hallucination-free references, we employ dynamic discipline-aware routing to retrieve candidates exclusively from trusted web-based academic repositories, while leveraging LLMs solely for generating context-aware search queries, ranking candidates by relevance, and validating and explaining support through paragraph-level semantic matching and an integrated chatbot. Evaluation results demonstrate the superior performance of the proposed system in returning valid and highly usable references.",
      "authors": [
        "Mengze Hong",
        "Di Jiang",
        "Chen Jason Zhang",
        "Zichang Guo",
        "Yawen Li",
        "Jun Chen",
        "Shaobo Cui",
        "Zhiyang Su"
      ],
      "published": "2026-02-26T15:02:22Z",
      "updated": "2026-02-26T15:02:22Z",
      "categories": [
        "cs.CL",
        "cs.IR"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23075v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23071v1",
      "title": "Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody",
      "summary": "While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subject-Verb (SBV) interface (Major Phrase B3 -&gt; Prosodic Word B1), while erroneously promoting the boundary at the Verb-Object (VOB) interface (Prosodic Word B1 -&gt; Major Phrase B3). This strategy allows learners to maintain high long phrasal output at the expense of structural accuracy. This results in a distorted prosodic hierarchy where the native pattern is inverted.",
      "authors": [
        "Yuqi Shi",
        "Hao Yang",
        "Xiyao Lu",
        "Jinsong Zhang"
      ],
      "published": "2026-02-26T15:00:59Z",
      "updated": "2026-02-26T15:00:59Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23071v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23070v1",
      "title": "Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization via Extreme Augmentation and Perfect Alignment",
      "summary": "Although Automatic Speech Recognition (ASR) in Bengali has seen significant progress, processing long-duration audio and performing robust speaker diarization remain critical research gaps. To address the severe scarcity of joint ASR and diarization resources for this language, we introduce Lipi-Ghor-882, a comprehensive 882-hour multi-speaker Bengali dataset. In this paper, detailing our submission to the DL Sprint 4.0 competition, we systematically evaluate various architectures and approaches for long-form Bengali speech. For ASR, we demonstrate that raw data scaling is ineffective; instead, targeted fine-tuning utilizing perfectly aligned annotations paired with synthetic acoustic degradation (noise and reverberation) emerges as the singular most effective approach. Conversely, for speaker diarization, we observed that global open-source state-of-the-art models (such as Diarizen) performed surprisingly poorly on this complex dataset. Extensive model retraining yielded negligible improvements; instead, strategic, heuristic post-processing of baseline model outputs proved to be the primary driver for increasing accuracy. Ultimately, this work outlines a highly optimized dual pipeline achieving a $\\sim$0.019 Real-Time Factor (RTF), establishing a practical, empirically backed benchmark for low-resource, long-form speech processing.",
      "authors": [
        "Sanjid Hasan",
        "Risalat Labib",
        "A H M Fuad",
        "Bayazid Hasan"
      ],
      "published": "2026-02-26T14:59:24Z",
      "updated": "2026-02-26T14:59:24Z",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23070v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23062v1",
      "title": "Toward Automatic Filling of Case Report Forms: A Case Study on Data from an Italian Emergency Department",
      "summary": "Case Report Forms (CRFs) collect data about patients and are at the core of well-established practices to conduct research in clinical settings. With the recent progress of language technologies, there is an increasing interest in automatic CRF-filling from clinical notes, mostly based on the use of Large Language Models (LLMs). However, there is a general scarcity of annotated CRF data, both for training and testing LLMs, which limits the progress on this task. As a step in the direction of providing such data, we present a new dataset of clinical notes from an Italian Emergency Department annotated with respect to a pre-defined CRF containing 134 items to be filled. We provide an analysis of the data, define the CRF-filling task and metric for its evaluation, and report on pilot experiments where we use an open-source state-of-the-art LLM to automatically execute the task. Results of the case-study show that (i) CRF-filling from real clinical notes in Italian can be approached in a zero-shot setting; (ii) LLMs' results are affected by biases (e.g., a cautious behaviour favours \"unknown\" answers), which need to be corrected.",
      "authors": [
        "Gabriela Anna Kaczmarek",
        "Pietro Ferrazzi",
        "Lorenzo Porta",
        "Vicky Rubini",
        "Bernardo Magnini"
      ],
      "published": "2026-02-26T14:49:11Z",
      "updated": "2026-02-26T14:49:11Z",
      "categories": [
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23062v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23061v1",
      "title": "MoDora: Tree-Based Semi-Structured Document Analysis System",
      "summary": "Semi-structured documents integrate diverse interleaved data elements (e.g., tables, charts, hierarchical paragraphs) arranged in various and often irregular layouts. These documents are widely observed across domains and account for a large portion of real-world data. However, existing methods struggle to support natural language question answering over these documents due to three main technical challenges: (1) The elements extracted by techniques like OCR are often fragmented and stripped of their original semantic context, making them inadequate for analysis. (2) Existing approaches lack effective representations to capture hierarchical structures within documents (e.g., associating tables with nested chapter titles) and to preserve layout-specific distinctions (e.g., differentiating sidebars from main content). (3) Answering questions often requires retrieving and aligning relevant information scattered across multiple regions or pages, such as linking a descriptive paragraph to table cells located elsewhere in the document. To address these issues, we propose MoDora, an LLM-powered system for semi-structured document analysis. First, we adopt a local-alignment aggregation strategy to convert OCR-parsed elements into layout-aware components, and conduct type-specific information extraction for components with hierarchical titles or non-text elements. Second, we design the Component-Correlation Tree (CCTree) to hierarchically organize components, explicitly modeling inter-component relations and layout distinctions through a bottom-up cascade summarization process. Finally, we propose a question-type-aware retrieval strategy that supports (1) layout-based grid partitioning for location-based retrieval and (2) LLM-guided pruning for semantic-based retrieval. Experiments show MoDora outperforms baselines by 5.97%-61.07% in accuracy. The code is at https://github.com/weAIDB/MoDora.",
      "authors": [
        "Bangrui Xu",
        "Qihang Yao",
        "Zirui Tang",
        "Xuanhe Zhou",
        "Yeye He",
        "Shihan Yu",
        "Qianqian Xu",
        "Bin Wang",
        "Guoliang Li",
        "Conghui He",
        "Fan Wu"
      ],
      "published": "2026-02-26T14:48:49Z",
      "updated": "2026-02-26T14:48:49Z",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23061v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23057v1",
      "title": "Affine-Scaled Attention: Towards Flexible and Stable Transformer Attention",
      "summary": "Transformer attention is typically implemented using softmax normalization, which enforces attention weights with unit sum normalization. While effective in many settings, this constraint can limit flexibility in controlling attention magnitudes and may contribute to overly concentrated or unstable attention patterns during training. Prior work has explored modifications such as attention sinks or gating mechanisms, but these approaches provide only limited or indirect control over attention reweighting. We propose Affine-Scaled Attention, a simple extension to standard attention that introduces input-dependent scaling and a corresponding bias term applied to softmax-normalized attention weights. This design relaxes the strict normalization constraint while maintaining aggregation of value representations, allowing the model to adjust both the relative distribution and the scale of attention in a controlled manner. We empirically evaluate Affine-Scaled Attention in large-scale language model pretraining across multiple model sizes. Experimental results show consistent improvements in training stability, optimization behavior, and downstream task performance compared to standard softmax attention and attention sink baselines. These findings suggest that modest reweighting of attention outputs provides a practical and effective way to improve attention behavior in Transformer models.",
      "authors": [
        "Jeongin Bae",
        "Baeseong Park",
        "Gunho Park",
        "Minsub Kim",
        "Joonhyung Lee",
        "Junhee Yoo",
        "Sunghyeon Woo",
        "Jiwon Ryu",
        "Se Jung Kwon",
        "Dongsoo Lee"
      ],
      "published": "2026-02-26T14:42:16Z",
      "updated": "2026-02-26T14:42:16Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23057v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22958v1",
      "title": "Frequency-Ordered Tokenization for Better Text Compression",
      "summary": "We present frequency-ordered tokenization, a simple preprocessing technique that improves lossless text compression by exploiting the power-law frequency distribution of natural language tokens (Zipf's law). The method tokenizes text with Byte Pair Encoding (BPE), reorders the vocabulary so that frequent tokens receive small integer identifiers, and encodes the result with variable-length integers before passing it to any standard compressor. On enwik8 (100 MB Wikipedia), this yields improvements of 7.08 percentage points (pp) for zlib, 1.69 pp for LZMA, and 0.76 pp for zstd (all including vocabulary overhead), outperforming the classical Word Replacing Transform. Gains are consistent at 1 GB scale (enwik9) and across Chinese and Arabic text. We further show that preprocessing accelerates compression for computationally expensive algorithms: the total wall-clock time including preprocessing is 3.1x faster than raw zstd-22 and 2.4x faster than raw LZMA, because the preprocessed input is substantially smaller. The method can be implemented in under 50 lines of code.",
      "authors": [
        "Maximilian Kalcher"
      ],
      "published": "2026-02-26T12:53:48Z",
      "updated": "2026-02-26T12:53:48Z",
      "categories": [
        "cs.IT",
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22958v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22918v1",
      "title": "Where Vision Becomes Text: Locating the OCR Routing Bottleneck in Vision-Language Models",
      "summary": "Vision-language models (VLMs) can read text from images, but where does this optical character recognition (OCR) information enter the language processing stream? We investigate the OCR routing mechanism across three architecture families (Qwen3-VL, Phi-4, InternVL3.5) using causal interventions. By computing activation differences between original images and text-inpainted versions, we identify architecture-specific OCR bottlenecks whose dominant location depends on the vision-language integration strategy: DeepStack models (Qwen) show peak sensitivity at mid-depth (about 50%) for scene text, while single-stage projection models (Phi-4, InternVL) peak at early layers (6-25%), though the exact layer of maximum effect varies across datasets. The OCR signal is remarkably low-dimensional: PC1 captures 72.9% of variance. Crucially, principal component analysis (PCA) directions learned on one dataset transfer to others, demonstrating shared text-processing pathways. Surprisingly, in models with modular OCR circuits (notably Qwen3-VL-4B), OCR removal can improve counting performance (up to +6.9 percentage points), suggesting OCR interferes with other visual processing in sufficiently modular architectures.",
      "authors": [
        "Jonathan Steinberg",
        "Oren Gal"
      ],
      "published": "2026-02-26T12:06:02Z",
      "updated": "2026-02-26T12:06:02Z",
      "categories": [
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22918v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22911v1",
      "title": "NoRA: Breaking the Linear Ceiling of Low-Rank Adaptation via Manifold Expansion",
      "summary": "Low-Rank Adaptation (LoRA) dominates parameter-efficient fine-tuning (PEFT). However, it faces a critical ``linear ceiling'' in complex reasoning tasks: simply increasing the rank yields diminishing returns due to intrinsic linear constraints. We introduce NoRA (Non-linear Rank Adaptation), a weight-level parallel adapter that injects SiLU gating and structural dropout to induce manifold expansion. On the SlimOrca benchmark, NoRA breaks this linear barrier: NoRA remarkably at rank 64 (PPL 3.89) outperforms LoRA at rank 512 (PPL 3.90), demonstrating superior spectral efficiency. This advantage generalizes to mathematical reasoning, where NoRA achieves a perplexity of 1.97 on MathInstruct, significantly surpassing LoRA's saturation point of 2.07. Mechanism analysis via Singular Value Decomposition (SVD) confirms that NoRA activates the dormant tail of the singular value spectrum, effectively preventing the rank collapse observed in linear methods.",
      "authors": [
        "Hung-Hsuan Chen"
      ],
      "published": "2026-02-26T11:55:25Z",
      "updated": "2026-02-26T11:55:25Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22911v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22897v1",
      "title": "OmniGAIA: Towards Native Omni-Modal AI Agents",
      "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.",
      "authors": [
        "Xiaoxi Li",
        "Wenxiang Jiao",
        "Jiarui Jin",
        "Shijian Wang",
        "Guanting Dong",
        "Jiajie Jin",
        "Hao Wang",
        "Yinuo Wang",
        "Ji-Rong Wen",
        "Yuan Lu",
        "Zhicheng Dou"
      ],
      "published": "2026-02-26T11:35:04Z",
      "updated": "2026-02-26T11:35:04Z",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22897v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22871v1",
      "title": "Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching",
      "summary": "Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or \"nearly correct\" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions an autoregressive (AR) model (solver) to recompute only the final answer. This modular pipeline separates exploration (diffusion) from evaluation and solution synthesis, avoiding monolithic unified hybrids while preserving broad search. Across math reasoning benchmarks, we find that step-level recombination is most beneficial on harder problems, and ablations highlight the importance of the final AR solver in converting stitched but imperfect rationales into accurate answers. Using low-confidence diffusion sampling with parallel, independent rollouts, our training-free framework improves average accuracy by up to 23.8% across six math and coding tasks. At the same time, it achieves up to a 1.8x latency reduction relative to both traditional diffusion models (e.g., Dream, LLaDA) and unified architectures (e.g., TiDAR). Code is available at https://github.com/roymiles/diffusion-stitching.",
      "authors": [
        "Roy Miles",
        "Aysim Toker",
        "Andreea-Maria Oncescu",
        "Songcen Xu",
        "Jiankang Deng",
        "Ismail Elezi"
      ],
      "published": "2026-02-26T11:08:39Z",
      "updated": "2026-02-26T11:08:39Z",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22871v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22868v1",
      "title": "Rejection Mixing: Fast Semantic Propagation of Mask Tokens for Efficient DLLM Inference",
      "summary": "Diffusion Large Language Models (DLLMs) promise fast non-autoregressive inference but suffer a severe quality-speed trade-off in parallel decoding. This stems from the ''combinatorial contradiction'' phenomenon, where parallel tokens form semantically inconsistent combinations. We address this by integrating continuous representations into the discrete decoding process, as they preserve rich inter-position dependency. We propose ReMix (Rejection Mixing), a framework that introduces a novel Continuous Mixing State as an intermediate between the initial masked state and the final decoded token state. This intermediate state allows a token's representation to be iteratively refined in a continuous space, resolving mutual conflicts with other tokens before collapsing into a final discrete sample. Furthermore, a rejection rule reverts uncertain representations from the continuous state back to the masked state for reprocessing, ensuring stability and preventing error propagation. ReMix thus mitigates combinatorial contradictions by enabling continuous-space refinement during discrete diffusion decoding. Extensive experiments demonstrate that ReMix, as a training-free method, achieves a $2-8 \\times$ inference speedup without any quality degradation.",
      "authors": [
        "Yushi Ye",
        "Feng Hong",
        "Huangjie Zheng",
        "Xu Chen",
        "Zhiyong Chen",
        "Yanfeng Wang",
        "Jiangchao Yao"
      ],
      "published": "2026-02-26T11:08:11Z",
      "updated": "2026-02-26T11:08:11Z",
      "categories": [
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22868v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23363v1",
      "title": "MediX-R1: Open Ended Medical Reinforcement Learning",
      "summary": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com",
      "authors": [
        "Sahal Shaji Mullappilly",
        "Mohammed Irfan Kurpath",
        "Omair Mohamed",
        "Mohamed Zidan",
        "Fahad Khan",
        "Salman Khan",
        "Rao Anwer",
        "Hisham Cholakkal"
      ],
      "published": "2026-02-26T18:59:46Z",
      "updated": "2026-02-26T18:59:46Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23363v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23361v1",
      "title": "VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale",
      "summary": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.",
      "authors": [
        "Sven Elflein",
        "Ruilong Li",
        "Sérgio Agostinho",
        "Zan Gojcic",
        "Laura Leal-Taixé",
        "Qunjie Zhou",
        "Aljosa Osep"
      ],
      "published": "2026-02-26T18:59:33Z",
      "updated": "2026-02-26T18:59:33Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23361v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23357v1",
      "title": "Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training",
      "summary": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.",
      "authors": [
        "Aheli Saha",
        "René Schuster",
        "Didier Stricker"
      ],
      "published": "2026-02-26T18:57:52Z",
      "updated": "2026-02-26T18:57:52Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23357v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23339v1",
      "title": "Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?",
      "summary": "Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability.",
      "authors": [
        "Tilemachos Aravanis",
        "Vladan Stojnić",
        "Bill Psomas",
        "Nikos Komodakis",
        "Giorgos Tolias"
      ],
      "published": "2026-02-26T18:45:33Z",
      "updated": "2026-02-26T18:45:33Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23339v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23306v1",
      "title": "ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding",
      "summary": "Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning and provides new insights into the generalization and application of reasoning capabilities.",
      "authors": [
        "Yiran Guan",
        "Sifan Tu",
        "Dingkang Liang",
        "Linghao Zhu",
        "Jianzhong Ju",
        "Zhenbo Luo",
        "Jian Luan",
        "Yuliang Liu",
        "Xiang Bai"
      ],
      "published": "2026-02-26T18:10:41Z",
      "updated": "2026-02-26T18:10:41Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23306v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23297v1",
      "title": "PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM",
      "summary": "Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods. Notably, our framework achieves superior robustness without the need for massive data collection or exhaustive computational resources. Our code will be made public upon acceptance.",
      "authors": [
        "Yiqing Wang",
        "Chunming He",
        "Ming-Chen Lu",
        "Mercy Pawar",
        "Leslie Niziol",
        "Maria Woodward",
        "Sina Farsiu"
      ],
      "published": "2026-02-26T18:07:52Z",
      "updated": "2026-02-26T18:07:52Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23297v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23294v1",
      "title": "Towards Long-Form Spatio-Temporal Video Grounding",
      "summary": "In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.",
      "authors": [
        "Xin Gu",
        "Bing Fan",
        "Jiali Yao",
        "Zhipeng Zhang",
        "Yan Huang",
        "Cheng Han",
        "Heng Fan",
        "Libo Zhang"
      ],
      "published": "2026-02-26T18:04:09Z",
      "updated": "2026-02-26T18:04:09Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23294v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23292v1",
      "title": "PGVMS: A Prompt-Guided Unified Framework for Virtual Multiplex IHC Staining with Pathological Semantic Learning",
      "summary": "Immunohistochemical (IHC) staining enables precise molecular profiling of protein expression, with over 200 clinically available antibody-based tests in modern pathology. However, comprehensive IHC analysis is frequently limited by insufficient tissue quantities in small biopsies. Therefore, virtual multiplex staining emerges as an innovative solution to digitally transform H&amp;E images into multiple IHC representations, yet current methods still face three critical challenges: (1) inadequate semantic guidance for multi-staining, (2) inconsistent distribution of immunochemistry staining, and (3) spatial misalignment across different stain modalities. To overcome these limitations, we present a prompt-guided framework for virtual multiplex IHC staining using only uniplex training data (PGVMS). Our framework introduces three key innovations corresponding to each challenge: First, an adaptive prompt guidance mechanism employing a pathological visual language model dynamically adjusts staining prompts to resolve semantic guidance limitations (Challenge 1). Second, our protein-aware learning strategy (PALS) maintains precise protein expression patterns by direct quantification and constraint of protein distributions (Challenge 2). Third, the prototype-consistent learning strategy (PCLS) establishes cross-image semantic interaction to correct spatial misalignments (Challenge 3).",
      "authors": [
        "Fuqiang Chen",
        "Ranran Zhang",
        "Wanming Hu",
        "Deboch Eyob Abera",
        "Yue Peng",
        "Boyun Zheng",
        "Yiwen Sun",
        "Jing Cai",
        "Wenjian Qin"
      ],
      "published": "2026-02-26T18:03:24Z",
      "updated": "2026-02-26T18:03:24Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23292v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23290v1",
      "title": "LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction",
      "summary": "The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS strategy to preserve critical connections. We evaluate LineGraph2Road on three benchmarks: City-scale, SpaceNet, and Global-scale, and show that it achieves state-of-the-art results on two key metrics, TOPO-F1 and APLS. It also captures fine visual details critical for real-world deployment. We will make our code publicly available.",
      "authors": [
        "Zhengyang Wei",
        "Renzhi Jing",
        "Yiyi He",
        "Jenny Suckale"
      ],
      "published": "2026-02-26T18:02:44Z",
      "updated": "2026-02-26T18:02:44Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23290v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23262v1",
      "title": "Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling",
      "summary": "Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks.",
      "authors": [
        "Jasmine Bayrooti",
        "Weiwei Kong",
        "Natalia Ponomareva",
        "Carlos Esteves",
        "Ameesh Makadia",
        "Amanda Prorok"
      ],
      "published": "2026-02-26T17:36:48Z",
      "updated": "2026-02-26T17:36:48Z",
      "categories": [
        "cs.CV",
        "cs.CR"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23262v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23231v1",
      "title": "Skarimva: Skeleton-based Action Recognition is a Multi-view Application",
      "summary": "Human action recognition plays an important role when developing intelligent interactions between humans and machines. While there is a lot of active research on improving the machine learning algorithms for skeleton-based action recognition, not much attention has been given to the quality of the input skeleton data itself. This work demonstrates that by making use of multiple camera views to triangulate more accurate 3D~skeletons, the performance of state-of-the-art action recognition models can be improved significantly. This suggests that the quality of the input data is currently a limiting factor for the performance of these models. Based on these results, it is argued that the cost-benefit ratio of using multiple cameras is very favorable in most practical use-cases, therefore future research in skeleton-based action recognition should consider multi-view applications as the standard setup.",
      "authors": [
        "Daniel Bermuth",
        "Alexander Poeppel",
        "Wolfgang Reif"
      ],
      "published": "2026-02-26T17:10:58Z",
      "updated": "2026-02-26T17:10:58Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23231v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23229v1",
      "title": "Large Multimodal Models as General In-Context Classifiers",
      "summary": "Which multimodal model should we use for classification? Previous studies suggest that the answer lies in CLIP-like contrastive Vision-Language Models (VLMs), due to their remarkable performance in zero-shot classification. In contrast, Large Multimodal Models (LMM) are more suitable for complex tasks. In this work, we argue that this answer overlooks an important capability of LMMs: in-context learning. We benchmark state-of-the-art LMMs on diverse datasets for closed-world classification and find that, although their zero-shot performance is lower than CLIP's, LMMs with a few in-context examples can match or even surpass contrastive VLMs with cache-based adapters, their \"in-context\" equivalent. We extend this analysis to the open-world setting, where the generative nature of LMMs makes them more suitable for the task. In this challenging scenario, LMMs struggle whenever provided with imperfect context information. To address this issue, we propose CIRCLE, a simple training-free method that assigns pseudo-labels to in-context examples, iteratively refining them with the available context itself. Through extensive experiments, we show that CIRCLE establishes a robust baseline for open-world classification, surpassing VLM counterparts and highlighting the potential of LMMs to serve as unified classifiers, and a flexible alternative to specialized models.",
      "authors": [
        "Marco Garosi",
        "Matteo Farina",
        "Alessandro Conti",
        "Massimiliano Mancini",
        "Elisa Ricci"
      ],
      "published": "2026-02-26T17:08:18Z",
      "updated": "2026-02-26T17:08:18Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23229v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23228v1",
      "title": "MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction",
      "summary": "With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external \"tool\" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to steer the VLM's reasoning, ensuring the generated scene descriptions are anchored to verifiable facts. Furthermore, our progressive abstraction pipeline decomposes the summarization of a full-length movie into a multi-stage process, effectively mitigating the context length limitations of current VLMs. Experiments demonstrate that our approach yields significant improvements in factual accuracy, character consistency, and overall narrative coherence compared to end-to-end baselines.",
      "authors": [
        "Yizhi Li",
        "Xiaohan Chen",
        "Miao Jiang",
        "Wentao Tang",
        "Gaoang Wang"
      ],
      "published": "2026-02-26T17:08:08Z",
      "updated": "2026-02-26T17:08:08Z",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23228v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23224v1",
      "title": "UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception",
      "summary": "We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encoding strategies, making it particularly suitable for resource-constrained robotic teams. We evaluate UniScale on multiple benchmarks, demonstrating strong generalization and consistent performance across diverse environments. We will release our implementation upon acceptance.",
      "authors": [
        "Mohammad Mahdavian",
        "Gordon Tan",
        "Binbin Xu",
        "Yuan Ren",
        "Dongfeng Bai",
        "Bingbing Liu"
      ],
      "published": "2026-02-26T17:04:36Z",
      "updated": "2026-02-26T17:04:36Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23224v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23217v1",
      "title": "Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks",
      "summary": "This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.",
      "authors": [
        "Alaa El Ichi",
        "Khalide Jbilou"
      ],
      "published": "2026-02-26T17:00:45Z",
      "updated": "2026-02-26T17:00:45Z",
      "categories": [
        "cs.CV",
        "math.NA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23217v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23212v1",
      "title": "Through BrokenEyes: How Eye Disorders Impact Face Detection?",
      "summary": "Vision disorders significantly impact millions of lives, altering how visual information is processed and perceived. In this work, a computational framework was developed using the BrokenEyes system to simulate five common eye disorders: Age-related macular degeneration, cataract, glaucoma, refractive errors, and diabetic retinopathy and analyze their effects on neural-like feature representations in deep learning models. Leveraging a combination of human and non-human datasets, models trained under normal and disorder-specific conditions revealed critical disruptions in feature maps, particularly for cataract and glaucoma, which align with known neural processing challenges in these conditions. Evaluation metrics such as activation energy and cosine similarity quantified the severity of these distortions, providing insights into the interplay between degraded visual inputs and learned representations.",
      "authors": [
        "Prottay Kumar Adhikary"
      ],
      "published": "2026-02-26T16:56:51Z",
      "updated": "2026-02-26T16:56:51Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23212v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23205v1",
      "title": "EmbodMocap: In-the-Wild 4D Human-Scene Reconstruction for Embodied Agents",
      "summary": "Human behaviors in the real world naturally encode rich, long-term contextual information that can be leveraged to train embodied agents for perception, understanding, and acting. However, existing capture systems typically rely on costly studio setups and wearable devices, limiting the large-scale collection of scene-conditioned human motion data in the wild. To address this, we propose EmbodMocap, a portable and affordable data collection pipeline using two moving iPhones. Our key idea is to jointly calibrate dual RGB-D sequences to reconstruct both humans and scenes within a unified metric world coordinate frame. The proposed method allows metric-scale and scene-consistent capture in everyday environments without static cameras or markers, bridging human motion and scene geometry seamlessly. Compared with optical capture ground truth, we demonstrate that the dual-view setting exhibits a remarkable ability to mitigate depth ambiguity, achieving superior alignment and reconstruction performance over single iphone or monocular models. Based on the collected data, we empower three embodied AI tasks: monocular human-scene-reconstruction, where we fine-tune on feedforward models that output metric-scale, world-space aligned humans and scenes; physics-based character animation, where we prove our data could be used to scale human-object interaction skills and scene-aware motion tracking; and robot motion control, where we train a humanoid robot via sim-to-real RL to replicate human motions depicted in videos. Experimental results validate the effectiveness of our pipeline and its contributions towards advancing embodied AI research.",
      "authors": [
        "Wenjia Wang",
        "Liang Pan",
        "Huaijin Pi",
        "Yuke Lou",
        "Xuqian Ren",
        "Yifan Wu",
        "Zhouyingcheng Liao",
        "Lei Yang",
        "Rishabh Dabral",
        "Christian Theobalt",
        "Taku Komura"
      ],
      "published": "2026-02-26T16:53:41Z",
      "updated": "2026-02-26T16:53:41Z",
      "categories": [
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23205v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.23204v1",
      "title": "Motion-aware Event Suppression for Event Cameras",
      "summary": "In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.",
      "authors": [
        "Roberto Pellerito",
        "Nico Messikommer",
        "Giovanni Cioffi",
        "Marco Cannici",
        "Davide Scaramuzza"
      ],
      "published": "2026-02-26T16:53:36Z",
      "updated": "2026-02-26T16:53:36Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23204v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23287v1",
      "title": "Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning",
      "summary": "Assistive robots offer agency to humans with severe motor impairments. Often, these users control high-DoF robots through low-dimensional interfaces, such as using a 1-D sip-and-puff interface to operate a 6-DoF robotic arm. This mismatch results in having access to only a subset of control dimensions at a given time, imposing unintended and artificial constraints on robot motion. As a result, interface-limited demonstrations embed suboptimal motions that reflect interface restrictions rather than user intent. To address this, we present a trajectory reconstruction algorithm that reasons about task, environment, and interface constraints to lift demonstrations into the robot's full control space. We evaluate our approach using real-world demonstrations of ADL-inspired tasks performed via a 2-D joystick and 1-D sip-and-puff control interface, teleoperating two distinct 7-DoF robotic arms. Analyses of the reconstructed demonstrations and derived control policies show that lifted trajectories are faster and more efficient than their interface-constrained counterparts while respecting user preferences.",
      "authors": [
        "Demiana R. Barsoum",
        "Mahdieh Nejati Javaremi",
        "Larisa Y. C. Loke",
        "Brenna D. Argall"
      ],
      "published": "2026-02-26T18:01:25Z",
      "updated": "2026-02-26T18:01:25Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23287v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23283v1",
      "title": "Simple Models, Real Swimming: Digital Twins for Tendon-Driven Underwater Robots",
      "summary": "Mimicking the graceful motion of swimming animals remains a core challenge in soft robotics due to the complexity of fluid-structure interaction and the difficulty of controlling soft, biomimetic bodies. Existing modeling approaches are often computationally expensive and impractical for complex control or reinforcement learning needed for realistic motions to emerge in robotic systems. In this work, we present a tendon-driven fish robot modeled in an efficient underwater swimmer environment using a simplified, stateless hydrodynamics formulation implemented in the widespread robotics framework MuJoCo. With just two real-world swimming trajectories, we identify five fluid parameters that allow a matching to experimental behavior and generalize across a range of actuation frequencies. We show that this stateless fluid model can generalize to unseen actuation and outperform classical analytical models such as the elongated body theory. This simulation environment runs faster than real-time and can easily enable downstream learning algorithms such as reinforcement learning for target tracking, reaching a 93% success rate. Due to the simplicity and ease of use of the model and our open-source simulation environment, our results show that even simple, stateless models -- when carefully matched to physical data -- can serve as effective digital twins for soft underwater robots, opening up new directions for scalable learning and control in aquatic environments.",
      "authors": [
        "Mike Y. Michelis",
        "Nana Obayashi",
        "Josie Hughes",
        "Robert K. Katzschmann"
      ],
      "published": "2026-02-26T17:55:22Z",
      "updated": "2026-02-26T17:55:22Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23283v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23253v1",
      "title": "SPARR: Simulation-based Policies with Asymmetric Real-world Residuals for Assembly",
      "summary": "Robotic assembly presents a long-standing challenge due to its requirement for precise, contact-rich manipulation. While simulation-based learning has enabled the development of robust assembly policies, their performance often degrades when deployed in real-world settings due to the sim-to-real gap. Conversely, real-world reinforcement learning (RL) methods avoid the sim-to-real gap, but rely heavily on human supervision and lack generalization ability to environmental changes. In this work, we propose a hybrid approach that combines a simulation-trained base policy with a real-world residual policy to efficiently adapt to real-world variations. The base policy, trained in simulation using low-level state observations and dense rewards, provides strong priors for initial behavior. The residual policy, learned in the real world using visual observations and sparse rewards, compensates for discrepancies in dynamics and sensor noise. Extensive real-world experiments demonstrate that our method, SPARR, achieves near-perfect success rates across diverse two-part assembly tasks. Compared to the state-of-the-art zero-shot sim-to-real methods, SPARR improves success rates by 38.4% while reducing cycle time by 29.7%. Moreover, SPARR requires no human expertise, in contrast to the state-of-the-art real-world RL approaches that depend heavily on human supervision.",
      "authors": [
        "Yijie Guo",
        "Iretiayo Akinola",
        "Lars Johannsmeier",
        "Hugo Hadfield",
        "Abhishek Gupta",
        "Yashraj Narang"
      ],
      "published": "2026-02-26T17:26:13Z",
      "updated": "2026-02-26T17:26:13Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23253v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23206v1",
      "title": "Grasp, Slide, Roll: Comparative Analysis of Contact Modes for Tactile-Based Shape Reconstruction",
      "summary": "Tactile sensing allows robots to gather detailed geometric information about objects through physical interaction, complementing vision-based approaches. However, efficiently acquiring useful tactile data remains challenging due to the time-consuming nature of physical contact and the need to strategically choose contact locations that maximize information gain while minimizing physical interactions. This paper studies how different contact modes affect object shape reconstruction using a tactile-enabled dexterous gripper. We compare three contact interaction modes: grasp-releasing, sliding induced by finger-grazing, and palm-rolling. These contact modes are combined with an information-theoretic exploration framework that guides subsequent sampling locations using a shape completion model. Our results show that the improved tactile sensing efficiency of finger-grazing and palm-rolling translates into faster convergence in shape reconstruction, requiring 34% fewer physical interactions while improving reconstruction accuracy by 55%. We validate our approach using a UR5e robot arm equipped with an Inspire-Robots Dexterous Hand, showing robust performance across primitive object geometries.",
      "authors": [
        "Chung Hee Kim",
        "Shivani Kamtikar",
        "Tye Brady",
        "Taskin Padir",
        "Joshua Migdal"
      ],
      "published": "2026-02-26T16:53:59Z",
      "updated": "2026-02-26T16:53:59Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23206v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23172v1",
      "title": "Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking",
      "summary": "Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, we first fuse observations into 3D Gaussians that serve as a sparse point-centric latent representation of the 3D scene, and then splat the aggregated features onto a 3D voxel grid that is decoded by a mask-based segmentation head. We evaluate LaGS on the Occ3D nuScenes and Waymo datasets, achieving state-of-the-art performance for 4D panoptic occupancy tracking. We make our code available at https://lags.cs.uni-freiburg.de/.",
      "authors": [
        "Maximilian Luz",
        "Rohit Mohan",
        "Thomas Nürnberg",
        "Yakov Miron",
        "Daniele Cattaneo",
        "Abhinav Valada"
      ],
      "published": "2026-02-26T16:34:49Z",
      "updated": "2026-02-26T16:34:49Z",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23172v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23115v1",
      "title": "FLIGHT: Fibonacci Lattice-based Inference for Geometric Heading in real-Time",
      "summary": "Estimating camera motion from monocular video is a fundamental problem in computer vision, central to tasks such as SLAM, visual odometry, and structure-from-motion. Existing methods that recover the camera's heading under known rotation, whether from an IMU or an optimization algorithm, tend to perform well in low-noise, low-outlier conditions, but often decrease in accuracy or become computationally expensive as noise and outlier levels increase. To address these limitations, we propose a novel generalization of the Hough transform on the unit sphere (S(2)) to estimate the camera's heading. First, the method extracts correspondences between two frames and generates a great circle of directions compatible with each pair of correspondences. Then, by discretizing the unit sphere using a Fibonacci lattice as bin centers, each great circle casts votes for a range of directions, ensuring that features unaffected by noise or dynamic objects vote consistently for the correct motion direction. Experimental results on three datasets demonstrate that the proposed method is on the Pareto frontier of accuracy versus efficiency. Additionally, experiments on SLAM show that the proposed method reduces RMSE by correcting the heading during camera pose initialization.",
      "authors": [
        "David Dirnfeld",
        "Fabien Delattre",
        "Pedro Miraldo",
        "Erik Learned-Miller"
      ],
      "published": "2026-02-26T15:27:49Z",
      "updated": "2026-02-26T15:27:49Z",
      "categories": [
        "cs.CV",
        "cs.CG",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23115v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23109v1",
      "title": "Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios",
      "summary": "The sudden appearance of occluded pedestrians presents a critical safety challenge in autonomous driving. Conventional rule-based or purely data-driven approaches struggle with the inherent high uncertainty of these long-tail scenarios. To tackle this challenge, we propose a novel framework grounded in Active Inference, which endows the agent with a human-like, belief-driven mechanism. Our framework leverages a Rao-Blackwellized Particle Filter (RBPF) to efficiently estimate the pedestrian's hybrid state. To emulate human-like cognitive processes under uncertainty, we introduce a Conditional Belief Reset mechanism and a Hypothesis Injection technique to explicitly model beliefs about the pedestrian's multiple latent intentions. Planning is achieved via a Cross-Entropy Method (CEM) enhanced Model Predictive Path Integral (MPPI) controller, which synergizes the efficient, iterative search of CEM with the inherent robustness of MPPI. Simulation experiments demonstrate that our approach significantly reduces the collision rate compared to reactive, rule-based, and reinforcement learning (RL) baselines, while also exhibiting explainable and human-like driving behavior that reflects the agent's internal belief state.",
      "authors": [
        "Kai Chen",
        "Yuyao Huang",
        "Guang Chen"
      ],
      "published": "2026-02-26T15:22:07Z",
      "updated": "2026-02-26T15:22:07Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23109v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23058v1",
      "title": "GeoWorld: Geometric World Models",
      "summary": "Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned in Euclidean space, neglecting the underlying geometric and hierarchical structure among states, and (ii) they struggle with long-horizon prediction, which leads to rapid degradation across extended rollouts. To address these challenges, we introduce GeoWorld, a geometric world model that preserves geometric structure and hierarchical relations through a Hyperbolic JEPA, which maps latent representations from Euclidean space onto hyperbolic manifolds. We further introduce Geometric Reinforcement Learning for energy-based optimization, enabling stable multi-step planning in hyperbolic latent space. Extensive experiments on CrossTask and COIN demonstrate around 3% SR improvement in 3-step planning and 2% SR improvement in 4-step planning compared to the state-of-the-art V-JEPA 2. Project website: https://steve-zeyu-zhang.github.io/GeoWorld.",
      "authors": [
        "Zeyu Zhang",
        "Danning Li",
        "Ian Reid",
        "Richard Hartley"
      ],
      "published": "2026-02-26T14:42:53Z",
      "updated": "2026-02-26T14:42:53Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23058v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23053v1",
      "title": "Marinarium: a New Arena to Bring Maritime Robotics Closer to Shore",
      "summary": "This paper presents the Marinarium, a modular and stand-alone underwater research facility designed to provide a realistic testbed for maritime and space-analog robotic experimentation in a resource-efficient manner. The Marinarium combines a fully instrumented underwater and aerial operational volume, extendable via a retractable roof for real-weather conditions, a digital twin in the SMaRCSim simulator and tight integration with a space robotics laboratory. All of these result from design choices aimed at bridging simulation, laboratory validation, and field conditions. We compare the Marinarium to similar existing infrastructures and illustrate how its design enables a set of experiments in four open research areas within field robotics. First, we exploit high-fidelity dynamics data from the tank to demonstrate the potential of learning-based system identification approaches applied to underwater vehicles. We further highlight the versatility of the multi-domain operating volume via a rendezvous mission with a heterogeneous fleet of robots across underwater, surface, and air. We then illustrate how the presented digital twin can be utilized to reduce the reality gap in underwater simulation. Finally, we demonstrate the potential of underwater surrogates for spacecraft navigation validation by executing spatiotemporally identical inspection tasks on a planar space-robot emulator and a neutrally buoyant \\gls{rov}. In this work, by sharing the insights obtained and rationale behind the design and construction of the Marinarium, we hope to provide the field robotics research community with a blueprint for bridging the gap between controlled and real offshore and space robotics experimentation.",
      "authors": [
        "Ignacio Torroba",
        "David Dorner",
        "Victor Nan Fernandez-Ayala",
        "Mart Kartasev",
        "Joris Verhagen",
        "Elias Krantz",
        "Gregorio Marchesini",
        "Carl Ljung",
        "Pedro Roque",
        "Chelsea Sidrane",
        "Linda Van der Spaa",
        "Nicola De Carli",
        "Petter Ogren",
        "Christer Fuglesang",
        "Jana Tumova",
        "Dimos V. Dimarogonas",
        "Ivan Stenius"
      ],
      "published": "2026-02-26T14:40:20Z",
      "updated": "2026-02-26T14:40:20Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23053v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23051v1",
      "title": "An Empirical Analysis of Cooperative Perception for Occlusion Risk Mitigation",
      "summary": "Occlusions present a significant challenge for connected and automated vehicles, as they can obscure critical road users from perception systems. Traditional risk metrics often fail to capture the cumulative nature of these threats over time adequately. In this paper, we propose a novel and universal risk assessment metric, the Risk of Tracking Loss (RTL), which aggregates instantaneous risk intensity throughout occluded periods. This provides a holistic risk profile that encompasses both high-intensity, short-term threats and prolonged exposure. Utilizing diverse and high-fidelity real-world datasets, a large-scale statistical analysis is conducted to characterize occlusion risk and validate the effectiveness of the proposed metric. The metric is applied to evaluate different vehicle-to-everything (V2X) deployment strategies. Our study shows that full V2X penetration theoretically eliminates this risk, the reduction is highly nonlinear; a substantial statistical benefit requires a high penetration threshold of 75-90%. To overcome this limitation, we propose a novel asymmetric communication framework that allows even non-connected vehicles to receive warnings. Experimental results demonstrate that this paradigm achieves better risk mitigation performance. We found that our approach at 25% penetration outperforms the traditional symmetric model at 75%, and benefits saturate at only 50% penetration. This work provides a crucial risk assessment metric and a cost-effective, strategic roadmap for accelerating the safety benefits of V2X deployment.",
      "authors": [
        "Aihong Wang",
        "Tenghui Xie",
        "Fuxi Wen",
        "Jun Li"
      ],
      "published": "2026-02-26T14:38:38Z",
      "updated": "2026-02-26T14:38:38Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23051v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23024v1",
      "title": "InCoM: Intent-Driven Perception and Structured Coordination for Whole-Body Mobile Manipulation",
      "summary": "Whole-body mobile manipulation is a fundamental capability for general-purpose robotic agents, requiring both coordinated control of the mobile base and manipulator and robust perception under dynamically changing viewpoints. However, existing approaches face two key challenges: strong coupling between base and arm actions complicates whole-body control optimization, and perceptual attention is often poorly allocated as viewpoints shift during mobile manipulation. We propose InCoM, an intent-driven perception and structured coordination framework for whole-body mobile manipulation. InCoM infers latent motion intent to dynamically reweight multi-scale perceptual features, enabling stage-adaptive allocation of perceptual attention. To support robust cross-modal perception, InCoM further incorporates a geometric-semantic structured alignment mechanism that enhances multimodal correspondence. On the control side, we design a decoupled coordinated flow matching action decoder that explicitly models coordinated base-arm action generation, alleviating optimization difficulties caused by control coupling. Without access to privileged perceptual information, InCoM outperforms state-of-the-art methods on three ManiSkill-HAB scenarios by 28.2%, 26.1%, and 23.6% in success rate, demonstrating strong effectiveness for whole-body mobile manipulation.",
      "authors": [
        "Jiahao Liu",
        "Cui Wenbo",
        "Haoran Li",
        "Dongbin Zhao"
      ],
      "published": "2026-02-26T14:03:58Z",
      "updated": "2026-02-26T14:03:58Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23024v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.23017v1",
      "title": "DigiArm: An Anthropomorphic 3D-Printed Prosthetic Hand with Enhanced Dexterity for Typing Tasks",
      "summary": "Despite recent advancements, existing prosthetic limbs are unable to replicate the dexterity and intuitive control of the human hand. Current control systems for prosthetic hands are often limited to grasping, and commercial prosthetic hands lack the precision needed for dexterous manipulation or applications that require fine finger motions. Thus, there is a critical need for accessible and replicable prosthetic designs that enable individuals to interact with electronic devices and perform precise finger pressing, such as keyboard typing or piano playing, while preserving current prosthetic capabilities. This paper presents a low-cost, lightweight, 3D-printed robotic prosthetic hand, specifically engineered for enhanced dexterity with electronic devices such as a computer keyboard or piano, as well as general object manipulation. The robotic hand features a mechanism to adjust finger abduction/adduction spacing, a 2-D wrist with the inclusion of controlled ulnar/radial deviation optimized for typing, and control of independent finger pressing. We conducted a study to demonstrate how participants can use the robotic hand to perform keyboard typing and piano playing in real time, with different levels of finger and wrist motion. This supports the notion that our proposed design can allow for the execution of key typing motions more effectively than before, aiming to enhance the functionality of prosthetic hands.",
      "authors": [
        "Dean Zadok",
        "Tom Naamani",
        "Yuval Bar-Ratson",
        "Elisha Barash",
        "Oren Salzman",
        "Alon Wolf",
        "Alex M. Bronstein",
        "Nili Krausz"
      ],
      "published": "2026-02-26T13:55:05Z",
      "updated": "2026-02-26T13:55:05Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23017v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22998v1",
      "title": "A Perspective on Open Challenges in Deformable Object Manipulation",
      "summary": "Deformable object manipulation (DOM) represents a critical challenge in robotics, with applications spanning healthcare, manufacturing, food processing, and beyond. Unlike rigid objects, deformable objects exhibit infinite dimensionality, dynamic shape changes, and complex interactions with their environment, posing significant hurdles for perception, modeling, and control. This paper reviews the state of the art in DOM, focusing on key challenges such as occlusion handling, task generalization, and scalable, real-time solutions. It highlights advancements in multimodal perception systems, including the integration of multi-camera setups, active vision, and tactile sensing, which collectively address occlusion and improve adaptability in unstructured environments. Cutting-edge developments in physically informed reinforcement learning (RL) and differentiable simulations are explored, showcasing their impact on efficiency, precision, and scalability. The review also emphasizes the potential of simulated expert demonstrations and generative neural networks to standardize task specifications and bridge the simulation-to-reality gap. Finally, future directions are proposed, including the adoption of graph neural networks for high-level decision-making and the creation of comprehensive datasets to enhance DOM's real-world applicability. By addressing these challenges, DOM research can pave the way for versatile robotic systems capable of handling diverse and dynamic tasks with deformable objects.",
      "authors": [
        "Ryan Paul McKennaa",
        "John Oyekan"
      ],
      "published": "2026-02-26T13:39:30Z",
      "updated": "2026-02-26T13:39:30Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22998v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22952v1",
      "title": "Automated Robotic Needle Puncture for Percutaneous Dilatational Tracheostomy",
      "summary": "Percutaneous dilatational tracheostomy (PDT) is frequently performed on patients in intensive care units for prolonged mechanical ventilation. The needle puncture, as the most critical step of PDT, could lead to adverse consequences such as major bleeding and posterior tracheal wall perforation if performed inaccurately. Current practices of PDT puncture are all performed manually with no navigation assistance, which leads to large position and angular errors (5 mm and 30 degree). To improve the accuracy and reduce the difficulty of the PDT procedure, we propose a system that automates the needle insertion using a velocity-controlled robotic manipulator. Guided using pose data from two electromagnetic sensors, one at the needle tip and the other inside the trachea, the robotic system uses an adaptive constrained controller to adapt the uncertain kinematic parameters online and avoid collisions with the patient's body and tissues near the target. Simulations were performed to validate the controller's implementation, and then four hundred PDT punctures were performed on a mannequin to evaluate the position and angular accuracy. The absolute median puncture position error was 1.7 mm (IQR: 1.9 mm) and midline deviation was 4.13 degree (IQR: 4.55 degree), measured by the sensor inside the trachea. The small deviations from the nominal puncture in a simulated experimental setup and formal guarantees of collision-free insertions suggest the feasibility of the robotic PDT puncture.",
      "authors": [
        "Yuan Tang",
        "Bruno V. Adorno",
        "Brendan A. McGrath",
        "Andrew Weightman"
      ],
      "published": "2026-02-26T12:47:04Z",
      "updated": "2026-02-26T12:47:04Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22952v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22940v1",
      "title": "Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning",
      "summary": "Recent automated vehicle (AV) motion planning strategies evolve around minimizing risk in road traffic. However, they exclusively consider risk from the AV's perspective and, as such, do not address the ethicality of its decisions for other road users. We argue that this does not reduce the risk of each road user, as risk may be different from the perspective of each road user. Indeed, minimizing the risk from the AV's perspective may not imply that the risk from the perspective of other road users is also being minimized; in fact, it may even increase. To test this hypothesis, we propose an AV motion planning strategy that supports switching risk minimization strategies between all road user perspectives. We find that the risk from the perspective of other road users can generally be considered different to the risk from the AV's perspective. Taking a collective risk perspective, i.e., balancing the risks of all road users, we observe an AV that minimizes overall traffic risk the best, while putting itself at slightly higher risk for the benefit of others, which is consistent with human driving behavior. In addition, adopting a collective risk minimization strategy can also be beneficial to the AV's travel efficiency by acting assertively when other road users maintain a low risk estimate of the AV. Yet, the AV drives conservatively when its planned actions are less predictable to other road users, i.e., associated with high risk. We argue that such behavior is a form of self-reflection and a natural prerequisite for socially acceptable AV behavior. We conclude that to facilitate ethicality in road traffic that includes AVs, the risk-perspective of each road user must be considered in the decision-making of AVs.",
      "authors": [
        "Leon Tolksdorf",
        "Arturo Tejada",
        "Christian Birkner",
        "Nathan van de Wouw"
      ],
      "published": "2026-02-26T12:30:44Z",
      "updated": "2026-02-26T12:30:44Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22940v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22923v1",
      "title": "WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents",
      "summary": "While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, the ability to bridge the gap between raw visual perception and complex cognitive reasoning is not merely an enhancement but a critical prerequisite for Autonomous Surface Vessels to execute safe and precise maneuvers. To this end, we present WaterVideoQA, the first large-scale, comprehensive Video Question Answering benchmark specifically engineered for all-waterway environments. This benchmark encompasses 3,029 video clips across six distinct waterway categories, integrating multifaceted variables such as volatile lighting and dynamic weather to rigorously stress-test ASV capabilities across a five-tier hierarchical cognitive framework. Furthermore, we introduce NaviMind, a pioneering multi-agent neuro-symbolic system designed for open-ended maritime reasoning. By synergizing Adaptive Semantic Routing, Situation-Aware Hierarchical Reasoning, and Autonomous Self-Reflective Verification, NaviMind transitions ASVs from superficial pattern matching to regulation-compliant, interpretable decision-making. Experimental results demonstrate that our framework significantly transcends existing baselines, establishing a new paradigm for intelligent, trustworthy interaction in dynamic maritime environments.",
      "authors": [
        "Runwei Guan",
        "Shaofeng Liang",
        "Ningwei Ouyang",
        "Weichen Fei",
        "Shanliang Yao",
        "Wei Dai",
        "Chenhao Ge",
        "Penglei Sun",
        "Xiaohui Zhu",
        "Tao Huang",
        "Ryan Wen Liu",
        "Hui Xiong"
      ],
      "published": "2026-02-26T12:12:40Z",
      "updated": "2026-02-26T12:12:40Z",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22923v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22922v1",
      "title": "Bayesian Preference Elicitation: Human-In-The-Loop Optimization of An Active Prosthesis",
      "summary": "Tuning active prostheses for people with amputation is time-consuming and relies on metrics that may not fully reflect user needs. We introduce a human-in-the-loop optimization (HILO) approach that leverages direct user preferences to personalize a standard four-parameter prosthesis controller efficiently. Our method employs preference-based Multiobjective Bayesian Optimization that uses a state-or-the-art acquisition function especially designed for preference learning, and includes two algorithmic variants: a discrete version (\\textit{EUBO-LineCoSpar}), and a continuous version (\\textit{BPE4Prost}). Simulation results on benchmark functions and real-application trials demonstrate efficient convergence, robust preference elicitation, and measurable biomechanical improvements, illustrating the potential of preference-driven tuning for user-centered prosthesis control.",
      "authors": [
        "Sophia Taddei",
        "Wouter Koppen",
        "Eligia Alfio",
        "Stefano Nuzzo",
        "Louis Flynn",
        "Maria Alejandra Diaz",
        "Sebastian Rojas Gonzalez",
        "Tom Dhaene",
        "Kevin De Pauw",
        "Ivo Couckuyt",
        "Tom Verstraten"
      ],
      "published": "2026-02-26T12:11:51Z",
      "updated": "2026-02-26T12:11:51Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22922v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22896v1",
      "title": "DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation",
      "summary": "Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.",
      "authors": [
        "Zebin Yang",
        "Yijiahao Qi",
        "Tong Xie",
        "Bo Yu",
        "Shaoshan Liu",
        "Meng Li"
      ],
      "published": "2026-02-26T11:34:36Z",
      "updated": "2026-02-26T11:34:36Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22896v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22862v1",
      "title": "GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion",
      "summary": "This paper focuses on enhancing the grasping precision and generalization of manipulation policies learned via imitation learning. Diffusion-based policy learning methods have recently become the mainstream approach for robotic manipulation tasks. As grasping is a critical subtask in manipulation, the ability of imitation-learned policies to execute precise and generalizable grasps merits particular attention. Existing imitation learning techniques for grasping often suffer from imprecise grasp executions, limited spatial generalization, and poor object generalization. To address these challenges, we incorporate grasp prior knowledge into the diffusion policy framework. In particular, we employ a latent diffusion policy to guide action chunk decoding with grasp pose prior, ensuring that generated motion trajectories adhere closely to feasible grasp configurations. Furthermore, we introduce a self-supervised reconstruction objective during diffusion to embed the graspness prior: at each reverse diffusion step, we reconstruct wrist-camera images back-projected the graspness from the intermediate representations. Both simulation and real robot experiments demonstrate that our approach significantly outperforms baseline methods and exhibits strong dynamic grasping capabilities.",
      "authors": [
        "Enda Xiang",
        "Haoxiang Ma",
        "Xinzhu Ma",
        "Zicheng Liu",
        "Di Huang"
      ],
      "published": "2026-02-26T10:56:01Z",
      "updated": "2026-02-26T10:56:01Z",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22862v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22854v1",
      "title": "Performance and Experimental Analysis of Strain-based Models for Continuum Robots",
      "summary": "Although strain-based models have been widely adopted in robotics, no comparison beyond the uniform bending test is commonly recognized to assess their performance. In addition, the increasing effort in prototyping continuum robots highlights the need to assess the applicability of these models and the necessity of comprehensive performance evaluation. To address this gap, this work investigates the shape reconstruction abilities of a third-order strain interpolation method, examining its ability to capture both individual and combined deformation effects. These results are compared and discussed against the Geometric-Variable Strain approach. Subsequently, simulation results are experimentally verified by reshaping a slender rod while recording the resulting configurations using cameras. The rod configuration is imposed using a manipulator displacing one of its tips and extracted through reflective markers, without the aid of any other external sensor -- i.e. strain gauges or wrench sensors placed along the rod. The experiments demonstrate good agreement between the model predictions and observed shapes, with average error of 0.58% of the rod length and average computational time of 0.32s per configuration, outperforming existing models.",
      "authors": [
        "Annika Delucchi",
        "Vincenzo Di Paola",
        "Andreas Müller",
        "and Matteo Zoppi"
      ],
      "published": "2026-02-26T10:46:13Z",
      "updated": "2026-02-26T10:46:13Z",
      "categories": [
        "cs.RO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22854v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.22804v1",
      "title": "Communication-Guided Multi-Mutation Differential Evolution for Crop Model Calibration",
      "summary": "In this paper, we propose a multi-mutation optimization algorithm, Differential Evolution with Multi-Mutation Operator-Guided Communication (DE-MMOGC), implemented to improve the performance and convergence abilities of standard differential evolution in uncertain environments. DE-MMOGC introduces a communication-guided scheme integrated with multiple mutation operators to encourage exploration and avoid premature convergence. Along with this, it includes a dynamic operator selection mechanism to use the best-performing operator over successive generations. To assimilate real-world uncertainties and missing observations into the predictive model, the proposed algorithm is combined with the Ensemble Kalman Filter. To evaluate the efficacy of the proposed DE-MMOGC in uncertain systems, the unified framework is applied to improve the predictive accuracy of crop simulation models. These simulation models are essential to precision agriculture, as they make it easier to estimate crop growth in a variety of unpredictable weather scenarios. Additionally, precisely calibrating these models raises a challenge due to missing observations. Hence, the simplified WOFOST crop simulation model is incorporated in this study for leaf area index (LAI)-based crop yield estimation. DE-MMOGC enhances the WOFOST performance by optimizing crucial weather parameters (temperature and rainfall), since these parameters are highly uncertain across different crop varieties, such as wheat, rice, and cotton. The experimental study shows that DE-MMOGC outperforms the traditional evolutionary optimizers and achieves better correlation with real LAI values. We found that DE-MMOGC is a resilient solution for crop monitoring.",
      "authors": [
        "Sakshi Aggarwal",
        "Mudasir Ganaie",
        "Mukesh Saini"
      ],
      "published": "2026-02-26T09:40:58Z",
      "updated": "2026-02-26T09:40:58Z",
      "categories": [
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22804v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22173v1",
      "title": "Applying a Random-Key Optimizer on Mixed Integer Programs",
      "summary": "Mixed-Integer Programs (MIPs) are NP-hard optimization models that arise in a broad range of decision-making applications, including finance, logistics, energy systems, and network design. Although modern commercial solvers have achieved remarkable progress and perform effectively on many small- and medium-sized instances, their performance often degrades when confronted with large-cale or highly constrained formulations. This paper explores the use of the Random-Key Optimizer (RKO) framework as a flexible, metaheuristic alternative for computing high-quality solutions to MIPs through the design of problem-specific decoders. The proposed approach separates the search process from feasibility enforcement by operating in a continuous random-key space while mapping candidate solutions to feasible integer solutions via efficient decoding procedures. We evaluate the methodology on two representative and structurally distinct benchmark problems: the mean-variance Markowitz portfolio optimization problem with buy-in and cardinality constraints, and the Time-Dependent Traveling Salesman Problem. For each formulation, tailored decoders are developed to reduce the effective search space, promote feasibility, and accelerate convergence. Computational experiments demonstrate that RKO consistently produces competitive, and in several cases superior, solutions compared to a state-of-the-art commercial MIP solver, both in terms of solution quality and computational time. These results highlight the potential of RKO as a scalable and versatile heuristic framework for tackling challenging large-scale MIPs.",
      "authors": [
        "Antonio A. Chaves",
        "Mauricio G. C. Resende",
        "Carise E. Schmidt",
        "J. Kyle Brubaker",
        "Helmut G. Katzgraber"
      ],
      "published": "2026-02-25T18:20:03Z",
      "updated": "2026-02-25T18:20:03Z",
      "categories": [
        "math.OC",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22173v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22152v1",
      "title": "Stream Neural Networks: Epoch-Free Learning with Persistent Temporal State",
      "summary": "Most contemporary neural learning systems rely on epoch-based optimization and repeated access to historical data, implicitly assuming reversible computation. In contrast, real-world environments often present information as irreversible streams, where inputs cannot be replayed or revisited. Under such conditions, conventional architectures degrade into reactive filters lacking long-horizon coherence. This paper introduces Stream Neural Networks (StNN), an execution paradigm designed for irreversible input streams. StNN operates through a stream-native execution algorithm, the Stream Network Algorithm (SNA), whose fundamental unit is the stream neuron. Each stream neuron maintains a persistent temporal state that evolves continuously across inputs. We formally establish three structural guarantees: (1) stateless mappings collapse under irreversibility and cannot encode temporal dependencies; (2) persistent state dynamics remain bounded under mild activation constraints; and (3) the state transition operator is contractive for λ &lt; 1, ensuring stable long-horizon execution. Empirical phase-space analysis and continuous tracking experiments validate these theoretical results. The execution principles introduced in this work define a minimal substrate for neural computation under irreversible streaming constraints.",
      "authors": [
        "Amama Pathan"
      ],
      "published": "2026-02-25T18:00:17Z",
      "updated": "2026-02-25T18:00:17Z",
      "categories": [
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22152v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21995v1",
      "title": "Outpatient Appointment Scheduling Optimization with a Genetic Algorithm Approach",
      "summary": "The optimization of complex medical appointment scheduling remains a significant operational challenge in multi-center healthcare environments, where clinical safety protocols and patient logistics must be reconciled. This study proposes and evaluates a Genetic Algorithm (GA) framework designed to automate the scheduling of multiple medical acts while adhering to rigorous inter-procedural incompatibility rules. Using a synthetic dataset encompassing 50 medical acts across four healthcare facilities, we compared two GA variants, Pre-Ordered and Unordered, against deterministic First-Come, First-Served (FCFS) and Random Choice baselines. Our results demonstrate that the GA framework achieved a 100% constraint fulfillment rate, effectively resolving temporal overlaps and clinical incompatibilities that the FCFS baseline failed to address in 60% and 40% of cases, respectively. Furthermore, the GA variants demonstrated statistically significant improvements (p &lt; 0.001) in patient-centric metrics, achieving an Idle Time Ratio (ITR) frequently below 0.4 and reducing inter-healthcenter trips. While the GA (Ordered) variant provided a superior initial search locus, both evolutionary models converged to comparable global optima by the 100th generation. These findings suggest that transitioning from manual, human-mediated scheduling to an automated metaheuristic approach enhances clinical integrity, reduces administrative overhead, and significantly improves the patient experience by minimizing wait times and logistical burdens.",
      "authors": [
        "Ana Rodrigues",
        "Rui Rego"
      ],
      "published": "2026-02-25T15:15:57Z",
      "updated": "2026-02-25T15:15:57Z",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21995v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21761v1",
      "title": "Survey on Neural Routing Solvers",
      "summary": "Neural routing solvers (NRSs) that leverage deep learning to tackle vehicle routing problems have demonstrated notable potential for practical applications. By learning implicit heuristic rules from data, NRSs replace the handcrafted counterparts in classic heuristic frameworks, thereby reducing reliance on costly manual design and trial-and-error adjustments. This survey makes two main contributions: (1) The heuristic nature of NRSs is highlighted, and existing NRSs are reviewed from the perspective of heuristics. A hierarchical taxonomy based on heuristic principles is further introduced. (2) A generalization-focused evaluation pipeline is proposed to address limitations of the conventional pipeline. Comparative benchmarking of representative NRSs across both pipelines uncovers a series of previously unreported gaps in current research.",
      "authors": [
        "Yunpeng Ba",
        "Xi Lin",
        "Changliang Zhou",
        "Ruihao Zheng",
        "Zhenkun Wang",
        "Xinyan Liang",
        "Zhichao Lu",
        "Jianyong Sun",
        "Yuhua Qian",
        "Qingfu Zhang"
      ],
      "published": "2026-02-25T10:24:43Z",
      "updated": "2026-02-25T10:24:43Z",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21761v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22260v1",
      "title": "Code World Models for Parameter Control in Evolutionary Algorithms",
      "summary": "Can an LLM learn how an optimizer behaves -- and use that knowledge to control it? We extend Code World Models (CWMs), LLM-synthesized Python programs that predict environment dynamics, from deterministic games to stochastic combinatorial optimization. Given suboptimal trajectories of $(1{+}1)$-$\\text{RLS}_k$, the LLM synthesizes a simulator of the optimizer's dynamics; greedy planning over this simulator then selects the mutation strength $k$ at each step. On \\lo{} and \\onemax{}, CWM-greedy performs within 6\\% of the theoretically optimal policy -- without ever seeing optimal-policy trajectories. On \\jump{$_k$}, where a deceptive valley causes all adaptive baselines to fail (0\\% success rate), CWM-greedy achieves 100\\% success rate -- without any collection policy using oracle knowledge of the gap parameter. On the NK-Landscape, where no closed-form model exists, CWM-greedy outperforms all baselines across fifteen independently generated instances ($36.94$ vs.\\ $36.32$; $p&lt;0.001$) when the prompt includes empirical transition statistics. The CWM also outperforms DQN in sample efficiency (200 offline trajectories vs.\\ 500 online episodes), success rate (100\\% vs.\\ 58\\%), and generalization ($k{=}3$: 78\\% vs.\\ 0\\%). Robustness experiments confirm stable synthesis across 5 independent runs.",
      "authors": [
        "Camilo Chacón Sartori",
        "Guillem Rodríguez Corominas"
      ],
      "published": "2026-02-25T01:49:29Z",
      "updated": "2026-02-25T01:49:29Z",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22260v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.20846v1",
      "title": "Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization",
      "summary": "Standard game theory explains cooperation in repeated games through conditional strategies such as Tit-for-Tat (TfT), but these require continuous computation that imposes physical costs on embodied agents. We propose a three-layer Body-Reservoir Governance (BRG) architecture: (1) a body reservoir (echo state network) whose $d$-dimensional state performs implicit inference over interaction history, serving as both decision-maker and anomaly detector, (2) a cognitive filter providing costly strategic tools activated on demand, and (3) a metacognitive governance layer with receptivity parameter $α\\in [0,1]$. At full body governance ($α=1$), closed-loop dynamics satisfy a self-consistency equation: cooperation is expressed as the reservoir's fixed point, not computed. Strategy complexity cost is defined as the KL divergence between the reservoir's state distribution and its habituated baseline. Body governance reduces this cost, with action variance decreasing up to $1600\\times$ with dimension $d$. A dynamic sentinel generates a composite discomfort signal from the reservoir's own state, driving adaptive $α(t)$: near baseline during cooperation, rapidly dropping upon defection to activate cognitive retaliation. Overriding the body incurs thermodynamic cost proportional to internal state distortion. The sentinel achieves the highest payoff across all conditions, outperforming static body governance, TfT, and EMA baselines. A dimension sweep ($d \\in \\{5,\\ldots,100\\}$) shows implicit inference scales with bodily richness ($23\\times$ to $1600\\times$ variance reduction), attributable to reservoir dynamics. A phase diagram in $(d, τ_{\\mathrm{env}})$ space reveals governance regime transitions near $d \\approx 20$. The framework reinterprets cooperation as the minimum-dissipation response of an adapted dynamical system -- emergent from embodied dynamics rather than computed.",
      "authors": [
        "Yuki Nakamura"
      ],
      "published": "2026-02-24T12:36:41Z",
      "updated": "2026-02-24T12:36:41Z",
      "categories": [
        "cs.GT",
        "cs.MA",
        "cs.NE",
        "nlin.AO"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20846v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.20133v1",
      "title": "AdaEvolve: Adaptive LLM Driven Zeroth-Order Optimization",
      "summary": "The paradigm of automated program generation is shifting from one-shot generation to inference-time search, where Large Language Models (LLMs) function as semantic mutation operators within evolutionary loops. While effective, these systems are currently governed by static schedules that fail to account for the non-stationary dynamics of the search process. This rigidity results in substantial computational waste, as resources are indiscriminately allocated to stagnating populations while promising frontiers remain under-exploited. We introduce AdaEvolve, a framework that reformulates LLM-driven evolution as a hierarchical adaptive optimization problem. AdaEvolve uses an \"accumulated improvement signal\" to unify decisions across three levels: Local Adaptation, which dynamically modulates the exploration intensity within a population of solution candidates; Global Adaptation, which routes the global resource budget via bandit-based scheduling across different solution candidate populations; and Meta-Guidance which generates novel solution tactics based on the previously generated solutions and their corresponding improvements when the progress stalls. We demonstrate that AdaEvolve consistently outperforms the open-sourced baselines across 185 different open-ended optimization problems including combinatorial, systems optimization and algorithm design problems.",
      "authors": [
        "Mert Cemri",
        "Shubham Agrawal",
        "Akshat Gupta",
        "Shu Liu",
        "Audrey Cheng",
        "Qiuyang Mang",
        "Ashwin Naren",
        "Lutfi Eren Erdogan",
        "Koushik Sen",
        "Matei Zaharia",
        "Alex Dimakis",
        "Ion Stoica"
      ],
      "published": "2026-02-23T18:45:31Z",
      "updated": "2026-02-23T18:45:31Z",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20133v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.19802v1",
      "title": "Linear Reservoir: A Diagonalization-Based Optimization",
      "summary": "We introduce a diagonalization-based optimization for Linear Echo State Networks (ESNs) that reduces the per-step computational complexity of reservoir state updates from O(N^2) to O(N). By reformulating reservoir dynamics in the eigenbasis of the recurrent matrix, the recurrent update becomes a set of independent element-wise operations, eliminating the matrix multiplication. We further propose three methods to use our optimization depending on the situation: (i) Eigenbasis Weight Transformation (EWT), which preserves the dynamics of standard and trained Linear ESNs, (ii) End-to-End Eigenbasis Training (EET), which directly optimizes readout weights in the transformed space and (iii) Direct Parameter Generation (DPG), that bypasses matrix diagonalization by directly sampling eigenvalues and eigenvectors, achieving comparable performance than standard Linear ESNs. Across all experiments, both our methods preserve predictive accuracy while offering significant computational speedups, making them a replacement of standard Linear ESNs computations and training, and suggesting a shift of paradigm in linear ESN towards the direct selection of eigenvalues.",
      "authors": [
        "Romain de Coudenhove",
        "Yannis Bendi-Ouis",
        "Anthony Strock",
        "Xavier Hinaut"
      ],
      "published": "2026-02-23T12:58:34Z",
      "updated": "2026-02-23T12:58:34Z",
      "categories": [
        "cs.DC",
        "cs.NE",
        "math.CV",
        "math.DS"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19802v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.19785v1",
      "title": "Unsupervised Anomaly Detection in NSL-KDD Using $β$-VAE: A Latent Space and Reconstruction Error Approach",
      "summary": "As Operational Technology increasingly integrates with Information Technology, the need for Intrusion Detection Systems becomes more important. This paper explores an unsupervised approach to anomaly detection in network traffic using $β$-Variational Autoencoders on the NSL-KDD dataset. We investigate two methods: leveraging the latent space structure by measuring distances from test samples to the training data projections, and using the reconstruction error as a conventional anomaly detection metric. By comparing these approaches, we provide insights into their respective advantages and limitations in an unsupervised setting. Experimental results highlight the effectiveness of latent space exploitation for classification tasks.",
      "authors": [
        "Dylan Baptiste",
        "Ramla Saddem",
        "Alexandre Philippot",
        "François Foyer"
      ],
      "published": "2026-02-23T12:42:00Z",
      "updated": "2026-02-23T12:42:00Z",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19785v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.19331v1",
      "title": "Partial Soft-Matching Distance for Neural Representational Comparison with Partial Unit Correspondence",
      "summary": "Representational similarity metrics typically force all units to be matched, making them susceptible to noise and outliers common in neural representations. We extend the soft-matching distance to a partial optimal transport setting that allows some neurons to remain unmatched, yielding rotation-sensitive but robust correspondences. This partial soft-matching distance provides theoretical advantages -- relaxing strict mass conservation while maintaining interpretable transport costs -- and practical benefits through efficient neuron ranking in terms of cross-network alignment without costly iterative recomputation. In simulations, it preserves correct matches under outliers and reliably selects the correct model in noise-corrupted identification tasks. On fMRI data, it automatically excludes low-reliability voxels and produces voxel rankings by alignment quality that closely match computationally expensive brute-force approaches. It achieves higher alignment precision across homologous brain areas than standard soft-matching, which is forced to match all units regardless of quality. In deep networks, highly matched units exhibit similar maximally exciting images, while unmatched units show divergent patterns. This ability to partition by match quality enables focused analyses, e.g., testing whether networks have privileged axes even within their most aligned subpopulations. Overall, partial soft-matching provides a principled and practical method for representational comparison under partial correspondence.",
      "authors": [
        "Chaitanya Kapoor",
        "Alex H. Williams",
        "Meenakshi Khosla"
      ],
      "published": "2026-02-22T20:31:35Z",
      "updated": "2026-02-22T20:31:35Z",
      "categories": [
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19331v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.19268v1",
      "title": "CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications",
      "summary": "This brief presents a runtime-adaptive, performance-enhanced vector engine featuring a low-resource, iterative CORDIC-based MAC unit for edge AI acceleration. The proposed design enables dynamic reconfiguration between approximate and accurate modes, exploiting the latency-accuracy trade-off for a wide range of workloads. Its resource-efficient approach further enables up to 4x throughput improvement within the same hardware resources by leveraging vectorised, time-multiplexed execution and flexible precision scaling. With a time-multiplexed multi-AF block and a lightweight pooling and normalisation unit, the proposed vector engine supports flexible precision (4/8/16-bit) and high MAC density. The ASIC implementation results show that each MAC stage can save up to 33% of time and 21% of power, with a 256-PE configuration that achieves higher compute density (4.83 TOPS/mm2 ) and energy efficiency (11.67 TOPS/W) than previous state-of-the-art work. A detailed hardware-software co-design methodology for object detection and classification tasks on Pynq-Z2 is discussed to assess the proposed architecture, demonstrating a scalable, energy-efficient solution for edge AI applications.",
      "authors": [
        "Sonu Kumar",
        "Mohd Faisal Khan",
        "Mukul Lokhande",
        "Santosh Kumar Vishvakarma"
      ],
      "published": "2026-02-22T16:51:17Z",
      "updated": "2026-02-22T16:51:17Z",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "eess.IV"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19268v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.19261v1",
      "title": "DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation",
      "summary": "Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.",
      "authors": [
        "Aleksei Liuliakov",
        "Luca Hermes",
        "Barbara Hammer"
      ],
      "published": "2026-02-22T16:23:42Z",
      "updated": "2026-02-22T16:23:42Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19261v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.19253v1",
      "title": "Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems",
      "summary": "Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.",
      "authors": [
        "Qusai Khaled",
        "Uzay Kaymak",
        "Laura Genga"
      ],
      "published": "2026-02-22T16:08:06Z",
      "updated": "2026-02-22T16:08:06Z",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.19253v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.18989v1",
      "title": "All Constant Mutation Rates for the $(1+1)$ Evolutionary Algorithm",
      "summary": "For every mutation rate $p \\in (0, 1)$, and for all $\\varepsilon &gt; 0$, there is a fitness function $f : \\{0,1\\}^n \\to \\mathbb{R}$ with a unique maximum for which the optimal mutation rate for the $(1+1)$ evolutionary algorithm on $f$ is in $(p-\\varepsilon, p+\\varepsilon)$. In other words, the set of optimal mutation rates for the $(1+1)$ EA is dense in the interval $[0, 1]$. To show that, this paper introduces DistantSteppingStones, a fitness function which consists of large plateaus separated by large fitness valleys.",
      "authors": [
        "Andrew James Kelley"
      ],
      "published": "2026-02-22T00:30:45Z",
      "updated": "2026-02-22T00:30:45Z",
      "categories": [
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18989v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.18960v1",
      "title": "Modularity is the Bedrock of Natural and Artificial Intelligence",
      "summary": "The remarkable performance of modern AI systems has been driven by unprecedented scales of data, computation, and energy -- far exceeding the resources required by human intelligence. This disparity highlights the need for new guiding principles and motivates drawing inspiration from the fundamental organizational principles of brain computation. Among these principles, modularity has been shown to be critical for supporting the efficient learning and strong generalization abilities consistently exhibited by humans. Furthermore, modularity aligns well with the No Free Lunch Theorem, which highlights the need for problem-specific inductive biases and motivates architectures composed of specialized components that solve subproblems. However, despite its fundamental role in natural intelligence and its demonstrated benefits across a range of seemingly disparate AI subfields, modularity remains relatively underappreciated in mainstream AI research. In this work, we review several research threads in artificial intelligence and neuroscience through a conceptual framework that highlights the central role of modularity in supporting both artificial and natural intelligence. In particular, we examine what computational advantages modularity provides, how it has emerged as a solution across several AI research areas, which modularity principles the brain exploits, and how modularity can help bridge the gap between natural and artificial intelligence.",
      "authors": [
        "Alessandro Salatiello"
      ],
      "published": "2026-02-21T21:47:09Z",
      "updated": "2026-02-21T21:47:09Z",
      "categories": [
        "cs.AI",
        "cs.NE",
        "q-bio.NC"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18960v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.18948v1",
      "title": "Toward Manifest Relationality in Transformers via Symmetry Reduction",
      "summary": "Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.",
      "authors": [
        "J. François",
        "L. Ravera"
      ],
      "published": "2026-02-21T19:43:17Z",
      "updated": "2026-02-21T19:43:17Z",
      "categories": [
        "cs.LG",
        "cs.NE",
        "hep-th",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18948v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.18674v1",
      "title": "Robustness of Deep ReLU Networks to Misclassification of High-Dimensional Data",
      "summary": "We present a theoretical study of the robustness of parameterized networks to random input perturbations. Specifically, we analyze local robustness at a given network input by quantifying the probability that a small additive random perturbation of the input leads to misclassification. For deep networks with rectified linear units, we derive lower bounds on local robustness in terms of the input dimensionality and the total number of network units.",
      "authors": [
        "Věra Kůrková"
      ],
      "published": "2026-02-21T00:55:47Z",
      "updated": "2026-02-21T00:55:47Z",
      "categories": [
        "cs.LG",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18674v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.18635v1",
      "title": "Musical Training, but not Mere Exposure to Music, Drives the Emergence of Chroma Equivalence in Artificial Neural Networks",
      "summary": "Pitch is a fundamental aspect of auditory perception. Pitch perception is commonly described across two perceptual dimensions: pitch height is the sense that tones with varying frequencies seem to be higher or lower, and chroma equivalence is the cyclical similarity of notes octaves, corresponding to a doubling of fundamental frequency. Existing research is divided on whether chroma equivalence is a learned percept that varies according to musical experience and culture, or is an innate percept that develops automatically. Building on a recent framework that proposes to use ANNs to ask 'why' questions about the brain, we evaluated recent auditory ANNs using representational similarity analysis to test the emergence of pitch height and chroma equivalence in their learned representations. Additionally, we fine-tuned two models, Wav2Vec 2.0 and Data2Vec, on a self-supervised learning task using speech and music, and a supervised music transcription task. We found that all models exhibited varying degrees of pitch height representation, but that only models trained on the supervised music transcription task exhibited chroma equivalence. Mere exposure to music through self-supervised learning was not sufficient for chroma equivalence to emerge. This supports the view that chroma equivalence is a higher-order cognitive computation that emerges to support the specific task of music perception, distinct from other auditory perception such as speech listening. This work also highlights the usefulness of ANNs for probing the developmental conditions that give rise to perceptual representations in humans.",
      "authors": [
        "Lukas Grasse",
        "Matthew S. Tata"
      ],
      "published": "2026-02-20T22:07:01Z",
      "updated": "2026-02-20T22:07:01Z",
      "categories": [
        "cs.SD",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18635v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.18140v1",
      "title": "Flexi-NeurA: A Configurable Neuromorphic Accelerator with Adaptive Bit-Precision Exploration for Edge SNNs",
      "summary": "Neuromorphic accelerators promise unparalleled energy efficiency and computational density for spiking neural networks (SNNs), especially in edge intelligence applications. However, most existing platforms exhibit rigid architectures with limited configurability, restricting their adaptability to heterogeneous workloads and diverse design objectives. To address these limitations, we present Flexi-NeurA -- a parameterizable neuromorphic accelerator (core) that unifies configurability, flexibility, and efficiency. Flexi-NeurA allows users to customize neuron models, network structures, and precision settings at design time. By pairing these design-time configurability and flexibility features with a time-multiplexed and event-driven processing approach, Flexi-NeurA substantially reduces the required hardware resources and total power while preserving high efficiency and low inference latency. Complementing this, we introduce Flex-plorer, a heuristic-guided design-space exploration (DSE) tool that determines cost-effective fixed-point precisions for critical parameters -- such as decay factors, synaptic weights, and membrane potentials -- based on user-defined trade-offs between accuracy and resource usage. Based on the configuration selected through the Flex-plorer process, RTL code is configured to match the specified design. Comprehensive evaluations across MNIST, SHD, and DVS benchmarks demonstrate that the Flexi-NeurA and Flex-plorer co-framework achieves substantial improvements in accuracy, latency, and energy efficiency. A three-layer 256--128--10 fully connected network with LIF neurons mapped onto two processing cores achieves 97.23% accuracy on MNIST with 1.1~ms inference latency, utilizing only 1,623 logic cells, 7 BRAMs, and 111~mW of total power -- establishing Flexi-NeurA as a scalable, edge-ready neuromorphic platform.",
      "authors": [
        "Mohammad Farahani",
        "Mohammad Rasoul Roshanshah",
        "Saeed Safari"
      ],
      "published": "2026-02-20T11:01:09Z",
      "updated": "2026-02-20T11:01:09Z",
      "categories": [
        "cs.AR",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18140v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.18042v1",
      "title": "PINEAPPLE: Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter Inference in Lithium-Ion Battery Electrodes",
      "summary": "Accurate, real-time, yet non-destructive estimation of internal states in lithium-ion batteries is critical for predicting degradation, optimizing usage strategies, and extending operational lifespan. Here, we introduce PINEAPPLE (Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter inference in Lithium-ion battery Electrodes), a novel framework that integrates physics-informed neural networks (PINNs) with an evolutionary search algorithm to enable rapid, scalable, and interpretable parameter inference with potential for application to next-generation batteries. The meta-learned PINN utilizes fundamental physics principles to achieve accurate zero-shot prediction of electrode behavior with test errors below 0.1$\\%$ while maintaining an order-of-magnitude speed-up over conventional solvers. PINEAPPLE demonstrates robust parameter inference solely from voltage-time discharge curves across multiple batteries from the open-source CALCE repository, recovering the evolution of key internal state parameters such as Li-ion diffusion coefficients across usage cycles. Notably, the inferred cycle-dependent evolution of these parameters exhibit consistent trends across different batteries without any customized degradation physics-embedded heuristic, highlighting the effective regularizing effect and robustness that can be conferred through incorporation of fundamental physics in PINEAPPLE. By enabling computationally efficient, real-time parameter estimation, PINEAPPLE offers a promising route towards the non-destructive, physics-based characterization of inter-cell and intra-cell variability of battery modules and battery packs, thereby unlocking new opportunities for downstream on-the-fly needs in next-generation battery management systems such as individual cell-scale state-of-health diagnostics.",
      "authors": [
        "Karkulali Pugalenthi",
        "Jian Cheng Wong",
        "Qizheng Yang",
        "Pao-Hsiung Chiu",
        "My Ha Dao",
        "Nagarajan Raghavan",
        "Chinchun Ooi"
      ],
      "published": "2026-02-20T07:51:59Z",
      "updated": "2026-02-20T07:51:59Z",
      "categories": [
        "cs.CE",
        "cs.NE",
        "physics.comp-ph"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18042v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.16829v1",
      "title": "Learning under noisy supervision is governed by a feedback-truth gap",
      "summary": "When feedback is absorbed faster than task structure can be evaluated, the learner will favor feedback over truth. A two-timescale model shows this feedback-truth gap is inevitable whenever the two rates differ and vanishes only when they match. We test this prediction across neural networks trained with noisy labels (30 datasets, 2,700 runs), human probabilistic reversal learning (N = 292), and human reward/punishment learning with concurrent EEG (N = 25). In each system, truth is defined operationally: held-out labels, the objectively correct option, or the participant's pre-feedback expectation - the only non-circular reference decodable from post-feedback EEG. The gap appeared universally but was regulated differently: dense networks accumulated it as memorization; sparse-residual scaffolding suppressed it; humans generated transient over-commitment that was actively recovered. Neural over-commitment (~0.04-0.10) was amplified tenfold into behavioral commitment (d = 3.3-3.9). The gap is a fundamental constraint on learning under noisy supervision; its consequences depend on the regulation each system employs.",
      "authors": [
        "Elan Schonfeld",
        "Elias Wisnia"
      ],
      "published": "2026-02-18T19:50:56Z",
      "updated": "2026-02-18T19:50:56Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.16829v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.18508v1",
      "title": "Parallelizable Neural Turing Machines",
      "summary": "We introduce a parallelizable simplification of Neural Turing Machine (NTM), referred to as P-NTM, which redesigns the core operations of the original architecture to enable efficient scan-based parallel execution. We evaluate the proposed architecture on a synthetic benchmark of algorithmic problems involving state tracking, memorization, and basic arithmetic, solved via autoregressive decoding. We compare it against a revisited stable implementation of the standard NTM, as well as conventional recurrent and attention-based architectures. Results show that, despite its simplifications, the proposed model attains length generalization performance comparable to the original, learning to solve all problems, including unseen sequence lengths, with perfect accuracy. It also improves training efficiency, with parallel execution of P-NTM being up to an order of magnitude faster than the standard NTM. Ultimately, this work contributes toward the development of efficient neural architectures capable of expressing a broad class of algorithms.",
      "authors": [
        "Gabriel Faria",
        "Arnaldo Candido Junior"
      ],
      "published": "2026-02-18T17:43:51Z",
      "updated": "2026-02-18T17:43:51Z",
      "categories": [
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18508v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.18507v1",
      "title": "Fine-Pruning: A Biologically Inspired Algorithm for Personalization of Machine Learning Models",
      "summary": "Neural networks have long strived to emulate the learning capabilities of the human brain. While deep neural networks (DNNs) draw inspiration from the brain in neuron design, their training methods diverge from biological foundations. Backpropagation, the primary training method for DNNs, requires substantial computational resources and fully labeled datasets, presenting major bottlenecks in development and application. This work demonstrates that by returning to biomimicry, specifically mimicking how the brain learns through pruning, we can solve various classical machine learning problems while utilizing orders of magnitude fewer computational resources and no labels. Our experiments successfully personalized multiple speech recognition and image classification models, including ResNet50 on ImageNet, resulting in increased sparsity of approximately 70\\% while simultaneously improving model accuracy to around 90\\%, all without the limitations of backpropagation. This biologically inspired approach offers a promising avenue for efficient, personalized machine learning models in resource-constrained environments.",
      "authors": [
        "Joseph Bingham",
        "Saman Zonouz",
        "Dvir Aran"
      ],
      "published": "2026-02-18T13:23:56Z",
      "updated": "2026-02-18T13:23:56Z",
      "categories": [
        "cs.NE",
        "q-bio.NC"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.18507v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.16321v1",
      "title": "End-user validation of BRIGHT with custom-developed graphical user interface applied to cervical cancer brachytherapy",
      "summary": "Multi-objective optimisation using BRIGHT has proven insightful and effective in prostate cancer brachytherapy treatment planning. BRachytherapy via artificially Intelligent GOMEA-Heuristic based Treatment planning (BRIGHT) generates multiple treatment plans, each with a different trade-off between tumour coverage and organs-at-risk sparing. BRIGHT was recently extended to cervical cancer brachytherapy. In this study, we present a novel, custom-developed graphical user interface (GUI) that enables plan navigation, pairwise comparisons, dose distribution visualisation, and possibility for adjustments - essential for efficient clinical use of BRIGHT. End-user validation of BRIGHT with the dedicated GUI was conducted for cervical cancer brachytherapy by emulating clinical practice in ten previously treated patients. A multidisciplinary brachytherapy team used BRIGHT to create new treatment plans. GUI usability was assessed using the System Usability Scale (SUS). BRIGHT plan quality was compared to clinical practice via blinded one-on-one comparisons. The GUI offered helpful features for plan navigation and evaluation, giving users quick insight into whether planning aims are achievable and what treatment options are available. The overall SUS score was 83.3, indicating an 'excellent' system. BRIGHT outperformed clinical practice in five out of ten patients regarding the coverage-sparing trade-off and performed equally well in the remaining five. The BRIGHT plan was preferred over the clinical plan in eight out of ten patients, four of which showed clinically relevant differences. The clinical plan was preferred in two patients, neither with clinically relevant differences. In conclusion, BRIGHT, with its dedicated GUI, is a clinically viable and user-friendly tool for treatment planning in cervical cancer brachytherapy.",
      "authors": [
        "Leah R. M. Dickhoff",
        "Ellen M. Kerkhof",
        "Heloisa H. Deuzeman",
        "Laura A. Velema",
        "Stephanie M. de Boer",
        "Lavinia A. L. Verhagen",
        "Danique L. J. Barten",
        "Bradley R. Pieters",
        "Lukas J. A. Stalpers",
        "Renzo J. Scholman",
        "Pedro M. Matos",
        "Anton Bouter",
        "Carien L. Creutzberg",
        "Peter A. N. Bosman",
        "Tanja Alderliesten"
      ],
      "published": "2026-02-18T10:01:21Z",
      "updated": "2026-02-18T10:01:21Z",
      "categories": [
        "cs.NE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.16321v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22942v1",
      "title": "ClawMobile: Rethinking Smartphone-Native Agentic Systems",
      "summary": "Smartphones represent a uniquely challenging environment for agentic systems. Unlike cloud or desktop settings, mobile devices combine constrained execution contexts, fragmented control interfaces, and rapidly changing application states. As large language models (LLMs) evolve from conversational assistants to action-oriented agents, achieving reliable smartphone-native autonomy requires rethinking how reasoning and control are composed. We introduce ClawMobile as a concrete exploration of this design space. ClawMobile adopts a hierarchical architecture that separates high-level language reasoning from structured, deterministic control pathways, improving execution stability and reproducibility on real devices. Using ClawMobile as a case study, we distill the design principles for mobile LLM runtimes and identify key challenges in efficiency, adaptability, and stability. We argue that building robust smartphone-native agentic systems demands principled coordination between probabilistic planning and deterministic system interfaces. The implementation is open-sourced~\\footnote{https://github.com/ClawMobile/ClawMobile} to facilitate future exploration.",
      "authors": [
        "Hongchao Du",
        "Shangyu Wu",
        "Qiao Li",
        "Riwei Pan",
        "Jinheng Li",
        "Youcheng Sun",
        "Chun Jason Xue"
      ],
      "published": "2026-02-26T12:34:57Z",
      "updated": "2026-02-26T12:34:57Z",
      "categories": [
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22942v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22915v1",
      "title": "Robust Information Design for Multi-Agent Systems with Complementarities: Smallest-Equilibrium Threshold Policies",
      "summary": "We study information design in multi-agent systems (MAS) with binary actions and strategic complementarities, where an external designer influences behavior only through signals. Agents play the smallest-equilibrium of the induced Bayesian game, reflecting conservative, coordination-averse behavior typical in distributed systems. We show that when utilities admit a convex potential and welfare is convex, the robustly implementable optimum has a remarkably simple form: perfect coordination at each state: either everyone acts or no one does. We provide a constructive threshold rule: compute a one-dimensional score for each state, sort states, and pick a single threshold (with a knife-edge lottery for at most one state). This rule is an explicit optimal vertex of a linear program (LP) characterized by feasibility and sequential obedience constraints. Empirically, in both vaccination and technology-adoption domains, our constructive policy matches LP optima, scales as $O(|Θ|\\log|Θ|)$, and avoids the inflated welfare predicted by obedience-only designs that assume the designer can dictate the (best) equilibrium. The result is a general, scalable recipe for robust coordination in MAS with complementarities.",
      "authors": [
        "Farzaneh Farhadi",
        "Maria Chli"
      ],
      "published": "2026-02-26T12:03:16Z",
      "updated": "2026-02-26T12:03:16Z",
      "categories": [
        "cs.GT",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22915v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22786v1",
      "title": "QSIM: Mitigating Overestimation in Multi-Agent Reinforcement Learning via Action Similarity Weighted Q-Learning",
      "summary": "Value decomposition (VD) methods have achieved remarkable success in cooperative multi-agent reinforcement learning (MARL). However, their reliance on the max operator for temporal-difference (TD) target calculation leads to systematic Q-value overestimation. This issue is particularly severe in MARL due to the combinatorial explosion of the joint action space, which often results in unstable learning and suboptimal policies. To address this problem, we propose QSIM, a similarity weighted Q-learning framework that reconstructs the TD target using action similarity. Instead of using the greedy joint action directly, QSIM forms a similarity weighted expectation over a structured near-greedy joint action space. This formulation allows the target to integrate Q-values from diverse yet behaviorally related actions while assigning greater influence to those that are more similar to the greedy choice. By smoothing the target with structurally relevant alternatives, QSIM effectively mitigates overestimation and improves learning stability. Extensive experiments demonstrate that QSIM can be seamlessly integrated with various VD methods, consistently yielding superior performance and stability compared to the original algorithms. Furthermore, empirical analysis confirms that QSIM significantly mitigates the systematic value overestimation in MARL. Code is available at https://github.com/MaoMaoLYJ/pymarl-qsim.",
      "authors": [
        "Yuanjun Li",
        "Bin Zhang",
        "Hao Chen",
        "Zhouyang Jiang",
        "Dapeng Li",
        "Zhiwei Xu"
      ],
      "published": "2026-02-26T09:20:46Z",
      "updated": "2026-02-26T09:20:46Z",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22786v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22365v1",
      "title": "Sustainable Multi-Agent Crowdsourcing via Physics-Informed Bandits",
      "summary": "Crowdsourcing platforms face a four-way tension between allocation quality, workforce sustainability, operational feasibility, and strategic contractor behaviour--a dilemma we formalise as the Cold-Start, Burnout, Utilisation, and Strategic Agency Dilemma. Existing methods resolve at most two of these tensions simultaneously: greedy heuristics and multi-criteria decision making (MCDM) methods achieve Day-1 quality but cause catastrophic burnout, while bandit algorithms eliminate burnout only through operationally infeasible 100% workforce utilisation.To address this, we introduce FORGE, a physics-grounded $K+1$ multi-agent simulator in which each contractor is a rational agent that declares its own load-acceptance threshold based on its fatigue state, converting the standard passive Restless Multi-Armed Bandit (RMAB) into a genuine Stackelberg game. Operating within FORGE, we propose a Neural-Linear UCB allocator that fuses a Two-Tower embedding network with a Physics-Informed Covariance Prior derived from offline simulator interactions. The prior simultaneously warm-starts skill-cluster geometry and UCB exploration landscape, providing a geometry-aware belief state from episode 1 that measurably reduces cold-start regret.Over $T = 200$ cold-start episodes, the proposed method achieves the highest reward of all non-oracle methods ($\\text{LRew} = 0.555 \\pm 0.041$) at only 7.6% workforce utilisation--a combination no conventional baseline achieves--while maintaining robustness to workforce turnover up to 50% and observation noise up to $σ= 0.20$.",
      "authors": [
        "Chayan Banerjee"
      ],
      "published": "2026-02-25T19:52:00Z",
      "updated": "2026-02-25T19:52:00Z",
      "categories": [
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22365v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22302v1",
      "title": "Agent Behavioral Contracts: Formal Specification and Runtime Enforcement for Reliable Autonomous AI Agents",
      "summary": "Traditional software relies on contracts -- APIs, type systems, assertions -- to specify and enforce correct behavior. AI agents, by contrast, operate on prompts and natural language instructions with no formal behavioral specification. This gap is the root cause of drift, governance failures, and frequent project failures in agentic AI deployments. We introduce Agent Behavioral Contracts (ABC), a formal framework that brings Design-by-Contract principles to autonomous AI agents. An ABC contract C = (P, I, G, R) specifies Preconditions, Invariants, Governance policies, and Recovery mechanisms as first-class, runtime-enforceable components. We define (p, delta, k)-satisfaction -- a probabilistic notion of contract compliance that accounts for LLM non-determinism and recovery -- and prove a Drift Bounds Theorem showing that contracts with recovery rate gamma &gt; alpha (the natural drift rate) bound behavioral drift to D* = alpha/gamma in expectation, with Gaussian concentration in the stochastic setting. We establish sufficient conditions for safe contract composition in multi-agent chains and derive probabilistic degradation bounds. We implement ABC in AgentAssert, a runtime enforcement library, and evaluate on AgentContract-Bench, a benchmark of 200 scenarios across 7 models from 6 vendors. Results across 1,980 sessions show that contracted agents detect 5.2-6.8 soft violations per session that uncontracted baselines miss entirely (p &lt; 0.0001, Cohen's d = 6.7-33.8), achieve 88-100% hard constraint compliance, and bound behavioral drift to D* &lt; 0.27 across extended sessions, with 100% recovery for frontier models and 17-100% across all models, at overhead &lt; 10 ms per action.",
      "authors": [
        "Varun Pratap Bhardwaj"
      ],
      "published": "2026-02-25T18:42:56Z",
      "updated": "2026-02-25T18:42:56Z",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22302v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22041v1",
      "title": "Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions",
      "summary": "Heralding the advent of autonomous vehicles and mobile robots that interact with humans, responsibility in spatial interaction is burgeoning as a research topic. Even though metrics of responsibility tailored to spatial interactions have been proposed, they are mostly focused on the responsibility of individual agents. Metrics of causal responsibility focusing on individuals fail in cases of causal overdeterminism -- when many actors simultaneously cause an outcome. To fill the gaps in causal responsibility left by individual-focused metrics, we formulate a metric for the causal responsibility of groups. To identify assertive agents that are causally responsible for the trajectory of an affected agent, we further formalise the types of assertive influences and propose a tiering algorithm for systematically identifying assertive agents. Finally, we use scenario-based simulations to illustrate the benefits of considering groups and how the emergence of group effects vary with interaction dynamics and the proximity of agents.",
      "authors": [
        "Vassil Guenov",
        "Ashwin George",
        "Arkady Zgonnikov",
        "David A. Abbink",
        "Luciano Cavalcante Siebert"
      ],
      "published": "2026-02-25T15:48:52Z",
      "updated": "2026-02-25T15:48:52Z",
      "categories": [
        "cs.MA",
        "cs.CY"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22041v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21680v1",
      "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning",
      "summary": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.",
      "authors": [
        "David Eckel",
        "Henri Meeß"
      ],
      "published": "2026-02-25T08:33:39Z",
      "updated": "2026-02-25T08:33:39Z",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21680v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21670v2",
      "title": "Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning",
      "summary": "Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.",
      "authors": [
        "Tomoya Kawabe",
        "Rin Takano"
      ],
      "published": "2026-02-25T08:08:26Z",
      "updated": "2026-02-26T02:28:18Z",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21670v2.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.21634v1",
      "title": "AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction",
      "summary": "Lifetime Value (LTV) prediction is critical in advertising, recommender systems, and e-commerce. In practice, LTV data patterns vary across decision scenarios. As a result, practitioners often build complex, scenario-specific pipelines and iterate over feature processing, objective design, and tuning. This process is expensive and hard to transfer. We propose AgentLTV, an agent-based unified search-and-evolution framework for automated LTV modeling. AgentLTV treats each candidate solution as an {executable pipeline program}. LLM-driven agents generate code, run and repair pipelines, and analyze execution feedback. Two decision agents coordinate a two-stage search. The Monte Carlo Tree Search (MCTS) stage explores a broad space of modeling choices under a fixed budget, guided by the Polynomial Upper Confidence bounds for Trees criterion and a Pareto-aware multi-metric value function. The Evolutionary Algorithm (EA) stage refines the best MCTS program via island-based evolution with crossover, mutation, and migration. Experiments on a large-scale proprietary dataset and a public benchmark show that AgentLTV consistently discovers strong models across ranking and error metrics. Online bucket-level analysis further indicates improved ranking consistency and value calibration, especially for high-value and negative-LTV segments. We summarize practitioner-oriented takeaways: use MCTS for rapid adaptation to new data patterns, use EA for stable refinement, and validate deployment readiness with bucket-level ranking and calibration diagnostics. The proposed AgentLTV has been successfully deployed online.",
      "authors": [
        "Chaowei Wu",
        "Huazhu Chen",
        "Congde Yuan",
        "Qirui Yang",
        "Guoqing Song",
        "Yue Gao",
        "Li Luo",
        "Frank Youhua Chen",
        "Mengzhuo Guo"
      ],
      "published": "2026-02-25T06:58:18Z",
      "updated": "2026-02-25T06:58:18Z",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21634v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21515v1",
      "title": "Training Generalizable Collaborative Agents via Strategic Risk Aversion",
      "summary": "Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.",
      "authors": [
        "Chengrui Qu",
        "Yizhou Zhang",
        "Nicholas Lanzetti",
        "Eric Mazumdar"
      ],
      "published": "2026-02-25T03:06:59Z",
      "updated": "2026-02-25T03:06:59Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21515v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21477v1",
      "title": "Pancake: Hierarchical Memory System for Multi-Agent LLM Serving",
      "summary": "In this work, we identify and address the core challenges of agentic memory management in LLM serving, where large-scale storage, frequent updates, and multiple coexisting agents jointly introduce complex and high-cost approximate nearest neighbor (ANN) searching problems. We present Pancake, a multi-tier agentic memory system that unifies three key techniques: (i) multi-level index caching for single agents, (ii) coordinated index management across multiple agents, and (iii) collaborative GPU-CPU acceleration. Pancake exposes easy-to-use interface that can be integrated into memory-based agents like Mem-GPT, and is compatible with agentic frameworks such as LangChain and LlamaIndex. Experiments on realistic agent workloads show that Pancake substantially outperforms existing frameworks, achieving more than 4.29x end-to-end throughput improvement.",
      "authors": [
        "Zhengding Hu",
        "Zaifeng Pan",
        "Prabhleen Kaur",
        "Vibha Murthy",
        "Zhongkai Yu",
        "Yue Guan",
        "Zhen Wang",
        "Steven Swanson",
        "Yufei Ding"
      ],
      "published": "2026-02-25T01:09:04Z",
      "updated": "2026-02-25T01:09:04Z",
      "categories": [
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21477v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21404v1",
      "title": "From Cooperation to Hierarchy: A Study of Dynamics of Hierarchy Emergence in a Multi-Agent System",
      "summary": "A central premise in evolutionary biology is that individual variation can generate information asymmetries that facilitate the emergence of hierarchical organisation. To examine this process, we develop an agent-based model (ABM) to identify the minimal conditions under which hierarchy arises in dynamic multi-agent systems, focusing on the roles of initial heterogeneity and mutation amplitude across generations. Hierarchical organisation is quantified using the Trophic Incoherence (TI) metric, which captures directional asymmetries in interaction networks. Our results show that even small individual differences can be amplified through repeated local interactions involving reproduction, competition, and cooperation, but that hierarchical order is markedly more sensitive to mutation amplitude than to initial heterogeneity. Across repeated trials, stable hierarchies reliably emerge only when mutation amplitude is sufficiently high, while initial heterogeneity primarily affects early formation rather than long-term persistence. Overall, these findings demonstrate how simple interaction rules can give rise to both the emergence and persistence of hierarchical organisation, providing a quantitative account of how structured inequality can develop from initially homogeneous populations.",
      "authors": [
        "Shanshan Mao",
        "Peter Tino"
      ],
      "published": "2026-02-24T22:17:19Z",
      "updated": "2026-02-24T22:17:19Z",
      "categories": [
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21404v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21351v1",
      "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
      "summary": "The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
      "authors": [
        "Dmitrii Pantiukhin",
        "Ivan Kuznetsov",
        "Boris Shapkin",
        "Antonia Anna Jost",
        "Thomas Jung",
        "Nikolay Koldunov"
      ],
      "published": "2026-02-24T20:37:38Z",
      "updated": "2026-02-24T20:37:38Z",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21351v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21148v1",
      "title": "A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms",
      "summary": "In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.",
      "authors": [
        "Davis S. Catherman",
        "Carlo Pinciroli"
      ],
      "published": "2026-02-24T17:49:56Z",
      "updated": "2026-02-24T17:49:56Z",
      "categories": [
        "cs.RO",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21148v1.pdf",
      "category": "robotics"
    },
    {
      "id": "2602.21041v1",
      "title": "Stability Under Valuation Updates in Coalition Formation",
      "summary": "Coalition formation studies how to partition a set of agents into disjoint coalitions under consideration of their preferences. We study the classical objective of stability in a variant of additively separable hedonic games where agents can change their valuations. Our objective is to find a stable partition after each change. To minimize the reconfiguration cost, we search for nearby stable coalition structures. Our focus is on stability concepts based on single-agent deviations. We present a detailed picture of the complexity of finding nearby stable coalition structures in additively separable hedonic games, for both symmetric and non-symmetric valuations. Our results show that the problem is NP-complete for Nash stability, individual stability, contractual Nash stability, and contractual individual stability. We complement these results by presenting polynomial-time algorithms for contractual Nash stability and contractual individual stability under restricted symmetric valuations. Finally, we show that these algorithms guarantee a bounded average distance over long sequences of updates.",
      "authors": [
        "Fabian Frank",
        "Matija Novaković",
        "René Romen"
      ],
      "published": "2026-02-24T16:02:36Z",
      "updated": "2026-02-24T16:02:36Z",
      "categories": [
        "cs.GT",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21041v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21020v1",
      "title": "Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning",
      "summary": "Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing examples where even exact measure matching fails, and demonstrating a new hardness result on characterizing the Nash gap given a fixed measure matching error. We then show how these challenges can be overcome using strategic dominance assumptions on the expert equilibrium. Specifically, for the case of dominant strategy expert equilibria, assuming Behavioral Cloning error $ε_{\\text{BC}}$, this provides a Nash imitation gap of $\\mathcal{O}\\left(nε_{\\text{BC}}/(1-γ)^2\\right)$ for a discount factor $γ$. We generalize this result with a new notion of best-response continuity, and argue that this is implicitly encouraged by standard regularization techniques.",
      "authors": [
        "Antoine Bergerault",
        "Volkan Cevher",
        "Negar Mehr"
      ],
      "published": "2026-02-24T15:38:11Z",
      "updated": "2026-02-24T15:38:11Z",
      "categories": [
        "cs.LG",
        "cs.GT",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21020v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.20804v1",
      "title": "Probing Dec-POMDP Reasoning in Cooperative MARL",
      "summary": "Cooperative multi-agent reinforcement learning (MARL) is typically framed as a decentralised partially observable Markov decision process (Dec-POMDP), a setting whose hardness stems from two key challenges: partial observability and decentralised coordination. Genuinely solving such tasks requires Dec-POMDP reasoning, where agents use history to infer hidden states and coordinate based on local information. Yet it remains unclear whether popular benchmarks actually demand this reasoning or permit success via simpler strategies. We introduce a diagnostic suite combining statistically grounded performance comparisons and information-theoretic probes to audit the behavioural complexity of baseline policies (IPPO and MAPPO) across 37 scenarios spanning MPE, SMAX, Overcooked, Hanabi, and MaBrax. Our diagnostics reveal that success on these benchmarks rarely requires genuine Dec-POMDP reasoning. Reactive policies match the performance of memory-based agents in over half the scenarios, and emergent coordination frequently relies on brittle, synchronous action coupling rather than robust temporal influence. These findings suggest that some widely used benchmarks may not adequately test core Dec-POMDP assumptions under current training paradigms, potentially leading to over-optimistic assessments of progress. We release our diagnostic tooling to support more rigorous environment design and evaluation in cooperative MARL.",
      "authors": [
        "Kale-ab Tessera",
        "Leonard Hinckeldey",
        "Riccardo Zamboni",
        "David Abel",
        "Amos Storkey"
      ],
      "published": "2026-02-24T11:44:46Z",
      "updated": "2026-02-24T11:44:46Z",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20804v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.20684v1",
      "title": "Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery",
      "summary": "Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gates. We evaluate three hypotheses: (H1) audit-ready artifacts emerge as a by-product of development, (H2) 100% requirement-level verification is achievable with independent test generation, and (H3) verified increments can be delivered with single-digit human interactions per cycle. A feasibility case study on a Hardware-in-the-Loop system (about 500 LOC, 8 requirements, 54 tests) supports all three hypotheses: audit-ready documentation was generated automatically (H1), 100% requirement-level pass rate was achieved (H2), and only 6 prompts per cycle were required (H3), yielding an estimated 10-50x cost reduction versus a COCOMO II baseline (sensitivity range from pessimistic to optimistic assumptions). We invite independent replication to validate generalizability.",
      "authors": [
        "Christopher Koch",
        "Joshua Andreas Wellbrock"
      ],
      "published": "2026-02-24T08:41:05Z",
      "updated": "2026-02-24T08:41:05Z",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20684v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.20603v1",
      "title": "The Tragedy of the Commons in Multi-Population Resource Games",
      "summary": "Self-optimizing behaviors can lead to outcomes where collective benefits are ultimately destroyed, a well-known phenomenon known as the ``tragedy of the commons\". These scenarios are widely studied using game-theoretic approaches to analyze strategic agent decision-making. In this paper, we examine this phenomenon in a bi-level decision-making hierarchy, where low-level agents belong to multiple distinct populations, and high-level agents make decisions that impact the choices of the local populations they represent. We study strategic interactions in a context where the populations benefit from a common environmental resource that degrades with higher extractive efforts made by high-level agents. We characterize a unique symmetric Nash equilibrium in the high-level game, and investigate its consequences on the common resource. While the equilibrium resource level degrades as the number of populations grows large, there are instances where it does not become depleted. We identify such regions, as well as the regions where the resource does deplete.",
      "authors": [
        "Yamin Vahmian",
        "Keith Paarporn"
      ],
      "published": "2026-02-24T06:53:04Z",
      "updated": "2026-02-24T06:53:04Z",
      "categories": [
        "cs.GT",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20603v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.21262v2",
      "title": "Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models",
      "summary": "With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.",
      "authors": [
        "Sasha Robinson",
        "Kerem Oktar",
        "Katherine M. Collins",
        "Ilia Sucholutsky",
        "Kelsey R. Allen"
      ],
      "published": "2026-02-24T04:09:21Z",
      "updated": "2026-02-26T06:37:29Z",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21262v2.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.20493v1",
      "title": "AWCP: A Workspace Delegation Protocol for Deep-Engagement Collaboration across Remote Agents",
      "summary": "The rapid evolution of Large Language Model (LLM)-based autonomous agents is reshaping the digital landscape toward an emerging Agentic Web, where increasingly specialized agents must collaborate to accomplish complex tasks. However, existing collaboration paradigms are constrained to message passing, leaving execution environments as isolated silos. This creates a context gap: agents cannot directly manipulate files or invoke tools in a peer's environment, and must instead resort to costly, error-prone environment reconstruction. We introduce the Agent Workspace Collaboration Protocol (AWCP), which bridges this gap through temporary workspace delegation inspired by the Unix philosophy that everything is a file. AWCP decouples a lightweight control plane from pluggable transport mechanisms, allowing a Delegator to project its workspace to a remote Executor, who then operates on the shared files directly with unmodified local toolchains. We provide a fully open-source reference implementation with MCP tool integration and validate the protocol through live demonstrations of asymmetric collaboration, where agents with complementary capabilities cooperate through delegated workspaces. By establishing the missing workspace layer in the agentic protocol stack, AWCP paves the way for a universally interoperable agent ecosystem in which collaboration transcends message boundaries. The protocol and reference implementation are publicly available at https://github.com/SII-Holos/awcp.",
      "authors": [
        "Xiaohang Nie",
        "Zihan Guo",
        "Youliang Chen",
        "Yuanjian Zhou",
        "Weinan Zhang"
      ],
      "published": "2026-02-24T02:49:08Z",
      "updated": "2026-02-24T02:49:08Z",
      "categories": [
        "cs.NI",
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20493v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.20229v1",
      "title": "HieraMAS: Optimizing Intra-Node LLM Mixtures and Inter-Node Topology for Multi-Agent Systems",
      "summary": "Multi-agent systems (MAS) built on large language models (LLMs) have shown strong performance across many tasks. Most existing approaches improve only one aspect at a time, such as the communication topology, role assignment, or LLM routing, while treating each agent as a single, indivisible unit. This misses the opportunity to use mixtures of LLMs within an agent to strengthen role-specific abilities. We propose HieraMAS, a hierarchical collaboration framework that combines intra-node LLM mixtures with an inter-node communication topology. HieraMAS introduces supernodes, where each functional role is implemented by multiple heterogeneous LLMs using a propose-synthesis structure. Optimizing HieraMAS creates unique credit-assignment challenges: final task performance depends heavily on the underlying LLMs' capabilities, which can lead reinforcement methods to incorrectly reward suboptimal configurations. To address this, we use a two-stage algorithm: (1) multi-level reward attribution, which provides fine-grained feedback at both the node level and the overall system level; (2) graph classification for topology selection, which treats choosing the communication structure as a holistic decision rather than optimizing edges one by one. Experiments on reasoning and coding benchmarks show that HieraMAS substantially outperforms existing methods while also delivering better cost-performance trade-offs.",
      "authors": [
        "Tianjun Yao",
        "Zhaoyi Li",
        "Zhiqiang Shen"
      ],
      "published": "2026-02-23T18:36:04Z",
      "updated": "2026-02-23T18:36:04Z",
      "categories": [
        "cs.MA"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.20229v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.23116v1",
      "title": "Regularized Online RLHF with Generalized Bilinear Preferences",
      "summary": "We consider the problem of contextual online RLHF with general preferences, where the goal is to identify the Nash Equilibrium. We adopt the Generalized Bilinear Preference Model (GBPM) to capture potentially intransitive preferences via low-rank, skew-symmetric matrices. We investigate general preference learning with any strongly convex regularizer (where $η^{-1}$ is the regularization strength), generalizing beyond prior works limited to reverse KL-regularization. Central to our analysis is proving that the dual gap of the greedy policy is bounded by the square of the estimation error - a result derived solely from strong convexity and the skew-symmetricity of GBPM.Building on this insight and a feature diversity assumption, we establish two regret bounds via two simple algorithms: (1) Greedy Sampling achieves polylogarithmic, $e^{O(η)}$-free regret $\\tilde{O}(ηd^4 (\\log T)^2)$. (2) Explore-Then-Commit achieves $\\mathrm{poly}(d)$-free regret $\\tilde{O}(\\sqrt{ηr T})$ by exploiting the low-rank structure; this is the first statistically efficient guarantee for online RLHF in high-dimensions.",
      "authors": [
        "Junghyun Lee",
        "Minju Hong",
        "Kwang-Sung Jun",
        "Chulhee Yun",
        "Se-Young Yun"
      ],
      "published": "2026-02-26T15:27:53Z",
      "updated": "2026-02-26T15:27:53Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23116v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23023v1",
      "title": "Low-degree Lower bounds for clustering in moderate dimension",
      "summary": "We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $Δ$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $Δ$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \\leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \\geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \\geq K$. We show that while the difficulty of clustering for $n \\leq dK$ is primarily driven by dimension reduction and spectral methods, the moderate-dimensional regime involves more delicate phenomena leading to a \"non-parametric rate\". We provide a novel non-spectral algorithm matching this rate, shedding new light on the computational limits of the clustering problem in moderate dimension.",
      "authors": [
        "Alexandra Carpentier",
        "Nicolas Verzelen"
      ],
      "published": "2026-02-26T14:03:55Z",
      "updated": "2026-02-26T14:03:55Z",
      "categories": [
        "math.ST",
        "cs.LG",
        "math.PR",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23023v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.23006v1",
      "title": "Regular Fourier Features for Nonstationary Gaussian Processes",
      "summary": "Simulating a Gaussian process requires sampling from a high-dimensional Gaussian distribution, which scales cubically with the number of sample locations. Spectral methods address this challenge by exploiting the Fourier representation, treating the spectral density as a probability distribution for Monte Carlo approximation. Although this probabilistic interpretation works for stationary processes, it is overly restrictive for the nonstationary case, where spectral densities are generally not probability measures. We propose regular Fourier features for harmonizable processes that avoid this limitation. Our method discretizes the spectral representation directly, preserving the correlation structure among spectral weights without requiring probability assumptions. Under a finite spectral support assumption, this yields an efficient low-rank approximation that is positive semi-definite by construction. When the spectral density is unknown, the framework extends naturally to kernel learning from data. We demonstrate the method on locally stationary kernels and on harmonizable mixture kernels with complex-valued spectral densities.",
      "authors": [
        "Arsalan Jawaid",
        "Abdullah Karatas",
        "Jörg Seewig"
      ],
      "published": "2026-02-26T13:50:28Z",
      "updated": "2026-02-26T13:50:28Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.23006v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22985v1",
      "title": "Kernel Integrated $R^2$: A Measure of Dependence",
      "summary": "We introduce kernel integrated $R^2$, a new measure of statistical dependence that combines the local normalization principle of the recently introduced integrated $R^2$ with the flexibility of reproducing kernel Hilbert spaces (RKHSs). The proposed measure extends integrated $R^2$ from scalar responses to responses taking values on general spaces equipped with a characteristic kernel, allowing to measure dependence of multivariate, functional, and structured data, while remaining sensitive to tail behaviour and oscillatory dependence structures. We establish that (i) this new measure takes values in $[0,1]$, (ii) equals zero if and only if independence holds, and (iii) equals one if and only if the response is almost surely a measurable function of the covariates. Two estimators are proposed: a graph-based method using $K$-nearest neighbours and an RKHS-based method built on conditional mean embeddings. We prove consistency and derive convergence rates for the graph-based estimator, showing its adaptation to intrinsic dimensionality. Numerical experiments on simulated data and a real data experiment in the context of dependency testing for media annotations demonstrate competitive power against state-of-the-art dependence measures, particularly in settings involving non-linear and structured relationships.",
      "authors": [
        "Pouya Roudaki",
        "Shakeel Gavioli-Akilagun",
        "Florian Kalinke",
        "Mona Azadkia",
        "Zoltán Szabó"
      ],
      "published": "2026-02-26T13:29:12Z",
      "updated": "2026-02-26T13:29:12Z",
      "categories": [
        "stat.ML",
        "cs.IT",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22985v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22974v1",
      "title": "An automatic counting algorithm for the quantification and uncertainty analysis of the number of microglial cells trainable in small and heterogeneous datasets",
      "summary": "Counting immunopositive cells on biological tissues generally requires either manual annotation or (when available) automatic rough systems, for scanning signal surface and intensity in whole slide imaging. In this work, we tackle the problem of counting microglial cells in lumbar spinal cord cross-sections of rats by omitting cell detection and focusing only on the counting task. Manual cell counting is, however, a time-consuming task and additionally entails extensive personnel training. The classic automatic color-based methods roughly inform about the total labeled area and intensity (protein quantification) but do not specifically provide information on cell number. Since the images to be analyzed have a high resolution but a huge amount of pixels contain just noise or artifacts, we first perform a pre-processing generating several filtered images {(providing a tailored, efficient feature extraction)}. Then, we design an automatic kernel counter that is a non-parametric and non-linear method. The proposed scheme can be easily trained in small datasets since, in its basic version, it relies only on one hyper-parameter. However, being non-parametric and non-linear, the proposed algorithm is flexible enough to express all the information contained in rich and heterogeneous datasets as well (providing the maximum overfit if required). Furthermore, the proposed kernel counter also provides uncertainty estimation of the given prediction, and can directly tackle the case of receiving several expert opinions over the same image. Different numerical experiments with artificial and real datasets show very promising results. Related Matlab code is also provided.",
      "authors": [
        "L. Martino",
        "M. M. Garcia",
        "P. S. Paradas",
        "E. Curbelo"
      ],
      "published": "2026-02-26T13:13:43Z",
      "updated": "2026-02-26T13:13:43Z",
      "categories": [
        "cs.CE",
        "cs.CV",
        "eess.IV",
        "eess.SP",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22974v1.pdf",
      "category": "multimodal"
    },
    {
      "id": "2602.22965v1",
      "title": "A note on the area under the likelihood and the fake evidence for model selection",
      "summary": "Improper priors are not allowed for the computation of the Bayesian evidence $Z=p({\\bf y})$ (a.k.a., marginal likelihood), since in this case $Z$ is not completely specified due to an arbitrary constant involved in the computation. However, in this work, we remark that they can be employed in a specific type of model selection problem: when we have several (possibly infinite) models belonging to the same parametric family (i.e., for tuning parameters of a parametric model). However, the quantities involved in this type of selection cannot be considered as Bayesian evidences: we suggest to use the name ``fake evidences'' (or ``areas under the likelihood'' in the case of uniform improper priors). We also show that, in this model selection scenario, using a diffuse prior and increasing its scale parameter asymptotically to infinity, we cannot recover the value of the area under the likelihood, obtained with a uniform improper prior. We first discuss it from a general point of view. Then we provide, as an applicative example, all the details for Bayesian regression models with nonlinear bases, considering two cases: the use of a uniform improper prior and the use of a Gaussian prior, respectively. A numerical experiment is also provided confirming and checking all the previous statements.",
      "authors": [
        "L. Martino",
        "F. Llorente"
      ],
      "published": "2026-02-26T13:01:50Z",
      "updated": "2026-02-26T13:01:50Z",
      "categories": [
        "stat.ME",
        "cs.CE",
        "eess.SP",
        "stat.CO",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22965v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22954v1",
      "title": "Effective sample size approximations as entropy measures",
      "summary": "In this work, we analyze alternative effective sample size (ESS) metrics for importance sampling algorithms, and discuss a possible extended range of applications. We show the relationship between the ESS expressions used in the literature and two entropy families, the Rényi and Tsallis entropy. The Rényi entropy is connected to the Huggins-Roy's ESS family introduced in \\cite{Huggins15}. We prove that that all the ESS functions included in the Huggins-Roy's family fulfill all the desirable theoretical conditions. We analyzed and remark the connections with several other fields, such as the Hill numbers introduced in ecology, the Gini inequality coefficient employed in economics, and the Gini impurity index used mainly in machine learning, to name a few. Finally, by numerical simulations, we study the performance of different ESS expressions contained in the previous ESS families in terms of approximation of the theoretical ESS definition, and show the application of ESS formulas in a variable selection problem.",
      "authors": [
        "L. Martino",
        "V. Elvira"
      ],
      "published": "2026-02-26T12:48:33Z",
      "updated": "2026-02-26T12:48:33Z",
      "categories": [
        "math.ST",
        "cs.CE",
        "eess.SP",
        "stat.CO",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22954v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22925v1",
      "title": "Beyond NNGP: Large Deviations and Feature Learning in Bayesian Neural Networks",
      "summary": "We study wide Bayesian neural networks focusing on the rare but statistically dominant fluctuations that govern posterior concentration, beyond Gaussian-process limits. Large-deviation theory provides explicit variational objectives-rate functions-on predictors, providing an emerging notion of complexity and feature learning directly at the functional level. We show that the posterior output rate function is obtained by a joint optimization over predictors and internal kernels, in contrast with fixed-kernel (NNGP) theory. Numerical experiments demonstrate that the resulting predictions accurately describe finite-width behavior for moderately sized networks, capturing non-Gaussian tails, posterior deformation, and data-dependent kernel selection effects.",
      "authors": [
        "Katerina Papagiannouli",
        "Dario Trevisan",
        "Giuseppe Pio Zitto"
      ],
      "published": "2026-02-26T12:15:11Z",
      "updated": "2026-02-26T12:15:11Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22925v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22884v1",
      "title": "Unsupervised Continual Learning for Amortized Bayesian Inference",
      "summary": "Amortized Bayesian Inference (ABI) enables efficient posterior estimation using generative neural networks trained on simulated data, but often suffers from performance degradation under model misspecification. While self-consistency (SC) training on unlabeled empirical data can enhance network robustness, current approaches are limited to static, single-task settings and fail to handle sequentially arriving data or distribution shifts. We propose a continual learning framework for ABI that decouples simulation-based pre-training from unsupervised sequential SC fine-tuning on real-world data. To address the challenge of catastrophic forgetting, we introduce two adaptation strategies: (1) SC with episodic replay, utilizing a memory buffer of past observations, and (2) SC with elastic weight consolidation, which regularizes updates to preserve task-critical parameters. Across three diverse case studies, our methods significantly mitigate forgetting and yield posterior estimates that outperform standard simulation-based training, achieving estimates closer to MCMC reference, providing a viable path for trustworthy ABI across a range of different tasks.",
      "authors": [
        "Aayush Mishra",
        "Šimon Kucharský",
        "Paul-Christian Bürkner"
      ],
      "published": "2026-02-26T11:22:46Z",
      "updated": "2026-02-26T11:22:46Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22884v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22847v1",
      "title": "Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus",
      "summary": "The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i.e., when all the ranking data to be aggregated can be brought together in a single computing unit. For many technologies (e.g. peer-to-peer networks, IoT, multi-agent systems), extending the ability to calculate consensus rankings with guarantees in a decentralized setting, i.e., when preference data is initially distributed across a communicating network, remains a major methodological challenge. Indeed, in recent years, the literature on decentralized computation has mainly focused on computing or optimizing statistics such as arithmetic means using gossip algorithms. The purpose of this article is precisely to study how to achieve reliable consensus on collective rankings using classical rules (e.g. Borda, Copeland) in a decentralized setting, thereby raising new questions, robustness to corrupted nodes, and scalability through reduced communication costs in particular. The approach proposed and analyzed here relies on random gossip communication, allowing autonomous agents to compute global ranking consensus using only local interactions, without coordination or central authority. We provide rigorous convergence guarantees, including explicit rate bounds, for the Borda and Copeland consensus methods. Beyond these rules, we also provide a decentralized implementation of consensus according to the median rank rule and local Kemenization. Extensive empirical evaluations on various network topologies and real and synthetic ranking datasets demonstrate that our algorithms converge quickly and reliably to the correct ranking aggregation.",
      "authors": [
        "Anna Van Elst",
        "Kerrian Le Caillec",
        "Igor Colin",
        "Stephan Clémençon"
      ],
      "published": "2026-02-26T10:37:23Z",
      "updated": "2026-02-26T10:37:23Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22847v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22505v1",
      "title": "Sharp Convergence Rates for Masked Diffusion Models",
      "summary": "Discrete diffusion models have achieved strong empirical performance in text and other symbolic domains, with masked (absorbing-rate) variants emerging as competitive alternatives to autoregressive models. Among existing samplers, the Euler method remains the standard choice in many applications, and more recently, the First-Hitting Sampler (FHS) has shown considerable promise for masked diffusion models. Despite their practical success, the theoretical understanding of these samplers remains limited. Existing analyses are conducted in Kullback-Leibler (KL) divergence, which often yields loose parameter dependencies and requires strong assumptions on score estimation. Moreover, these guarantees do not cover recently developed high-performance sampler of FHS. In this work, we first develop a direct total-variation (TV) based analysis for the Euler method that overcomes these limitations. Our results relax assumptions on score estimation, improve parameter dependencies, and establish convergence guarantees without requiring any surrogate initialization. Also for this setting, we provide the first convergence lower bound for the Euler sampler, establishing tightness with respect to both the data dimension $d$ and the target accuracy $\\varepsilon$. Finally, we analyze the FHS sampler and show that it incurs no sampling error beyond that induced by score estimation, which we show to be tight with a matching lower error bound. Overall, our analysis introduces a direct TV-based error decomposition along the CTMC trajectory and a decoupling-based path-wise analysis for FHS, which may be of independent interest.",
      "authors": [
        "Yuchen Liang",
        "Zhiheng Tan",
        "Ness Shroff",
        "Yingbin Liang"
      ],
      "published": "2026-02-26T00:47:51Z",
      "updated": "2026-02-26T00:47:51Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22505v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22492v1",
      "title": "From Shallow Bayesian Neural Networks to Gaussian Processes: General Convergence, Identifiability and Scalable Inference",
      "summary": "In this work, we study scaling limits of shallow Bayesian neural networks (BNNs) via their connection to Gaussian processes (GPs), with an emphasis on statistical modeling, identifiability, and scalable inference. We first establish a general convergence result from BNNs to GPs by relaxing assumptions used in prior formulations, and we compare alternative parameterizations of the limiting GP model. Building on this theory, we propose a new covariance function defined as a convex mixture of components induced by four widely used activation functions, and we characterize key properties including positive definiteness and both strict and practical identifiability under different input designs. For computation, we develop a scalable maximum a posterior (MAP) training and prediction procedure using a Nyström approximation, and we show how the Nyström rank and anchor selection control the cost-accuracy trade-off. Experiments on controlled simulations and real-world tabular datasets demonstrate stable hyperparameter estimates and competitive predictive performance at realistic computational cost.",
      "authors": [
        "Gracielle Antunes de Araújo",
        "Flávio B. Gonçalves"
      ],
      "published": "2026-02-26T00:02:54Z",
      "updated": "2026-02-26T00:02:54Z",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22492v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22486v1",
      "title": "Flow Matching is Adaptive to Manifold Structures",
      "summary": "Flow matching has emerged as a simulation-free alternative to diffusion-based generative modeling, producing samples by solving an ODE whose time-dependent velocity field is learned along an interpolation between a simple source distribution (e.g., a standard normal) and a target data distribution. Flow-based methods often exhibit greater training stability and have achieved strong empirical performance in high-dimensional settings where data concentrate near a low-dimensional manifold, such as text-to-image synthesis, video generation, and molecular structure generation. Despite this success, existing theoretical analyses of flow matching assume target distributions with smooth, full-dimensional densities, leaving its effectiveness in manifold-supported settings largely unexplained. To this end, we theoretically analyze flow matching with linear interpolation when the target distribution is supported on a smooth manifold. We establish a non-asymptotic convergence guarantee for the learned velocity field, and then propagate this estimation error through the ODE to obtain statistical consistency of the implicit density estimator induced by the flow-matching objective. The resulting convergence rate is near minimax-optimal, depends only on the intrinsic dimension, and reflects the smoothness of both the manifold and the target distribution. Together, these results provide a principled explanation for how flow matching adapts to intrinsic data geometry and circumvents the curse of dimensionality.",
      "authors": [
        "Shivam Kumar",
        "Yixin Wang",
        "Lizhen Lin"
      ],
      "published": "2026-02-25T23:52:32Z",
      "updated": "2026-02-25T23:52:32Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22486v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22432v1",
      "title": "LoBoost: Fast Model-Native Local Conformal Prediction for Gradient-Boosted Trees",
      "summary": "Gradient-boosted decision trees are among the strongest off-the-shelf predictors for tabular regression, but point predictions alone do not quantify uncertainty. Conformal prediction provides distribution-free marginal coverage, yet split conformal uses a single global residual quantile and can be poorly adaptive under heteroscedasticity. Methods that improve adaptivity typically fit auxiliary nuisance models or introduce additional data splits/partitions to learn the conformal score, increasing cost and reducing data efficiency. We propose LoBoost, a model-native local conformal method that reuses the fitted ensemble's leaf structure to define multiscale calibration groups. Each input is encoded by its sequence of visited leaves; at resolution level k, we group points by matching prefixes of leaf indices across the first k trees and calibrate residual quantiles within each group. LoBoost requires no retraining, auxiliary models, or extra splitting beyond the standard train/calibration split. Experiments show competitive interval quality, improved test MSE on most datasets, and large calibration speedups.",
      "authors": [
        "Vagner Santos",
        "Victor Coscrato",
        "Luben Cabezas",
        "Rafael Izbicki",
        "Thiago Ramos"
      ],
      "published": "2026-02-25T21:44:19Z",
      "updated": "2026-02-25T21:44:19Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22432v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22369v1",
      "title": "Sampling from Constrained Gibbs Measures: with Applications to High-Dimensional Bayesian Inference",
      "summary": "This paper considers a non-standard problem of generating samples from a low-temperature Gibbs distribution with \\emph{constrained} support, when some of the coordinates of the mode lie on the boundary. These coordinates are referred to as the non-regular part of the model. We show that in a ``pre-asymptotic'' regime in which the limiting Laplace approximation is not yet valid, the low-temperature Gibbs distribution concentrates on a neighborhood of its mode. Within this region, the distribution is a bounded perturbation of a product measure: a strongly log-concave distribution in the regular part and a one-dimensional exponential-type distribution in each coordinate of the non-regular part. Leveraging this structure, we provide a non-asymptotic sampling guarantee by analyzing the spectral gap of Langevin dynamics. Key examples of low-temperature Gibbs distributions include Bayesian posteriors, and we demonstrate our results on three canonical examples: a high-dimensional logistic regression model, a Poisson linear model, and a Gaussian mixture model.",
      "authors": [
        "Ruixiao Wang",
        "Xiaohong Chen",
        "Sinho Chewi"
      ],
      "published": "2026-02-25T20:06:07Z",
      "updated": "2026-02-25T20:06:07Z",
      "categories": [
        "math.ST",
        "math.PR",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22369v1.pdf",
      "category": "other"
    },
    {
      "id": "2602.22334v1",
      "title": "A 1/R Law for Kurtosis Contrast in Balanced Mixtures",
      "summary": "Kurtosis-based Independent Component Analysis (ICA) weakens in wide, balanced mixtures. We prove a sharp redundancy law: for a standardized projection with effective width $R_{\\mathrm{eff}}$ (participation ratio), the population excess kurtosis obeys $|κ(y)|=O(κ_{\\max}/R_{\\mathrm{eff}})$, yielding the order-tight $O(c_bκ_{\\max}/R)$ under balance (typically $c_b=O(\\log R)$). As an impossibility screen, under standard finite-moment conditions for sample kurtosis estimation, surpassing the $O(1/\\sqrt{T})$ estimation scale requires $R\\lesssim κ_{\\max}\\sqrt{T}$. We also show that \\emph{purification} -- selecting $m\\!\\ll\\!R$ sign-consistent sources -- restores $R$-independent contrast $Ω(1/m)$, with a simple data-driven heuristic. Synthetic experiments validate the predicted decay, the $\\sqrt{T}$ crossover, and contrast recovery.",
      "authors": [
        "Yuda Bi",
        "Wenjun Xiao",
        "Linhao Bai",
        "Vince D Calhoun"
      ],
      "published": "2026-02-25T19:01:01Z",
      "updated": "2026-02-25T19:01:01Z",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22334v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22122v1",
      "title": "Probing the Geometry of Diffusion Models with the String Method",
      "summary": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited. Standard latent-space interpolations fail to respect the structure of the learned distribution, often traversing low-density regions. We introduce a framework based on the string method that computes continuous paths between samples by evolving curves under the learned score function. Operating on pretrained models without retraining, our approach interpolates between three regimes: pure generative transport, which yields continuous sample paths; gradient-dominated dynamics, which recover minimum energy paths (MEPs); and finite-temperature string dynamics, which compute principal curves -- self-consistent paths that balance energy and entropy. We demonstrate that the choice of regime matters in practice. For image diffusion models, MEPs contain high-likelihood but unrealistic ''cartoon'' images, confirming prior observations that likelihood maxima appear unrealistic; principal curves instead yield realistic morphing sequences despite lower likelihood. For protein structure prediction, our method computes transition pathways between metastable conformers directly from models trained on static structures, yielding paths with physically plausible intermediates. Together, these results establish the string method as a principled tool for probing the modal structure of diffusion models -- identifying modes, characterizing barriers, and mapping connectivity in complex learned distributions.",
      "authors": [
        "Elio Moreau",
        "Florentin Coeurdoux",
        "Grégoire Ferre",
        "Eric Vanden-Eijnden"
      ],
      "published": "2026-02-25T17:10:59Z",
      "updated": "2026-02-25T17:10:59Z",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22122v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22083v1",
      "title": "Coarsening Bias from Variable Discretization in Causal Functionals",
      "summary": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation.",
      "authors": [
        "Xiaxian Ou",
        "Razieh Nabi"
      ],
      "published": "2026-02-25T16:32:04Z",
      "updated": "2026-02-25T16:32:04Z",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22083v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.22003v1",
      "title": "Neural solver for Wasserstein Geodesics and optimal transport dynamics",
      "summary": "In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets.",
      "authors": [
        "Hailiang Liu",
        "Yan-Han Chen"
      ],
      "published": "2026-02-25T15:21:24Z",
      "updated": "2026-02-25T15:21:24Z",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.22003v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21948v1",
      "title": "Bayesian Generative Adversarial Networks via Gaussian Approximation for Tabular Data Synthesis",
      "summary": "Generative Adversarial Networks (GAN) have been used in many studies to synthesise mixed tabular data. Conditional tabular GAN (CTGAN) have been the most popular variant but struggle to effectively navigate the risk-utility trade-off. Bayesian GAN have received less attention for tabular data, but have been explored with unstructured data such as images and text. The most used technique employed in Bayesian GAN is Markov Chain Monte Carlo (MCMC), but it is computationally intensive, particularly in terms of weight storage. In this paper, we introduce Gaussian Approximation of CTGAN (GACTGAN), an integration of the Bayesian posterior approximation technique using Stochastic Weight Averaging-Gaussian (SWAG) within the CTGAN generator to synthesise tabular data, reducing computational overhead after the training phase. We demonstrate that GACTGAN yields better synthetic data compared to CTGAN, achieving better preservation of tabular structure and inferential statistics with less privacy risk. These results highlight GACTGAN as a simpler, effective implementation of Bayesian tabular synthesis.",
      "authors": [
        "Bahrul Ilmi Nasution",
        "Mark Elliot",
        "Richard Allmendinger"
      ],
      "published": "2026-02-25T14:32:58Z",
      "updated": "2026-02-25T14:32:58Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21948v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21928v1",
      "title": "Learning Unknown Interdependencies for Decentralized Root Cause Analysis in Nonlinear Dynamical Systems",
      "summary": "Root cause analysis (RCA) in networked industrial systems, such as supply chains and power networks, is notoriously difficult due to unknown and dynamically evolving interdependencies among geographically distributed clients. These clients represent heterogeneous physical processes and industrial assets equipped with sensors that generate large volumes of nonlinear, high-dimensional, and heterogeneous IoT data. Classical RCA methods require partial or full knowledge of the system's dependency graph, which is rarely available in these complex networks. While federated learning (FL) offers a natural framework for decentralized settings, most existing FL methods assume homogeneous feature spaces and retrainable client models. These assumptions are not compatible with our problem setting. Different clients have different data features and often run fixed, proprietary models that cannot be modified. This paper presents a federated cross-client interdependency learning methodology for feature-partitioned, nonlinear time-series data, without requiring access to raw sensor streams or modifying proprietary client models. Each proprietary local client model is augmented with a Machine Learning (ML) model that encodes cross-client interdependencies. These ML models are coordinated via a global server that enforces representation consistency while preserving privacy through calibrated differential privacy noise. RCA is performed using model residuals and anomaly flags. We establish theoretical convergence guarantees and validate our approach on extensive simulations and a real-world industrial cybersecurity dataset.",
      "authors": [
        "Ayush Mohanty",
        "Paritosh Ramanan",
        "Nagi Gebraeel"
      ],
      "published": "2026-02-25T14:05:38Z",
      "updated": "2026-02-25T14:05:38Z",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21928v1.pdf",
      "category": "ml-theory"
    },
    {
      "id": "2602.21846v1",
      "title": "Scalable Kernel-Based Distances for Statistical Inference and Integration",
      "summary": "Representing, comparing, and measuring the distance between probability distributions is a key task in computational statistics and machine learning. The choice of representation and the associated distance determine properties of the methods in which they are used: for example, certain distances can allow one to encode robustness or smoothness of the problem. Kernel methods offer flexible and rich Hilbert space representations of distributions that allow the modeller to enforce properties through the choice of kernel, and estimate associated distances at efficient nonparametric rates. In particular, the maximum mean discrepancy (MMD), a kernel-based distance constructed by comparing Hilbert space mean functions, has received significant attention due to its computational tractability and is favoured by practitioners. In this thesis, we conduct a thorough study of kernel-based distances with a focus on efficient computation, with core contributions in Chapters 3 to 6. Part I of the thesis is focused on the MMD, specifically on improved MMD estimation. In Chapter 3 we propose a theoretically sound, improved estimator for MMD in simulation-based inference. Then, in Chapter 4, we propose an MMD-based estimator for conditional expectations, a ubiquitous task in statistical computation. Closing Part I, in Chapter 5 we study the problem of calibration when MMD is applied to the task of integration. In Part II, motivated by the recent developments in kernel embeddings beyond the mean, we introduce a family of novel kernel-based discrepancies: kernel quantile discrepancies. These address some of the pitfalls of MMD, and are shown through both theoretical results and an empirical study to offer a competitive alternative to MMD and its fast approximations. We conclude with a discussion on broader lessons and future work emerging from the thesis.",
      "authors": [
        "Masha Naslidnyk"
      ],
      "published": "2026-02-25T12:25:34Z",
      "updated": "2026-02-25T12:25:34Z",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST",
        "stat.ME"
      ],
      "pdfUrl": "http://arxiv.org/pdf/2602.21846v1.pdf",
      "category": "ml-theory"
    }
  ],
  "byCategory": {
    "robotics": [
      {
        "id": "2602.23331v1",
        "title": "Utilizing LLMs for Industrial Process Automation",
        "summary": "A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.",
        "authors": [
          "Salim Fares"
        ],
        "published": "2026-02-26T18:38:00Z",
        "updated": "2026-02-26T18:38:00Z",
        "categories": [
          "cs.SE",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23331v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23312v1",
        "title": "Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction",
        "summary": "Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.",
        "authors": [
          "Rafael R. Baptista",
          "André de Lima Salgado",
          "Ricardo V. Godoy",
          "Marcelo Becker",
          "Thiago Boaventura",
          "Gustavo J. G. Lahr"
        ],
        "published": "2026-02-26T18:20:26Z",
        "updated": "2026-02-26T18:20:26Z",
        "categories": [
          "cs.HC",
          "cs.AI",
          "cs.LG",
          "cs.RO",
          "eess.SY"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23312v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23259v1",
        "title": "Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving",
        "summary": "With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.",
        "authors": [
          "Jiangxin Sun",
          "Feng Xue",
          "Teng Long",
          "Chang Liu",
          "Jian-Fang Hu",
          "Wei-Shi Zheng",
          "Nicu Sebe"
        ],
        "published": "2026-02-26T17:32:30Z",
        "updated": "2026-02-26T17:32:30Z",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23259v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23280v1",
        "title": "Physics Informed Viscous Value Representations",
        "summary": "Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.",
        "authors": [
          "Hrishikesh Viswanath",
          "Juanwu Lu",
          "S. Talha Bukhari",
          "Damon Conover",
          "Ziran Wang",
          "Aniket Bera"
        ],
        "published": "2026-02-26T17:53:46Z",
        "updated": "2026-02-26T17:53:46Z",
        "categories": [
          "cs.LG",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23280v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23224v1",
        "title": "UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception",
        "summary": "We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encoding strategies, making it particularly suitable for resource-constrained robotic teams. We evaluate UniScale on multiple benchmarks, demonstrating strong generalization and consistent performance across diverse environments. We will release our implementation upon acceptance.",
        "authors": [
          "Mohammad Mahdavian",
          "Gordon Tan",
          "Binbin Xu",
          "Yuan Ren",
          "Dongfeng Bai",
          "Bingbing Liu"
        ],
        "published": "2026-02-26T17:04:36Z",
        "updated": "2026-02-26T17:04:36Z",
        "categories": [
          "cs.CV",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23224v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23204v1",
        "title": "Motion-aware Event Suppression for Event Cameras",
        "summary": "In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.",
        "authors": [
          "Roberto Pellerito",
          "Nico Messikommer",
          "Giovanni Cioffi",
          "Marco Cannici",
          "Davide Scaramuzza"
        ],
        "published": "2026-02-26T16:53:36Z",
        "updated": "2026-02-26T16:53:36Z",
        "categories": [
          "cs.CV",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23204v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23287v1",
        "title": "Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning",
        "summary": "Assistive robots offer agency to humans with severe motor impairments. Often, these users control high-DoF robots through low-dimensional interfaces, such as using a 1-D sip-and-puff interface to operate a 6-DoF robotic arm. This mismatch results in having access to only a subset of control dimensions at a given time, imposing unintended and artificial constraints on robot motion. As a result, interface-limited demonstrations embed suboptimal motions that reflect interface restrictions rather than user intent. To address this, we present a trajectory reconstruction algorithm that reasons about task, environment, and interface constraints to lift demonstrations into the robot's full control space. We evaluate our approach using real-world demonstrations of ADL-inspired tasks performed via a 2-D joystick and 1-D sip-and-puff control interface, teleoperating two distinct 7-DoF robotic arms. Analyses of the reconstructed demonstrations and derived control policies show that lifted trajectories are faster and more efficient than their interface-constrained counterparts while respecting user preferences.",
        "authors": [
          "Demiana R. Barsoum",
          "Mahdieh Nejati Javaremi",
          "Larisa Y. C. Loke",
          "Brenna D. Argall"
        ],
        "published": "2026-02-26T18:01:25Z",
        "updated": "2026-02-26T18:01:25Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23287v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23283v1",
        "title": "Simple Models, Real Swimming: Digital Twins for Tendon-Driven Underwater Robots",
        "summary": "Mimicking the graceful motion of swimming animals remains a core challenge in soft robotics due to the complexity of fluid-structure interaction and the difficulty of controlling soft, biomimetic bodies. Existing modeling approaches are often computationally expensive and impractical for complex control or reinforcement learning needed for realistic motions to emerge in robotic systems. In this work, we present a tendon-driven fish robot modeled in an efficient underwater swimmer environment using a simplified, stateless hydrodynamics formulation implemented in the widespread robotics framework MuJoCo. With just two real-world swimming trajectories, we identify five fluid parameters that allow a matching to experimental behavior and generalize across a range of actuation frequencies. We show that this stateless fluid model can generalize to unseen actuation and outperform classical analytical models such as the elongated body theory. This simulation environment runs faster than real-time and can easily enable downstream learning algorithms such as reinforcement learning for target tracking, reaching a 93% success rate. Due to the simplicity and ease of use of the model and our open-source simulation environment, our results show that even simple, stateless models -- when carefully matched to physical data -- can serve as effective digital twins for soft underwater robots, opening up new directions for scalable learning and control in aquatic environments.",
        "authors": [
          "Mike Y. Michelis",
          "Nana Obayashi",
          "Josie Hughes",
          "Robert K. Katzschmann"
        ],
        "published": "2026-02-26T17:55:22Z",
        "updated": "2026-02-26T17:55:22Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23283v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23253v1",
        "title": "SPARR: Simulation-based Policies with Asymmetric Real-world Residuals for Assembly",
        "summary": "Robotic assembly presents a long-standing challenge due to its requirement for precise, contact-rich manipulation. While simulation-based learning has enabled the development of robust assembly policies, their performance often degrades when deployed in real-world settings due to the sim-to-real gap. Conversely, real-world reinforcement learning (RL) methods avoid the sim-to-real gap, but rely heavily on human supervision and lack generalization ability to environmental changes. In this work, we propose a hybrid approach that combines a simulation-trained base policy with a real-world residual policy to efficiently adapt to real-world variations. The base policy, trained in simulation using low-level state observations and dense rewards, provides strong priors for initial behavior. The residual policy, learned in the real world using visual observations and sparse rewards, compensates for discrepancies in dynamics and sensor noise. Extensive real-world experiments demonstrate that our method, SPARR, achieves near-perfect success rates across diverse two-part assembly tasks. Compared to the state-of-the-art zero-shot sim-to-real methods, SPARR improves success rates by 38.4% while reducing cycle time by 29.7%. Moreover, SPARR requires no human expertise, in contrast to the state-of-the-art real-world RL approaches that depend heavily on human supervision.",
        "authors": [
          "Yijie Guo",
          "Iretiayo Akinola",
          "Lars Johannsmeier",
          "Hugo Hadfield",
          "Abhishek Gupta",
          "Yashraj Narang"
        ],
        "published": "2026-02-26T17:26:13Z",
        "updated": "2026-02-26T17:26:13Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23253v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23206v1",
        "title": "Grasp, Slide, Roll: Comparative Analysis of Contact Modes for Tactile-Based Shape Reconstruction",
        "summary": "Tactile sensing allows robots to gather detailed geometric information about objects through physical interaction, complementing vision-based approaches. However, efficiently acquiring useful tactile data remains challenging due to the time-consuming nature of physical contact and the need to strategically choose contact locations that maximize information gain while minimizing physical interactions. This paper studies how different contact modes affect object shape reconstruction using a tactile-enabled dexterous gripper. We compare three contact interaction modes: grasp-releasing, sliding induced by finger-grazing, and palm-rolling. These contact modes are combined with an information-theoretic exploration framework that guides subsequent sampling locations using a shape completion model. Our results show that the improved tactile sensing efficiency of finger-grazing and palm-rolling translates into faster convergence in shape reconstruction, requiring 34% fewer physical interactions while improving reconstruction accuracy by 55%. We validate our approach using a UR5e robot arm equipped with an Inspire-Robots Dexterous Hand, showing robust performance across primitive object geometries.",
        "authors": [
          "Chung Hee Kim",
          "Shivani Kamtikar",
          "Tye Brady",
          "Taskin Padir",
          "Joshua Migdal"
        ],
        "published": "2026-02-26T16:53:59Z",
        "updated": "2026-02-26T16:53:59Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23206v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23172v1",
        "title": "Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking",
        "summary": "Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, we first fuse observations into 3D Gaussians that serve as a sparse point-centric latent representation of the 3D scene, and then splat the aggregated features onto a 3D voxel grid that is decoded by a mask-based segmentation head. We evaluate LaGS on the Occ3D nuScenes and Waymo datasets, achieving state-of-the-art performance for 4D panoptic occupancy tracking. We make our code available at https://lags.cs.uni-freiburg.de/.",
        "authors": [
          "Maximilian Luz",
          "Rohit Mohan",
          "Thomas Nürnberg",
          "Yakov Miron",
          "Daniele Cattaneo",
          "Abhinav Valada"
        ],
        "published": "2026-02-26T16:34:49Z",
        "updated": "2026-02-26T16:34:49Z",
        "categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23172v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23115v1",
        "title": "FLIGHT: Fibonacci Lattice-based Inference for Geometric Heading in real-Time",
        "summary": "Estimating camera motion from monocular video is a fundamental problem in computer vision, central to tasks such as SLAM, visual odometry, and structure-from-motion. Existing methods that recover the camera's heading under known rotation, whether from an IMU or an optimization algorithm, tend to perform well in low-noise, low-outlier conditions, but often decrease in accuracy or become computationally expensive as noise and outlier levels increase. To address these limitations, we propose a novel generalization of the Hough transform on the unit sphere (S(2)) to estimate the camera's heading. First, the method extracts correspondences between two frames and generates a great circle of directions compatible with each pair of correspondences. Then, by discretizing the unit sphere using a Fibonacci lattice as bin centers, each great circle casts votes for a range of directions, ensuring that features unaffected by noise or dynamic objects vote consistently for the correct motion direction. Experimental results on three datasets demonstrate that the proposed method is on the Pareto frontier of accuracy versus efficiency. Additionally, experiments on SLAM show that the proposed method reduces RMSE by correcting the heading during camera pose initialization.",
        "authors": [
          "David Dirnfeld",
          "Fabien Delattre",
          "Pedro Miraldo",
          "Erik Learned-Miller"
        ],
        "published": "2026-02-26T15:27:49Z",
        "updated": "2026-02-26T15:27:49Z",
        "categories": [
          "cs.CV",
          "cs.CG",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23115v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23109v1",
        "title": "Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios",
        "summary": "The sudden appearance of occluded pedestrians presents a critical safety challenge in autonomous driving. Conventional rule-based or purely data-driven approaches struggle with the inherent high uncertainty of these long-tail scenarios. To tackle this challenge, we propose a novel framework grounded in Active Inference, which endows the agent with a human-like, belief-driven mechanism. Our framework leverages a Rao-Blackwellized Particle Filter (RBPF) to efficiently estimate the pedestrian's hybrid state. To emulate human-like cognitive processes under uncertainty, we introduce a Conditional Belief Reset mechanism and a Hypothesis Injection technique to explicitly model beliefs about the pedestrian's multiple latent intentions. Planning is achieved via a Cross-Entropy Method (CEM) enhanced Model Predictive Path Integral (MPPI) controller, which synergizes the efficient, iterative search of CEM with the inherent robustness of MPPI. Simulation experiments demonstrate that our approach significantly reduces the collision rate compared to reactive, rule-based, and reinforcement learning (RL) baselines, while also exhibiting explainable and human-like driving behavior that reflects the agent's internal belief state.",
        "authors": [
          "Kai Chen",
          "Yuyao Huang",
          "Guang Chen"
        ],
        "published": "2026-02-26T15:22:07Z",
        "updated": "2026-02-26T15:22:07Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23109v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23058v1",
        "title": "GeoWorld: Geometric World Models",
        "summary": "Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned in Euclidean space, neglecting the underlying geometric and hierarchical structure among states, and (ii) they struggle with long-horizon prediction, which leads to rapid degradation across extended rollouts. To address these challenges, we introduce GeoWorld, a geometric world model that preserves geometric structure and hierarchical relations through a Hyperbolic JEPA, which maps latent representations from Euclidean space onto hyperbolic manifolds. We further introduce Geometric Reinforcement Learning for energy-based optimization, enabling stable multi-step planning in hyperbolic latent space. Extensive experiments on CrossTask and COIN demonstrate around 3% SR improvement in 3-step planning and 2% SR improvement in 4-step planning compared to the state-of-the-art V-JEPA 2. Project website: https://steve-zeyu-zhang.github.io/GeoWorld.",
        "authors": [
          "Zeyu Zhang",
          "Danning Li",
          "Ian Reid",
          "Richard Hartley"
        ],
        "published": "2026-02-26T14:42:53Z",
        "updated": "2026-02-26T14:42:53Z",
        "categories": [
          "cs.CV",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23058v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23053v1",
        "title": "Marinarium: a New Arena to Bring Maritime Robotics Closer to Shore",
        "summary": "This paper presents the Marinarium, a modular and stand-alone underwater research facility designed to provide a realistic testbed for maritime and space-analog robotic experimentation in a resource-efficient manner. The Marinarium combines a fully instrumented underwater and aerial operational volume, extendable via a retractable roof for real-weather conditions, a digital twin in the SMaRCSim simulator and tight integration with a space robotics laboratory. All of these result from design choices aimed at bridging simulation, laboratory validation, and field conditions. We compare the Marinarium to similar existing infrastructures and illustrate how its design enables a set of experiments in four open research areas within field robotics. First, we exploit high-fidelity dynamics data from the tank to demonstrate the potential of learning-based system identification approaches applied to underwater vehicles. We further highlight the versatility of the multi-domain operating volume via a rendezvous mission with a heterogeneous fleet of robots across underwater, surface, and air. We then illustrate how the presented digital twin can be utilized to reduce the reality gap in underwater simulation. Finally, we demonstrate the potential of underwater surrogates for spacecraft navigation validation by executing spatiotemporally identical inspection tasks on a planar space-robot emulator and a neutrally buoyant \\gls{rov}. In this work, by sharing the insights obtained and rationale behind the design and construction of the Marinarium, we hope to provide the field robotics research community with a blueprint for bridging the gap between controlled and real offshore and space robotics experimentation.",
        "authors": [
          "Ignacio Torroba",
          "David Dorner",
          "Victor Nan Fernandez-Ayala",
          "Mart Kartasev",
          "Joris Verhagen",
          "Elias Krantz",
          "Gregorio Marchesini",
          "Carl Ljung",
          "Pedro Roque",
          "Chelsea Sidrane",
          "Linda Van der Spaa",
          "Nicola De Carli",
          "Petter Ogren",
          "Christer Fuglesang",
          "Jana Tumova",
          "Dimos V. Dimarogonas",
          "Ivan Stenius"
        ],
        "published": "2026-02-26T14:40:20Z",
        "updated": "2026-02-26T14:40:20Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23053v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23051v1",
        "title": "An Empirical Analysis of Cooperative Perception for Occlusion Risk Mitigation",
        "summary": "Occlusions present a significant challenge for connected and automated vehicles, as they can obscure critical road users from perception systems. Traditional risk metrics often fail to capture the cumulative nature of these threats over time adequately. In this paper, we propose a novel and universal risk assessment metric, the Risk of Tracking Loss (RTL), which aggregates instantaneous risk intensity throughout occluded periods. This provides a holistic risk profile that encompasses both high-intensity, short-term threats and prolonged exposure. Utilizing diverse and high-fidelity real-world datasets, a large-scale statistical analysis is conducted to characterize occlusion risk and validate the effectiveness of the proposed metric. The metric is applied to evaluate different vehicle-to-everything (V2X) deployment strategies. Our study shows that full V2X penetration theoretically eliminates this risk, the reduction is highly nonlinear; a substantial statistical benefit requires a high penetration threshold of 75-90%. To overcome this limitation, we propose a novel asymmetric communication framework that allows even non-connected vehicles to receive warnings. Experimental results demonstrate that this paradigm achieves better risk mitigation performance. We found that our approach at 25% penetration outperforms the traditional symmetric model at 75%, and benefits saturate at only 50% penetration. This work provides a crucial risk assessment metric and a cost-effective, strategic roadmap for accelerating the safety benefits of V2X deployment.",
        "authors": [
          "Aihong Wang",
          "Tenghui Xie",
          "Fuxi Wen",
          "Jun Li"
        ],
        "published": "2026-02-26T14:38:38Z",
        "updated": "2026-02-26T14:38:38Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23051v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23024v1",
        "title": "InCoM: Intent-Driven Perception and Structured Coordination for Whole-Body Mobile Manipulation",
        "summary": "Whole-body mobile manipulation is a fundamental capability for general-purpose robotic agents, requiring both coordinated control of the mobile base and manipulator and robust perception under dynamically changing viewpoints. However, existing approaches face two key challenges: strong coupling between base and arm actions complicates whole-body control optimization, and perceptual attention is often poorly allocated as viewpoints shift during mobile manipulation. We propose InCoM, an intent-driven perception and structured coordination framework for whole-body mobile manipulation. InCoM infers latent motion intent to dynamically reweight multi-scale perceptual features, enabling stage-adaptive allocation of perceptual attention. To support robust cross-modal perception, InCoM further incorporates a geometric-semantic structured alignment mechanism that enhances multimodal correspondence. On the control side, we design a decoupled coordinated flow matching action decoder that explicitly models coordinated base-arm action generation, alleviating optimization difficulties caused by control coupling. Without access to privileged perceptual information, InCoM outperforms state-of-the-art methods on three ManiSkill-HAB scenarios by 28.2%, 26.1%, and 23.6% in success rate, demonstrating strong effectiveness for whole-body mobile manipulation.",
        "authors": [
          "Jiahao Liu",
          "Cui Wenbo",
          "Haoran Li",
          "Dongbin Zhao"
        ],
        "published": "2026-02-26T14:03:58Z",
        "updated": "2026-02-26T14:03:58Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23024v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.23017v1",
        "title": "DigiArm: An Anthropomorphic 3D-Printed Prosthetic Hand with Enhanced Dexterity for Typing Tasks",
        "summary": "Despite recent advancements, existing prosthetic limbs are unable to replicate the dexterity and intuitive control of the human hand. Current control systems for prosthetic hands are often limited to grasping, and commercial prosthetic hands lack the precision needed for dexterous manipulation or applications that require fine finger motions. Thus, there is a critical need for accessible and replicable prosthetic designs that enable individuals to interact with electronic devices and perform precise finger pressing, such as keyboard typing or piano playing, while preserving current prosthetic capabilities. This paper presents a low-cost, lightweight, 3D-printed robotic prosthetic hand, specifically engineered for enhanced dexterity with electronic devices such as a computer keyboard or piano, as well as general object manipulation. The robotic hand features a mechanism to adjust finger abduction/adduction spacing, a 2-D wrist with the inclusion of controlled ulnar/radial deviation optimized for typing, and control of independent finger pressing. We conducted a study to demonstrate how participants can use the robotic hand to perform keyboard typing and piano playing in real time, with different levels of finger and wrist motion. This supports the notion that our proposed design can allow for the execution of key typing motions more effectively than before, aiming to enhance the functionality of prosthetic hands.",
        "authors": [
          "Dean Zadok",
          "Tom Naamani",
          "Yuval Bar-Ratson",
          "Elisha Barash",
          "Oren Salzman",
          "Alon Wolf",
          "Alex M. Bronstein",
          "Nili Krausz"
        ],
        "published": "2026-02-26T13:55:05Z",
        "updated": "2026-02-26T13:55:05Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23017v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22998v1",
        "title": "A Perspective on Open Challenges in Deformable Object Manipulation",
        "summary": "Deformable object manipulation (DOM) represents a critical challenge in robotics, with applications spanning healthcare, manufacturing, food processing, and beyond. Unlike rigid objects, deformable objects exhibit infinite dimensionality, dynamic shape changes, and complex interactions with their environment, posing significant hurdles for perception, modeling, and control. This paper reviews the state of the art in DOM, focusing on key challenges such as occlusion handling, task generalization, and scalable, real-time solutions. It highlights advancements in multimodal perception systems, including the integration of multi-camera setups, active vision, and tactile sensing, which collectively address occlusion and improve adaptability in unstructured environments. Cutting-edge developments in physically informed reinforcement learning (RL) and differentiable simulations are explored, showcasing their impact on efficiency, precision, and scalability. The review also emphasizes the potential of simulated expert demonstrations and generative neural networks to standardize task specifications and bridge the simulation-to-reality gap. Finally, future directions are proposed, including the adoption of graph neural networks for high-level decision-making and the creation of comprehensive datasets to enhance DOM's real-world applicability. By addressing these challenges, DOM research can pave the way for versatile robotic systems capable of handling diverse and dynamic tasks with deformable objects.",
        "authors": [
          "Ryan Paul McKennaa",
          "John Oyekan"
        ],
        "published": "2026-02-26T13:39:30Z",
        "updated": "2026-02-26T13:39:30Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22998v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22952v1",
        "title": "Automated Robotic Needle Puncture for Percutaneous Dilatational Tracheostomy",
        "summary": "Percutaneous dilatational tracheostomy (PDT) is frequently performed on patients in intensive care units for prolonged mechanical ventilation. The needle puncture, as the most critical step of PDT, could lead to adverse consequences such as major bleeding and posterior tracheal wall perforation if performed inaccurately. Current practices of PDT puncture are all performed manually with no navigation assistance, which leads to large position and angular errors (5 mm and 30 degree). To improve the accuracy and reduce the difficulty of the PDT procedure, we propose a system that automates the needle insertion using a velocity-controlled robotic manipulator. Guided using pose data from two electromagnetic sensors, one at the needle tip and the other inside the trachea, the robotic system uses an adaptive constrained controller to adapt the uncertain kinematic parameters online and avoid collisions with the patient's body and tissues near the target. Simulations were performed to validate the controller's implementation, and then four hundred PDT punctures were performed on a mannequin to evaluate the position and angular accuracy. The absolute median puncture position error was 1.7 mm (IQR: 1.9 mm) and midline deviation was 4.13 degree (IQR: 4.55 degree), measured by the sensor inside the trachea. The small deviations from the nominal puncture in a simulated experimental setup and formal guarantees of collision-free insertions suggest the feasibility of the robotic PDT puncture.",
        "authors": [
          "Yuan Tang",
          "Bruno V. Adorno",
          "Brendan A. McGrath",
          "Andrew Weightman"
        ],
        "published": "2026-02-26T12:47:04Z",
        "updated": "2026-02-26T12:47:04Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22952v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22940v1",
        "title": "Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning",
        "summary": "Recent automated vehicle (AV) motion planning strategies evolve around minimizing risk in road traffic. However, they exclusively consider risk from the AV's perspective and, as such, do not address the ethicality of its decisions for other road users. We argue that this does not reduce the risk of each road user, as risk may be different from the perspective of each road user. Indeed, minimizing the risk from the AV's perspective may not imply that the risk from the perspective of other road users is also being minimized; in fact, it may even increase. To test this hypothesis, we propose an AV motion planning strategy that supports switching risk minimization strategies between all road user perspectives. We find that the risk from the perspective of other road users can generally be considered different to the risk from the AV's perspective. Taking a collective risk perspective, i.e., balancing the risks of all road users, we observe an AV that minimizes overall traffic risk the best, while putting itself at slightly higher risk for the benefit of others, which is consistent with human driving behavior. In addition, adopting a collective risk minimization strategy can also be beneficial to the AV's travel efficiency by acting assertively when other road users maintain a low risk estimate of the AV. Yet, the AV drives conservatively when its planned actions are less predictable to other road users, i.e., associated with high risk. We argue that such behavior is a form of self-reflection and a natural prerequisite for socially acceptable AV behavior. We conclude that to facilitate ethicality in road traffic that includes AVs, the risk-perspective of each road user must be considered in the decision-making of AVs.",
        "authors": [
          "Leon Tolksdorf",
          "Arturo Tejada",
          "Christian Birkner",
          "Nathan van de Wouw"
        ],
        "published": "2026-02-26T12:30:44Z",
        "updated": "2026-02-26T12:30:44Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22940v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22923v1",
        "title": "WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents",
        "summary": "While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, the ability to bridge the gap between raw visual perception and complex cognitive reasoning is not merely an enhancement but a critical prerequisite for Autonomous Surface Vessels to execute safe and precise maneuvers. To this end, we present WaterVideoQA, the first large-scale, comprehensive Video Question Answering benchmark specifically engineered for all-waterway environments. This benchmark encompasses 3,029 video clips across six distinct waterway categories, integrating multifaceted variables such as volatile lighting and dynamic weather to rigorously stress-test ASV capabilities across a five-tier hierarchical cognitive framework. Furthermore, we introduce NaviMind, a pioneering multi-agent neuro-symbolic system designed for open-ended maritime reasoning. By synergizing Adaptive Semantic Routing, Situation-Aware Hierarchical Reasoning, and Autonomous Self-Reflective Verification, NaviMind transitions ASVs from superficial pattern matching to regulation-compliant, interpretable decision-making. Experimental results demonstrate that our framework significantly transcends existing baselines, establishing a new paradigm for intelligent, trustworthy interaction in dynamic maritime environments.",
        "authors": [
          "Runwei Guan",
          "Shaofeng Liang",
          "Ningwei Ouyang",
          "Weichen Fei",
          "Shanliang Yao",
          "Wei Dai",
          "Chenhao Ge",
          "Penglei Sun",
          "Xiaohui Zhu",
          "Tao Huang",
          "Ryan Wen Liu",
          "Hui Xiong"
        ],
        "published": "2026-02-26T12:12:40Z",
        "updated": "2026-02-26T12:12:40Z",
        "categories": [
          "cs.CV",
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22923v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22922v1",
        "title": "Bayesian Preference Elicitation: Human-In-The-Loop Optimization of An Active Prosthesis",
        "summary": "Tuning active prostheses for people with amputation is time-consuming and relies on metrics that may not fully reflect user needs. We introduce a human-in-the-loop optimization (HILO) approach that leverages direct user preferences to personalize a standard four-parameter prosthesis controller efficiently. Our method employs preference-based Multiobjective Bayesian Optimization that uses a state-or-the-art acquisition function especially designed for preference learning, and includes two algorithmic variants: a discrete version (\\textit{EUBO-LineCoSpar}), and a continuous version (\\textit{BPE4Prost}). Simulation results on benchmark functions and real-application trials demonstrate efficient convergence, robust preference elicitation, and measurable biomechanical improvements, illustrating the potential of preference-driven tuning for user-centered prosthesis control.",
        "authors": [
          "Sophia Taddei",
          "Wouter Koppen",
          "Eligia Alfio",
          "Stefano Nuzzo",
          "Louis Flynn",
          "Maria Alejandra Diaz",
          "Sebastian Rojas Gonzalez",
          "Tom Dhaene",
          "Kevin De Pauw",
          "Ivo Couckuyt",
          "Tom Verstraten"
        ],
        "published": "2026-02-26T12:11:51Z",
        "updated": "2026-02-26T12:11:51Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22922v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22896v1",
        "title": "DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation",
        "summary": "Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.",
        "authors": [
          "Zebin Yang",
          "Yijiahao Qi",
          "Tong Xie",
          "Bo Yu",
          "Shaoshan Liu",
          "Meng Li"
        ],
        "published": "2026-02-26T11:34:36Z",
        "updated": "2026-02-26T11:34:36Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22896v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22862v1",
        "title": "GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion",
        "summary": "This paper focuses on enhancing the grasping precision and generalization of manipulation policies learned via imitation learning. Diffusion-based policy learning methods have recently become the mainstream approach for robotic manipulation tasks. As grasping is a critical subtask in manipulation, the ability of imitation-learned policies to execute precise and generalizable grasps merits particular attention. Existing imitation learning techniques for grasping often suffer from imprecise grasp executions, limited spatial generalization, and poor object generalization. To address these challenges, we incorporate grasp prior knowledge into the diffusion policy framework. In particular, we employ a latent diffusion policy to guide action chunk decoding with grasp pose prior, ensuring that generated motion trajectories adhere closely to feasible grasp configurations. Furthermore, we introduce a self-supervised reconstruction objective during diffusion to embed the graspness prior: at each reverse diffusion step, we reconstruct wrist-camera images back-projected the graspness from the intermediate representations. Both simulation and real robot experiments demonstrate that our approach significantly outperforms baseline methods and exhibits strong dynamic grasping capabilities.",
        "authors": [
          "Enda Xiang",
          "Haoxiang Ma",
          "Xinzhu Ma",
          "Zicheng Liu",
          "Di Huang"
        ],
        "published": "2026-02-26T10:56:01Z",
        "updated": "2026-02-26T10:56:01Z",
        "categories": [
          "cs.RO",
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22862v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.22854v1",
        "title": "Performance and Experimental Analysis of Strain-based Models for Continuum Robots",
        "summary": "Although strain-based models have been widely adopted in robotics, no comparison beyond the uniform bending test is commonly recognized to assess their performance. In addition, the increasing effort in prototyping continuum robots highlights the need to assess the applicability of these models and the necessity of comprehensive performance evaluation. To address this gap, this work investigates the shape reconstruction abilities of a third-order strain interpolation method, examining its ability to capture both individual and combined deformation effects. These results are compared and discussed against the Geometric-Variable Strain approach. Subsequently, simulation results are experimentally verified by reshaping a slender rod while recording the resulting configurations using cameras. The rod configuration is imposed using a manipulator displacing one of its tips and extracted through reflective markers, without the aid of any other external sensor -- i.e. strain gauges or wrench sensors placed along the rod. The experiments demonstrate good agreement between the model predictions and observed shapes, with average error of 0.58% of the rod length and average computational time of 0.32s per configuration, outperforming existing models.",
        "authors": [
          "Annika Delucchi",
          "Vincenzo Di Paola",
          "Andreas Müller",
          "and Matteo Zoppi"
        ],
        "published": "2026-02-26T10:46:13Z",
        "updated": "2026-02-26T10:46:13Z",
        "categories": [
          "cs.RO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22854v1.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.21670v2",
        "title": "Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning",
        "summary": "Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.",
        "authors": [
          "Tomoya Kawabe",
          "Rin Takano"
        ],
        "published": "2026-02-25T08:08:26Z",
        "updated": "2026-02-26T02:28:18Z",
        "categories": [
          "cs.RO",
          "cs.AI",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21670v2.pdf",
        "category": "robotics"
      },
      {
        "id": "2602.21148v1",
        "title": "A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms",
        "summary": "In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.",
        "authors": [
          "Davis S. Catherman",
          "Carlo Pinciroli"
        ],
        "published": "2026-02-24T17:49:56Z",
        "updated": "2026-02-24T17:49:56Z",
        "categories": [
          "cs.RO",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21148v1.pdf",
        "category": "robotics"
      }
    ],
    "multimodal": [
      {
        "id": "2602.23359v1",
        "title": "SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation",
        "summary": "We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.",
        "authors": [
          "Vaibhav Agrawal",
          "Rishubh Parihar",
          "Pradhaan Bhat",
          "Ravi Kiran Sarvadevabhatla",
          "R. Venkatesh Babu"
        ],
        "published": "2026-02-26T18:59:05Z",
        "updated": "2026-02-26T18:59:05Z",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23359v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23353v1",
        "title": "SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport",
        "summary": "The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.",
        "authors": [
          "Simon Roschmann",
          "Paul Krzakala",
          "Sonia Mazelet",
          "Quentin Bouniot",
          "Zeynep Akata"
        ],
        "published": "2026-02-26T18:55:06Z",
        "updated": "2026-02-26T18:55:06Z",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23353v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23329v1",
        "title": "LLM Novice Uplift on Dual-Use, In Silico Biology Tasks",
        "summary": "Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.",
        "authors": [
          "Chen Bo Calvin Zhang",
          "Christina Q. Knight",
          "Nicholas Kruus",
          "Jason Hausenloy",
          "Pedro Medeiros",
          "Nathaniel Li",
          "Aiden Kim",
          "Yury Orlovskiy",
          "Coleman Breen",
          "Bryce Cai",
          "Jasper Götting",
          "Andrew Bo Liu",
          "Samira Nedungadi",
          "Paula Rodriguez",
          "Yannis Yiming He",
          "Mohamed Shaaban",
          "Zifan Wang",
          "Seth Donoughe",
          "Julian Michael"
        ],
        "published": "2026-02-26T18:37:23Z",
        "updated": "2026-02-26T18:37:23Z",
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.CR",
          "cs.CY",
          "cs.HC"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23329v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23302v1",
        "title": "The logic of KM belief update is contained in the logic of AGM belief revision",
        "summary": "For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $&gt;$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a single axiom, which deals exclusively with unsurprising information, that is, with formulas that were not initially disbelieved.",
        "authors": [
          "Giacomo Bonanno"
        ],
        "published": "2026-02-26T18:09:02Z",
        "updated": "2026-02-26T18:09:02Z",
        "categories": [
          "cs.AI",
          "cs.LO",
          "math.LO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23302v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23286v1",
        "title": "SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables",
        "summary": "Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.",
        "authors": [
          "Sungho Park",
          "Jueun Kim",
          "Wook-Shin Han"
        ],
        "published": "2026-02-26T17:59:51Z",
        "updated": "2026-02-26T17:59:51Z",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.DB",
          "cs.IR"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23286v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23258v1",
        "title": "AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning",
        "summary": "While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.",
        "authors": [
          "Yutong Wang",
          "Siyuan Xiong",
          "Xuebo Liu",
          "Wenkang Zhou",
          "Liang Ding",
          "Miao Zhang",
          "Min Zhang"
        ],
        "published": "2026-02-26T17:31:43Z",
        "updated": "2026-02-26T17:31:43Z",
        "categories": [
          "cs.AI",
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23258v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23235v1",
        "title": "Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents",
        "summary": "Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.",
        "authors": [
          "Zhou Xu",
          "Bowen Zhou",
          "Qi Wang",
          "Shuwen Feng",
          "Jingyu Xiao"
        ],
        "published": "2026-02-26T17:12:40Z",
        "updated": "2026-02-26T17:12:40Z",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23235v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23358v1",
        "title": "A Dataset is Worth 1 MB",
        "summary": "A dataset server must often distribute the same large payload to many clients, incurring massive communication costs. Since clients frequently operate on diverse hardware and software frameworks, transmitting a pre-trained model is often infeasible; instead, agents require raw data to train their own task-specific models locally. While dataset distillation attempts to compress training signals, current methods struggle to scale to high-resolution data and rarely achieve sufficiently small files. In this paper, we propose Pseudo-Labels as Data (PLADA), a method that completely eliminates pixel transmission. We assume agents are preloaded with a large, generic, unlabeled reference dataset (e.g., ImageNet-1K, ImageNet-21K) and communicate a new task by transmitting only the class labels for specific images. To address the distribution mismatch between the reference and target datasets, we introduce a pruning mechanism that filters the reference dataset to retain only the labels of the most semantically relevant images for the target task. This selection process simultaneously maximizes training efficiency and minimizes transmission payload. Experiments on 10 diverse datasets demonstrate that our approach can transfer task knowledge with a payload of less than 1 MB while retaining high classification accuracy, offering a promising solution for efficient dataset serving.",
        "authors": [
          "Elad Kimchi Shoshani",
          "Leeyam Gabay",
          "Yedid Hoshen"
        ],
        "published": "2026-02-26T18:59:03Z",
        "updated": "2026-02-26T18:59:03Z",
        "categories": [
          "cs.LG",
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23358v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23320v1",
        "title": "ParamMem: Augmenting Language Agents with Parametric Reflective Memory",
        "summary": "Self-reflection enables language agents to iteratively refine solutions, yet often produces repetitive outputs that limit reasoning performance. Recent studies have attempted to address this limitation through various approaches, among which increasing reflective diversity has shown promise. Our empirical analysis reveals a strong positive correlation between reflective diversity and task success, further motivating the need for diverse reflection signals. We introduce ParamMem, a parametric memory module that encodes cross-sample reflection patterns into model parameters, enabling diverse reflection generation through temperature-controlled sampling. Building on this module, we propose ParamAgent, a reflection-based agent framework that integrates parametric memory with episodic and cross-sample memory. Extensive experiments on code generation, mathematical reasoning, and multi-hop question answering demonstrate consistent improvements over state-of-the-art baselines. Further analysis reveals that ParamMem is sample-efficient, enables weak-to-strong transfer across model scales, and supports self-improvement without reliance on stronger external model, highlighting the potential of ParamMem as an effective component for enhancing language agents.",
        "authors": [
          "Tianjun Yao",
          "Yongqiang Chen",
          "Yujia Zheng",
          "Pan Li",
          "Zhiqiang Shen",
          "Kun Zhang"
        ],
        "published": "2026-02-26T18:28:04Z",
        "updated": "2026-02-26T18:28:04Z",
        "categories": [
          "cs.LG",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23320v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23295v1",
        "title": "ManifoldGD: Training-Free Hierarchical Manifold Guidance for Diffusion-Based Dataset Distillation",
        "summary": "In recent times, large datasets hinder efficient model training while also containing redundant concepts. Dataset distillation aims to synthesize compact datasets that preserve the knowledge of large-scale training sets while drastically reducing storage and computation. Recent advances in diffusion models have enabled training-free distillation by leveraging pre-trained generative priors; however, existing guidance strategies remain limited. Current score-based methods either perform unguided denoising or rely on simple mode-based guidance toward instance prototype centroids (IPC centroids), which often are rudimentary and suboptimal. We propose Manifold-Guided Distillation (ManifoldGD), a training-free diffusion-based framework that integrates manifold consistent guidance at every denoising timestep. Our method employs IPCs computed via a hierarchical, divisive clustering of VAE latent features, yielding a multi-scale coreset of IPCs that captures both coarse semantic modes and fine intra-class variability. Using a local neighborhood of the extracted IPC centroids, we create the latent manifold for each diffusion denoising timestep. At each denoising step, we project the mode-alignment vector onto the local tangent space of the estimated latent manifold, thus constraining the generation trajectory to remain manifold-faithful while preserving semantic consistency. This formulation improves representativeness, diversity, and image fidelity without requiring any model retraining. Empirical results demonstrate consistent gains over existing training-free and training-based baselines in terms of FID, l2 distance among real and synthetic dataset embeddings, and classification accuracy, establishing ManifoldGD as the first geometry-aware training-free data distillation framework.",
        "authors": [
          "Ayush Roy",
          "Wei-Yang Alex Lee",
          "Rudrasis Chakraborty",
          "Vishnu Suresh Lokhande"
        ],
        "published": "2026-02-26T18:07:10Z",
        "updated": "2026-02-26T18:07:10Z",
        "categories": [
          "cs.CV",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23295v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23214v1",
        "title": "Plug-and-Play Diffusion Meets ADMM: Dual-Variable Coupling for Robust Medical Image Reconstruction",
        "summary": "Plug-and-Play diffusion prior (PnPDP) frameworks have emerged as a powerful paradigm for solving imaging inverse problems by treating pretrained generative models as modular priors. However, we identify a critical flaw in prevailing PnP solvers (e.g., based on HQS or Proximal Gradient): they function as memoryless operators, updating estimates solely based on instantaneous gradients. This lack of historical tracking inevitably leads to non-vanishing steady-state bias, where the reconstruction fails to strictly satisfy physical measurements under heavy corruption. To resolve this, we propose Dual-Coupled PnP Diffusion, which restores the classical dual variable to provide integral feedback, theoretically guaranteeing asymptotic convergence to the exact data manifold. However, this rigorous geometric coupling introduces a secondary challenge: the accumulated dual residuals exhibit spectrally colored, structured artifacts that violate the Additive White Gaussian Noise (AWGN) assumption of diffusion priors, causing severe hallucinations. To bridge this gap, we introduce Spectral Homogenization (SH), a frequency-domain adaptation mechanism that modulates these structured residuals into statistically compliant pseudo-AWGN inputs. This effectively aligns the solver's rigorous optimization trajectory with the denoiser's valid statistical manifold. Extensive experiments on CT and MRI reconstruction demonstrate that our approach resolves the bias-hallucination trade-off, achieving state-of-the-art fidelity with significantly accelerated convergence.",
        "authors": [
          "Chenhe Du",
          "Xuanyu Tian",
          "Qing Wu",
          "Muyu Liu",
          "Jingyi Yu",
          "Hongjiang Wei",
          "Yuyao Zhang"
        ],
        "published": "2026-02-26T16:58:43Z",
        "updated": "2026-02-26T16:58:43Z",
        "categories": [
          "cs.CV",
          "cs.LG",
          "eess.IV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23214v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23201v1",
        "title": "Tell Me What To Learn: Generalizing Neural Memory to be Controllable in Natural Language",
        "summary": "Modern machine learning models are deployed in diverse, non-stationary environments where they must continually adapt to new tasks and evolving knowledge. Continual fine-tuning and in-context learning are costly and brittle, whereas neural memory methods promise lightweight updates with minimal forgetting. However, existing neural memory models typically assume a single fixed objective and homogeneous information streams, leaving users with no control over what the model remembers or ignores over time. To address this challenge, we propose a generalized neural memory system that performs flexible updates based on learning instructions specified in natural language. Our approach enables adaptive agents to learn selectively from heterogeneous information sources, supporting settings, such as healthcare and customer service, where fixed-objective memory updates are insufficient.",
        "authors": [
          "Max S. Bennett",
          "Thomas P. Zollo",
          "Richard Zemel"
        ],
        "published": "2026-02-26T16:50:52Z",
        "updated": "2026-02-26T16:50:52Z",
        "categories": [
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23201v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23200v1",
        "title": "InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models",
        "summary": "Reducing the hardware footprint of large language models (LLMs) during decoding is critical for efficient long-sequence generation. A key bottleneck is the key-value (KV) cache, whose size scales with sequence length and easily dominates the memory footprint of the model. Previous work proposed quantization methods that are focused on compressing the KV cache while maintaining its information. We introduce InnerQ, a hardware-aware KV-cache quantization scheme that lowers decode latency without sacrificing accuracy. InnerQ applies group-wise quantization while grouping the cache matrices over their inner dimension. Unlike previous work that group over the outer dimension, InnerQ aligns dequantization with the vector-matrix multiplication and enables scale factor reuse across GPU compute units. This reduces memory accesses and accelerates dequantization, yielding up to $22\\%$ speedup over previous work and up to $88\\%$ over half-precision vector-matrix multiplication. To preserve fidelity under aggressive compression, InnerQ incorporates (i) hybrid quantization, selecting symmetric or asymmetric quantization per group based on local statistics; (ii) high-precision windows for both the most recent tokens and the attention sink tokens to mitigate outlier leakage; and (iii) per-channel normalization of the key cache, computed once during prefill and folded into the query to avoid runtime overhead. Our evaluation experiments on Llama models shows that InnerQ maintains a few-shot GSM8K performance comparable to non-quantized KV caches and surpasses prior KV cache quantization methods.",
        "authors": [
          "Sayed Mohammadreza Tayaranian Hosseini",
          "Amir Ardakani",
          "Warren J. Gross"
        ],
        "published": "2026-02-26T16:50:36Z",
        "updated": "2026-02-26T16:50:36Z",
        "categories": [
          "cs.LG",
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23200v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23197v1",
        "title": "Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models",
        "summary": "Transformer-based large language models exhibit in-context learning, enabling adaptation to downstream tasks via few-shot prompting with demonstrations. In practice, such models are often fine-tuned to improve zero-shot performance on downstream tasks, allowing them to solve tasks without examples and thereby reducing inference costs. However, fine-tuning can degrade in-context learning, limiting the performance of fine-tuned models on tasks not seen during fine-tuning. Using linear attention models, we provide a theoretical analysis that characterizes how fine-tuning objectives modify attention parameters and identifies conditions under which this leads to degraded few-shot performance. We show that fine-tuning all attention parameters can harm in-context learning, whereas restricting updates to the value matrix improves zero-shot performance while preserving in-context learning. We further show that incorporating an auxiliary few-shot loss enhances in-context learning primarily on the target task, at the expense of degraded in-context learning ability on tasks not seen during fine-tuning. We empirically validate our theoretical results.",
        "authors": [
          "Chungpa Lee",
          "Jy-yong Sohn",
          "Kangwook Lee"
        ],
        "published": "2026-02-26T16:49:15Z",
        "updated": "2026-02-26T16:49:15Z",
        "categories": [
          "cs.CL",
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23197v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23192v1",
        "title": "FairQuant: Fairness-Aware Mixed-Precision Quantization for Medical Image Classification",
        "summary": "Compressing neural networks by quantizing model parameters offers useful trade-off between performance and efficiency. Methods like quantization-aware training and post-training quantization strive to maintain the downstream performance of compressed models compared to the full precision models. However, these techniques do not explicitly consider the impact on algorithmic fairness. In this work, we study fairness-aware mixed-precision quantization schemes for medical image classification under explicit bit budgets. We introduce FairQuant, a framework that combines group-aware importance analysis, budgeted mixed-precision allocation, and a learnable Bit-Aware Quantization (BAQ) mode that jointly optimizes weights and per-unit bit allocations under bitrate and fairness regularization. We evaluate the method on Fitzpatrick17k and ISIC2019 across ResNet18/50, DeiT-Tiny, and TinyViT. Results show that FairQuant configurations with average precision near 4-6 bits recover much of the Uniform 8-bit accuracy while improving worst-group performance relative to Uniform 4- and 8-bit baselines, with comparable fairness metrics under shared budgets.",
        "authors": [
          "Thomas Woergaard",
          "Raghavendra Selvan"
        ],
        "published": "2026-02-26T16:44:47Z",
        "updated": "2026-02-26T16:44:47Z",
        "categories": [
          "cs.CV",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23192v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23179v1",
        "title": "Induction Meets Biology: Mechanisms of Repeat Detection in Protein Language Models",
        "summary": "Protein sequences are abundant in repeating segments, both as exact copies and as approximate segments with mutations. These repeats are important for protein structure and function, motivating decades of algorithmic work on repeat identification. Recent work has shown that protein language models (PLMs) identify repeats, by examining their behavior in masked-token prediction. To elucidate their internal mechanisms, we investigate how PLMs detect both exact and approximate repeats. We find that the mechanism for approximate repeats functionally subsumes that of exact repeats. We then characterize this mechanism, revealing two main stages: PLMs first build feature representations using both general positional attention heads and biologically specialized components, such as neurons that encode amino-acid similarity. Then, induction heads attend to aligned tokens across repeated segments, promoting the correct answer. Our results reveal how PLMs solve this biological task by combining language-based pattern matching with specialized biological knowledge, thereby establishing a basis for studying more complex evolutionary processes in PLMs.",
        "authors": [
          "Gal Kesten-Pomeranz",
          "Yaniv Nikankin",
          "Anja Reusch",
          "Tomer Tsaban",
          "Ora Schueler-Furman",
          "Yonatan Belinkov"
        ],
        "published": "2026-02-26T16:39:04Z",
        "updated": "2026-02-26T16:39:04Z",
        "categories": [
          "cs.LG",
          "q-bio.BM"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23179v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23351v1",
        "title": "Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning",
        "summary": "The lack of reasoning capabilities in Vision-Language Models (VLMs) has remained at the forefront of research discourse. We posit that this behavior stems from a reporting bias in their training data. That is, how people communicate about visual content by default omits tacit information needed to supervise some types of reasoning; e.g., \"at the game today!\" is a more likely caption than \"a photo of 37 people standing behind a field\". We investigate the data underlying the popular VLMs OpenCLIP, LLaVA-1.5 and Molmo through the lens of theories from pragmatics, and find that reporting bias results in insufficient representation of four reasoning skills (spatial, temporal, negation, and counting), despite the corpora being of web-scale, and/or synthetically generated. With a set of curated benchmarks, we demonstrate that: (i) VLMs perform poorly on the aforementioned types of reasoning suppressed in the training data by reporting bias; (ii) contrary to popular belief, scaling data size, model size, and to multiple languages does not result in emergence of these skills by default; but, promisingly, (iii) incorporating annotations specifically collected to obtain tacit information is effective. Our findings highlight the need for more intentional training data curation methods, rather than counting on scale for emergence of reasoning capabilities.",
        "authors": [
          "Amita Kamath",
          "Jack Hessel",
          "Khyathi Chandu",
          "Jena D. Hwang",
          "Kai-Wei Chang",
          "Ranjay Krishna"
        ],
        "published": "2026-02-26T18:54:06Z",
        "updated": "2026-02-26T18:54:06Z",
        "categories": [
          "cs.CL",
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23351v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23300v1",
        "title": "A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations",
        "summary": "Emotion Recognition in Conversations (ERC) presents unique challenges, requiring models to capture the temporal flow of multi-turn dialogues and to effectively integrate cues from multiple modalities. We propose Mixture of Speech-Text Experts for Recognition of Emotions (MiSTER-E), a modular Mixture-of-Experts (MoE) framework designed to decouple two core challenges in ERC: modality-specific context modeling and multimodal information fusion. MiSTER-E leverages large language models (LLMs) fine-tuned for both speech and text to provide rich utterance-level embeddings, which are then enhanced through a convolutional-recurrent context modeling layer. The system integrates predictions from three experts-speech-only, text-only, and cross-modal-using a learned gating mechanism that dynamically weighs their outputs. To further encourage consistency and alignment across modalities, we introduce a supervised contrastive loss between paired speech-text representations and a KL-divergence-based regulariza-tion across expert predictions. Importantly, MiSTER-E does not rely on speaker identity at any stage. Experiments on three benchmark datasets-IEMOCAP, MELD, and MOSI-show that our proposal achieves 70.9%, 69.5%, and 87.9% weighted F1-scores respectively, outperforming several baseline speech-text ERC systems. We also provide various ablations to highlight the contributions made in the proposed approach.",
        "authors": [
          "Soumya Dutta",
          "Smruthi Balaji",
          "Sriram Ganapathy"
        ],
        "published": "2026-02-26T18:08:40Z",
        "updated": "2026-02-26T18:08:40Z",
        "categories": [
          "cs.CL",
          "eess.AS"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23300v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23266v1",
        "title": "Discourse-Aware Dual-Track Streaming Response for Low-Latency Spoken Dialogue Systems",
        "summary": "Achieving human-like responsiveness is a critical yet challenging goal for cascaded spoken dialogue systems. Conventional ASR-LLM-TTS pipelines follow a strictly sequential paradigm, requiring complete transcription and full reasoning before speech synthesis can begin, which results in high response latency. We propose the Discourse-Aware Dual-Track Streaming Response (DDTSR) framework, a low-latency architecture that enables listen-while-thinking and speak-while-thinking. DDTSR is built upon three key mechanisms: (1) connective-guided small-large model synergy, where an auxiliary small model generates minimal-committal discourse connectives while a large model performs knowledge-intensive reasoning in parallel; (2) streaming-based cross-modal collaboration, which dynamically overlaps ASR, LLM inference, and TTS to advance the earliest speakable moment; and (3) curriculum-learning-based discourse continuity enhancement, which maintains coherence and logical consistency between early responses and subsequent reasoning outputs. Experiments on two spoken dialogue benchmarks demonstrate that DDTSR reduces response latency by 19%-51% while preserving discourse quality. Further analysis shows that DDTSR functions as a plug-and-play module compatible with diverse LLM backbones, and remains robust across varying utterance lengths, indicating strong practicality and scalability for real-time spoken interaction.",
        "authors": [
          "Siyuan Liu",
          "Jiahui Xu",
          "Feng Jiang",
          "Kuang Wang",
          "Zefeng Zhao",
          "Chu-Ren Huang",
          "Jinghang Gu",
          "Changqing Yin",
          "Haizhou Li"
        ],
        "published": "2026-02-26T17:39:56Z",
        "updated": "2026-02-26T17:39:56Z",
        "categories": [
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23266v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23225v1",
        "title": "Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?",
        "summary": "Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at https://github.com/pixeli99/NAP.",
        "authors": [
          "Pengxiang Li",
          "Dilxat Muhtar",
          "Lu Yin",
          "Tianlong Chen",
          "Shiwei Liu"
        ],
        "published": "2026-02-26T17:04:57Z",
        "updated": "2026-02-26T17:04:57Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23225v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23184v1",
        "title": "MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations",
        "summary": "We present MTRAG-UN, a benchmark for exploring open challenges in multi-turn retrieval augmented generation, a popular use of large language models. We release a benchmark of 666 tasks containing over 2,800 conversation turns across 6 domains with accompanying corpora. Our experiments show that retrieval and generation models continue to struggle on conversations with UNanswerable, UNderspecified, and NONstandalone questions and UNclear responses. Our benchmark is available at https://github.com/IBM/mt-rag-benchmark",
        "authors": [
          "Sara Rosenthal",
          "Yannis Katsis",
          "Vraj Shah",
          "Lihong He",
          "Lucian Popa",
          "Marina Danilevsky"
        ],
        "published": "2026-02-26T16:41:17Z",
        "updated": "2026-02-26T16:41:17Z",
        "categories": [
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23184v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23163v1",
        "title": "A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring",
        "summary": "Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \\textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.",
        "authors": [
          "Usman Anwar",
          "Julianna Piskorz",
          "David D. Baek",
          "David Africa",
          "Jim Weatherall",
          "Max Tegmark",
          "Christian Schroeder de Witt",
          "Mihaela van der Schaar",
          "David Krueger"
        ],
        "published": "2026-02-26T16:27:24Z",
        "updated": "2026-02-26T16:27:24Z",
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.CR",
          "cs.IT",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23163v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23136v1",
        "title": "Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs",
        "summary": "Multimodal LLMs can process speech and images, but they cannot hear a speaker's voice or see an object's texture. We show this is not a failure of encoding: speaker identity, emotion, and visual attributes survive through every LLM layer (3--55$\\times$ above chance in linear probes), yet removing 64--71% of modality-specific variance improves decoder loss. The decoder has no learned use for these directions; their presence is noise. We formalize this as a mismatched decoder problem: a decoder trained on text can only extract information along text-aligned directions. Accessible information is bounded by the Generalized Mutual Information (GMI), with degradation scaling with distributional distance and decoder sensitivity. The bound is a property of the decoder's scoring rule, not of any particular architecture; it applies whether non-text inputs arrive through a learned projection, a discrete codebook, or no explicit adapter at all. We validate this across five models spanning speech and vision. A controlled experiment (two Prismatic VLMs differing only in encoder text-alignment) confirms the bottleneck is the decoder's scoring rule, not the encoder or projection. A LoRA intervention demonstrates the fix: training with an emotion objective improves emotion accessibility ($+$7.5%) without affecting other attributes, confirming that the training objective determines what becomes accessible.",
        "authors": [
          "Jayadev Billa"
        ],
        "published": "2026-02-26T15:52:48Z",
        "updated": "2026-02-26T15:52:48Z",
        "categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23136v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23079v1",
        "title": "Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent",
        "summary": "The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.",
        "authors": [
          "Boyang Zhang",
          "Yang Zhang"
        ],
        "published": "2026-02-26T15:05:13Z",
        "updated": "2026-02-26T15:05:13Z",
        "categories": [
          "cs.CL",
          "cs.CR",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23079v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23075v1",
        "title": "CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery",
        "summary": "Large language models (LLMs) have created new opportunities to enhance the efficiency of scholarly activities; however, challenges persist in the ethical deployment of AI assistance, including (1) the trustworthiness of AI-generated content, (2) preservation of academic integrity and intellectual property, and (3) protection of information privacy. In this work, we present CiteLLM, a specialized agentic platform designed to enable trustworthy reference discovery for grounding author-drafted claims and statements. The system introduces a novel interaction paradigm by embedding LLM utilities directly within the LaTeX editor environment, ensuring a seamless user experience and no data transmission outside the local system. To guarantee hallucination-free references, we employ dynamic discipline-aware routing to retrieve candidates exclusively from trusted web-based academic repositories, while leveraging LLMs solely for generating context-aware search queries, ranking candidates by relevance, and validating and explaining support through paragraph-level semantic matching and an integrated chatbot. Evaluation results demonstrate the superior performance of the proposed system in returning valid and highly usable references.",
        "authors": [
          "Mengze Hong",
          "Di Jiang",
          "Chen Jason Zhang",
          "Zichang Guo",
          "Yawen Li",
          "Jun Chen",
          "Shaobo Cui",
          "Zhiyang Su"
        ],
        "published": "2026-02-26T15:02:22Z",
        "updated": "2026-02-26T15:02:22Z",
        "categories": [
          "cs.CL",
          "cs.IR"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23075v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23071v1",
        "title": "Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody",
        "summary": "While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subject-Verb (SBV) interface (Major Phrase B3 -&gt; Prosodic Word B1), while erroneously promoting the boundary at the Verb-Object (VOB) interface (Prosodic Word B1 -&gt; Major Phrase B3). This strategy allows learners to maintain high long phrasal output at the expense of structural accuracy. This results in a distorted prosodic hierarchy where the native pattern is inverted.",
        "authors": [
          "Yuqi Shi",
          "Hao Yang",
          "Xiyao Lu",
          "Jinsong Zhang"
        ],
        "published": "2026-02-26T15:00:59Z",
        "updated": "2026-02-26T15:00:59Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23071v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23070v1",
        "title": "Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization via Extreme Augmentation and Perfect Alignment",
        "summary": "Although Automatic Speech Recognition (ASR) in Bengali has seen significant progress, processing long-duration audio and performing robust speaker diarization remain critical research gaps. To address the severe scarcity of joint ASR and diarization resources for this language, we introduce Lipi-Ghor-882, a comprehensive 882-hour multi-speaker Bengali dataset. In this paper, detailing our submission to the DL Sprint 4.0 competition, we systematically evaluate various architectures and approaches for long-form Bengali speech. For ASR, we demonstrate that raw data scaling is ineffective; instead, targeted fine-tuning utilizing perfectly aligned annotations paired with synthetic acoustic degradation (noise and reverberation) emerges as the singular most effective approach. Conversely, for speaker diarization, we observed that global open-source state-of-the-art models (such as Diarizen) performed surprisingly poorly on this complex dataset. Extensive model retraining yielded negligible improvements; instead, strategic, heuristic post-processing of baseline model outputs proved to be the primary driver for increasing accuracy. Ultimately, this work outlines a highly optimized dual pipeline achieving a $\\sim$0.019 Real-Time Factor (RTF), establishing a practical, empirically backed benchmark for low-resource, long-form speech processing.",
        "authors": [
          "Sanjid Hasan",
          "Risalat Labib",
          "A H M Fuad",
          "Bayazid Hasan"
        ],
        "published": "2026-02-26T14:59:24Z",
        "updated": "2026-02-26T14:59:24Z",
        "categories": [
          "cs.SD",
          "cs.AI",
          "cs.CL",
          "eess.AS"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23070v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23062v1",
        "title": "Toward Automatic Filling of Case Report Forms: A Case Study on Data from an Italian Emergency Department",
        "summary": "Case Report Forms (CRFs) collect data about patients and are at the core of well-established practices to conduct research in clinical settings. With the recent progress of language technologies, there is an increasing interest in automatic CRF-filling from clinical notes, mostly based on the use of Large Language Models (LLMs). However, there is a general scarcity of annotated CRF data, both for training and testing LLMs, which limits the progress on this task. As a step in the direction of providing such data, we present a new dataset of clinical notes from an Italian Emergency Department annotated with respect to a pre-defined CRF containing 134 items to be filled. We provide an analysis of the data, define the CRF-filling task and metric for its evaluation, and report on pilot experiments where we use an open-source state-of-the-art LLM to automatically execute the task. Results of the case-study show that (i) CRF-filling from real clinical notes in Italian can be approached in a zero-shot setting; (ii) LLMs' results are affected by biases (e.g., a cautious behaviour favours \"unknown\" answers), which need to be corrected.",
        "authors": [
          "Gabriela Anna Kaczmarek",
          "Pietro Ferrazzi",
          "Lorenzo Porta",
          "Vicky Rubini",
          "Bernardo Magnini"
        ],
        "published": "2026-02-26T14:49:11Z",
        "updated": "2026-02-26T14:49:11Z",
        "categories": [
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23062v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23061v1",
        "title": "MoDora: Tree-Based Semi-Structured Document Analysis System",
        "summary": "Semi-structured documents integrate diverse interleaved data elements (e.g., tables, charts, hierarchical paragraphs) arranged in various and often irregular layouts. These documents are widely observed across domains and account for a large portion of real-world data. However, existing methods struggle to support natural language question answering over these documents due to three main technical challenges: (1) The elements extracted by techniques like OCR are often fragmented and stripped of their original semantic context, making them inadequate for analysis. (2) Existing approaches lack effective representations to capture hierarchical structures within documents (e.g., associating tables with nested chapter titles) and to preserve layout-specific distinctions (e.g., differentiating sidebars from main content). (3) Answering questions often requires retrieving and aligning relevant information scattered across multiple regions or pages, such as linking a descriptive paragraph to table cells located elsewhere in the document. To address these issues, we propose MoDora, an LLM-powered system for semi-structured document analysis. First, we adopt a local-alignment aggregation strategy to convert OCR-parsed elements into layout-aware components, and conduct type-specific information extraction for components with hierarchical titles or non-text elements. Second, we design the Component-Correlation Tree (CCTree) to hierarchically organize components, explicitly modeling inter-component relations and layout distinctions through a bottom-up cascade summarization process. Finally, we propose a question-type-aware retrieval strategy that supports (1) layout-based grid partitioning for location-based retrieval and (2) LLM-guided pruning for semantic-based retrieval. Experiments show MoDora outperforms baselines by 5.97%-61.07% in accuracy. The code is at https://github.com/weAIDB/MoDora.",
        "authors": [
          "Bangrui Xu",
          "Qihang Yao",
          "Zirui Tang",
          "Xuanhe Zhou",
          "Yeye He",
          "Shihan Yu",
          "Qianqian Xu",
          "Bin Wang",
          "Guoliang Li",
          "Conghui He",
          "Fan Wu"
        ],
        "published": "2026-02-26T14:48:49Z",
        "updated": "2026-02-26T14:48:49Z",
        "categories": [
          "cs.IR",
          "cs.AI",
          "cs.CL",
          "cs.DB",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23061v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23057v1",
        "title": "Affine-Scaled Attention: Towards Flexible and Stable Transformer Attention",
        "summary": "Transformer attention is typically implemented using softmax normalization, which enforces attention weights with unit sum normalization. While effective in many settings, this constraint can limit flexibility in controlling attention magnitudes and may contribute to overly concentrated or unstable attention patterns during training. Prior work has explored modifications such as attention sinks or gating mechanisms, but these approaches provide only limited or indirect control over attention reweighting. We propose Affine-Scaled Attention, a simple extension to standard attention that introduces input-dependent scaling and a corresponding bias term applied to softmax-normalized attention weights. This design relaxes the strict normalization constraint while maintaining aggregation of value representations, allowing the model to adjust both the relative distribution and the scale of attention in a controlled manner. We empirically evaluate Affine-Scaled Attention in large-scale language model pretraining across multiple model sizes. Experimental results show consistent improvements in training stability, optimization behavior, and downstream task performance compared to standard softmax attention and attention sink baselines. These findings suggest that modest reweighting of attention outputs provides a practical and effective way to improve attention behavior in Transformer models.",
        "authors": [
          "Jeongin Bae",
          "Baeseong Park",
          "Gunho Park",
          "Minsub Kim",
          "Joonhyung Lee",
          "Junhee Yoo",
          "Sunghyeon Woo",
          "Jiwon Ryu",
          "Se Jung Kwon",
          "Dongsoo Lee"
        ],
        "published": "2026-02-26T14:42:16Z",
        "updated": "2026-02-26T14:42:16Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23057v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22958v1",
        "title": "Frequency-Ordered Tokenization for Better Text Compression",
        "summary": "We present frequency-ordered tokenization, a simple preprocessing technique that improves lossless text compression by exploiting the power-law frequency distribution of natural language tokens (Zipf's law). The method tokenizes text with Byte Pair Encoding (BPE), reorders the vocabulary so that frequent tokens receive small integer identifiers, and encodes the result with variable-length integers before passing it to any standard compressor. On enwik8 (100 MB Wikipedia), this yields improvements of 7.08 percentage points (pp) for zlib, 1.69 pp for LZMA, and 0.76 pp for zstd (all including vocabulary overhead), outperforming the classical Word Replacing Transform. Gains are consistent at 1 GB scale (enwik9) and across Chinese and Arabic text. We further show that preprocessing accelerates compression for computationally expensive algorithms: the total wall-clock time including preprocessing is 3.1x faster than raw zstd-22 and 2.4x faster than raw LZMA, because the preprocessed input is substantially smaller. The method can be implemented in under 50 lines of code.",
        "authors": [
          "Maximilian Kalcher"
        ],
        "published": "2026-02-26T12:53:48Z",
        "updated": "2026-02-26T12:53:48Z",
        "categories": [
          "cs.IT",
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22958v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22918v1",
        "title": "Where Vision Becomes Text: Locating the OCR Routing Bottleneck in Vision-Language Models",
        "summary": "Vision-language models (VLMs) can read text from images, but where does this optical character recognition (OCR) information enter the language processing stream? We investigate the OCR routing mechanism across three architecture families (Qwen3-VL, Phi-4, InternVL3.5) using causal interventions. By computing activation differences between original images and text-inpainted versions, we identify architecture-specific OCR bottlenecks whose dominant location depends on the vision-language integration strategy: DeepStack models (Qwen) show peak sensitivity at mid-depth (about 50%) for scene text, while single-stage projection models (Phi-4, InternVL) peak at early layers (6-25%), though the exact layer of maximum effect varies across datasets. The OCR signal is remarkably low-dimensional: PC1 captures 72.9% of variance. Crucially, principal component analysis (PCA) directions learned on one dataset transfer to others, demonstrating shared text-processing pathways. Surprisingly, in models with modular OCR circuits (notably Qwen3-VL-4B), OCR removal can improve counting performance (up to +6.9 percentage points), suggesting OCR interferes with other visual processing in sufficiently modular architectures.",
        "authors": [
          "Jonathan Steinberg",
          "Oren Gal"
        ],
        "published": "2026-02-26T12:06:02Z",
        "updated": "2026-02-26T12:06:02Z",
        "categories": [
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22918v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22911v1",
        "title": "NoRA: Breaking the Linear Ceiling of Low-Rank Adaptation via Manifold Expansion",
        "summary": "Low-Rank Adaptation (LoRA) dominates parameter-efficient fine-tuning (PEFT). However, it faces a critical ``linear ceiling'' in complex reasoning tasks: simply increasing the rank yields diminishing returns due to intrinsic linear constraints. We introduce NoRA (Non-linear Rank Adaptation), a weight-level parallel adapter that injects SiLU gating and structural dropout to induce manifold expansion. On the SlimOrca benchmark, NoRA breaks this linear barrier: NoRA remarkably at rank 64 (PPL 3.89) outperforms LoRA at rank 512 (PPL 3.90), demonstrating superior spectral efficiency. This advantage generalizes to mathematical reasoning, where NoRA achieves a perplexity of 1.97 on MathInstruct, significantly surpassing LoRA's saturation point of 2.07. Mechanism analysis via Singular Value Decomposition (SVD) confirms that NoRA activates the dormant tail of the singular value spectrum, effectively preventing the rank collapse observed in linear methods.",
        "authors": [
          "Hung-Hsuan Chen"
        ],
        "published": "2026-02-26T11:55:25Z",
        "updated": "2026-02-26T11:55:25Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22911v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22897v1",
        "title": "OmniGAIA: Towards Native Omni-Modal AI Agents",
        "summary": "Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.",
        "authors": [
          "Xiaoxi Li",
          "Wenxiang Jiao",
          "Jiarui Jin",
          "Shijian Wang",
          "Guanting Dong",
          "Jiajie Jin",
          "Hao Wang",
          "Yinuo Wang",
          "Ji-Rong Wen",
          "Yuan Lu",
          "Zhicheng Dou"
        ],
        "published": "2026-02-26T11:35:04Z",
        "updated": "2026-02-26T11:35:04Z",
        "categories": [
          "cs.AI",
          "cs.CL",
          "cs.CV",
          "cs.LG",
          "cs.MM"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22897v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22871v1",
        "title": "Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching",
        "summary": "Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or \"nearly correct\" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions an autoregressive (AR) model (solver) to recompute only the final answer. This modular pipeline separates exploration (diffusion) from evaluation and solution synthesis, avoiding monolithic unified hybrids while preserving broad search. Across math reasoning benchmarks, we find that step-level recombination is most beneficial on harder problems, and ablations highlight the importance of the final AR solver in converting stitched but imperfect rationales into accurate answers. Using low-confidence diffusion sampling with parallel, independent rollouts, our training-free framework improves average accuracy by up to 23.8% across six math and coding tasks. At the same time, it achieves up to a 1.8x latency reduction relative to both traditional diffusion models (e.g., Dream, LLaDA) and unified architectures (e.g., TiDAR). Code is available at https://github.com/roymiles/diffusion-stitching.",
        "authors": [
          "Roy Miles",
          "Aysim Toker",
          "Andreea-Maria Oncescu",
          "Songcen Xu",
          "Jiankang Deng",
          "Ismail Elezi"
        ],
        "published": "2026-02-26T11:08:39Z",
        "updated": "2026-02-26T11:08:39Z",
        "categories": [
          "cs.CL",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22871v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22868v1",
        "title": "Rejection Mixing: Fast Semantic Propagation of Mask Tokens for Efficient DLLM Inference",
        "summary": "Diffusion Large Language Models (DLLMs) promise fast non-autoregressive inference but suffer a severe quality-speed trade-off in parallel decoding. This stems from the ''combinatorial contradiction'' phenomenon, where parallel tokens form semantically inconsistent combinations. We address this by integrating continuous representations into the discrete decoding process, as they preserve rich inter-position dependency. We propose ReMix (Rejection Mixing), a framework that introduces a novel Continuous Mixing State as an intermediate between the initial masked state and the final decoded token state. This intermediate state allows a token's representation to be iteratively refined in a continuous space, resolving mutual conflicts with other tokens before collapsing into a final discrete sample. Furthermore, a rejection rule reverts uncertain representations from the continuous state back to the masked state for reprocessing, ensuring stability and preventing error propagation. ReMix thus mitigates combinatorial contradictions by enabling continuous-space refinement during discrete diffusion decoding. Extensive experiments demonstrate that ReMix, as a training-free method, achieves a $2-8 \\times$ inference speedup without any quality degradation.",
        "authors": [
          "Yushi Ye",
          "Feng Hong",
          "Huangjie Zheng",
          "Xu Chen",
          "Zhiyong Chen",
          "Yanfeng Wang",
          "Jiangchao Yao"
        ],
        "published": "2026-02-26T11:08:11Z",
        "updated": "2026-02-26T11:08:11Z",
        "categories": [
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22868v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23363v1",
        "title": "MediX-R1: Open Ended Medical Reinforcement Learning",
        "summary": "We introduce MediX-R1, an open-ended Reinforcement Learning (RL) framework for medical multimodal large language models (MLLMs) that enables clinically grounded, free-form answers beyond multiple-choice formats. MediX-R1 fine-tunes a baseline vision-language backbone with Group Based RL and a composite reward tailored for medical reasoning: an LLM-based accuracy reward that judges semantic correctness with a strict YES/NO decision, a medical embedding-based semantic reward to capture paraphrases and terminology variants, and lightweight format and modality rewards that enforce interpretable reasoning and modality recognition. This multi-signal design provides stable, informative feedback for open-ended outputs where traditional verifiable or MCQ-only rewards fall short. To measure progress, we propose a unified evaluation framework for both text-only and image+text tasks that uses a Reference-based LLM-as-judge in place of brittle string-overlap metrics, capturing semantic correctness, reasoning, and contextual alignment. Despite using only $\\sim51$K instruction examples, MediX-R1 achieves excellent results across standard medical LLM (text-only) and VLM (image + text) benchmarks, outperforming strong open-source baselines and delivering particularly large gains on open-ended clinical tasks. Our results demonstrate that open-ended RL with comprehensive reward signals and LLM-based evaluation is a practical path toward reliable medical reasoning in multimodal models. Our trained models, curated datasets and source code are available at https://medix.cvmbzuai.com",
        "authors": [
          "Sahal Shaji Mullappilly",
          "Mohammed Irfan Kurpath",
          "Omair Mohamed",
          "Mohamed Zidan",
          "Fahad Khan",
          "Salman Khan",
          "Rao Anwer",
          "Hisham Cholakkal"
        ],
        "published": "2026-02-26T18:59:46Z",
        "updated": "2026-02-26T18:59:46Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23363v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23361v1",
        "title": "VGG-T$^3$: Offline Feed-Forward 3D Reconstruction at Scale",
        "summary": "We present a scalable 3D reconstruction model that addresses a critical limitation in offline feed-forward methods: their computational and memory requirements grow quadratically w.r.t. the number of input images. Our approach is built on the key insight that this bottleneck stems from the varying-length Key-Value (KV) space representation of scene geometry, which we distill into a fixed-size Multi-Layer Perceptron (MLP) via test-time training. VGG-T$^3$ (Visual Geometry Grounded Test Time Training) scales linearly w.r.t. the number of input views, similar to online models, and reconstructs a $1k$ image collection in just $54$ seconds, achieving a $11.6\\times$ speed-up over baselines that rely on softmax attention. Since our method retains global scene aggregation capability, our point map reconstruction error outperforming other linear-time methods by large margins. Finally, we demonstrate visual localization capabilities of our model by querying the scene representation with unseen images.",
        "authors": [
          "Sven Elflein",
          "Ruilong Li",
          "Sérgio Agostinho",
          "Zan Gojcic",
          "Laura Leal-Taixé",
          "Qunjie Zhou",
          "Aljosa Osep"
        ],
        "published": "2026-02-26T18:59:33Z",
        "updated": "2026-02-26T18:59:33Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23361v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23357v1",
        "title": "Sensor Generalization for Adaptive Sensing in Event-based Object Detection via Joint Distribution Training",
        "summary": "Bio-inspired event cameras have recently attracted significant research due to their asynchronous and low-latency capabilities. These features provide a high dynamic range and significantly reduce motion blur. However, because of the novelty in the nature of their output signals, there is a gap in the variability of available data and a lack of extensive analysis of the parameters characterizing their signals. This paper addresses these issues by providing readers with an in-depth understanding of how intrinsic parameters affect the performance of a model trained on event data, specifically for object detection. We also use our findings to expand the capabilities of the downstream model towards sensor-agnostic robustness.",
        "authors": [
          "Aheli Saha",
          "René Schuster",
          "Didier Stricker"
        ],
        "published": "2026-02-26T18:57:52Z",
        "updated": "2026-02-26T18:57:52Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23357v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23339v1",
        "title": "Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?",
        "summary": "Open-vocabulary segmentation (OVS) extends the zero-shot recognition capabilities of vision-language models (VLMs) to pixel-level prediction, enabling segmentation of arbitrary categories specified by text prompts. Despite recent progress, OVS lags behind fully supervised approaches due to two challenges: the coarse image-level supervision used to train VLMs and the semantic ambiguity of natural language. We address these limitations by introducing a few-shot setting that augments textual prompts with a support set of pixel-annotated images. Building on this, we propose a retrieval-augmented test-time adapter that learns a lightweight, per-image classifier by fusing textual and visual support features. Unlike prior methods relying on late, hand-crafted fusion, our approach performs learned, per-query fusion, achieving stronger synergy between modalities. The method supports continually expanding support sets, and applies to fine-grained tasks such as personalized segmentation. Experiments show that we significantly narrow the gap between zero-shot and supervised segmentation while preserving open-vocabulary ability.",
        "authors": [
          "Tilemachos Aravanis",
          "Vladan Stojnić",
          "Bill Psomas",
          "Nikos Komodakis",
          "Giorgos Tolias"
        ],
        "published": "2026-02-26T18:45:33Z",
        "updated": "2026-02-26T18:45:33Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23339v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23306v1",
        "title": "ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding",
        "summary": "Omni-modal reasoning is essential for intelligent systems to understand and draw inferences from diverse data sources. While existing omni-modal large language models (OLLM) excel at perceiving diverse modalities, they lack the complex reasoning abilities of recent large reasoning models (LRM). However, enhancing the reasoning ability of OLLMs through additional training presents significant challenges, including the need for high-quality data, task-specific adaptation, and substantial computational costs. To address these limitations, we propose ThinkOmni, a training-free and data-free framework that lifts textual reasoning to omni-modal scenarios. ThinkOmni introduces two key components: 1) LRM-as-a-Guide, which leverages off-the-shelf LRMs to guide the OLLM decoding process; 2) Stepwise Contrastive Scaling, which adaptively balances perception and reasoning signals without manual hyperparameter tuning. Experiments on six multi-modal reasoning benchmarks demonstrate that ThinkOmni consistently delivers performance improvements, with main results achieving 70.2 on MathVista and 75.5 on MMAU. Overall, ThinkOmni offers a flexible and generalizable solution for omni-modal reasoning and provides new insights into the generalization and application of reasoning capabilities.",
        "authors": [
          "Yiran Guan",
          "Sifan Tu",
          "Dingkang Liang",
          "Linghao Zhu",
          "Jianzhong Ju",
          "Zhenbo Luo",
          "Jian Luan",
          "Yuliang Liu",
          "Xiang Bai"
        ],
        "published": "2026-02-26T18:10:41Z",
        "updated": "2026-02-26T18:10:41Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23306v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23297v1",
        "title": "PRIMA: Pre-training with Risk-integrated Image-Metadata Alignment for Medical Diagnosis via LLM",
        "summary": "Medical diagnosis requires the effective synthesis of visual manifestations and clinical metadata. However, existing methods often treat metadata as isolated tags, failing to exploit the rich semantic knowledge embedded in clinical descriptions. We propose PRIMA (Pre-training with Risk-integrated Image-Metadata Alignment), a framework that integrates domain-specific knowledge into multi-modal representation learning. We first curate an expert corpus of risk-disease correlations via Retrieval-Augmented Generation (RAG) to refine Clinical ModernBERT, embedding diagnostic priors into the text encoder. To bridge the modality gap, we introduce a dual-encoder pre-training strategy utilizing DINOv3 and our refined BERT, optimized by a suite of four complementary loss functions. These losses are designed to capture multi-granular semantic alignment and handle the ambiguity of clinical correlations through soft labels. Finally, we leverage Qwen-3 to fuse these aligned features for precise disease classification. Extensive experiments demonstrate that PRIMA effectively harmonizes pixel-level features with abstract clinical expertise, significantly outperforming other state-of-the-art methods. Notably, our framework achieves superior robustness without the need for massive data collection or exhaustive computational resources. Our code will be made public upon acceptance.",
        "authors": [
          "Yiqing Wang",
          "Chunming He",
          "Ming-Chen Lu",
          "Mercy Pawar",
          "Leslie Niziol",
          "Maria Woodward",
          "Sina Farsiu"
        ],
        "published": "2026-02-26T18:07:52Z",
        "updated": "2026-02-26T18:07:52Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23297v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23294v1",
        "title": "Towards Long-Form Spatio-Temporal Video Grounding",
        "summary": "In real scenarios, videos can span several minutes or even hours. However, existing research on spatio-temporal video grounding (STVG), given a textual query, mainly focuses on localizing targets in short videos of tens of seconds, typically less than one minute, which limits real-world applications. In this paper, we explore Long-Form STVG (LF-STVG), which aims to locate targets in long-term videos. Compared with short videos, long-term videos contain much longer temporal spans and more irrelevant information, making it difficult for existing STVG methods that process all frames at once. To address this challenge, we propose an AutoRegressive Transformer architecture for LF-STVG, termed ART-STVG. Unlike conventional STVG methods that require the entire video sequence to make predictions at once, ART-STVG treats the video as streaming input and processes frames sequentially, enabling efficient handling of long videos. To model spatio-temporal context, we design spatial and temporal memory banks and apply them to the decoders. Since memories from different moments are not always relevant to the current frame, we introduce simple yet effective memory selection strategies to provide more relevant information to the decoders, significantly improving performance. Furthermore, instead of parallel spatial and temporal localization, we propose a cascaded spatio-temporal design that connects the spatial decoder to the temporal decoder, allowing fine-grained spatial cues to assist complex temporal localization in long videos. Experiments on newly extended LF-STVG datasets show that ART-STVG significantly outperforms state-of-the-art methods, while achieving competitive performance on conventional short-form STVG.",
        "authors": [
          "Xin Gu",
          "Bing Fan",
          "Jiali Yao",
          "Zhipeng Zhang",
          "Yan Huang",
          "Cheng Han",
          "Heng Fan",
          "Libo Zhang"
        ],
        "published": "2026-02-26T18:04:09Z",
        "updated": "2026-02-26T18:04:09Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23294v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23292v1",
        "title": "PGVMS: A Prompt-Guided Unified Framework for Virtual Multiplex IHC Staining with Pathological Semantic Learning",
        "summary": "Immunohistochemical (IHC) staining enables precise molecular profiling of protein expression, with over 200 clinically available antibody-based tests in modern pathology. However, comprehensive IHC analysis is frequently limited by insufficient tissue quantities in small biopsies. Therefore, virtual multiplex staining emerges as an innovative solution to digitally transform H&amp;E images into multiple IHC representations, yet current methods still face three critical challenges: (1) inadequate semantic guidance for multi-staining, (2) inconsistent distribution of immunochemistry staining, and (3) spatial misalignment across different stain modalities. To overcome these limitations, we present a prompt-guided framework for virtual multiplex IHC staining using only uniplex training data (PGVMS). Our framework introduces three key innovations corresponding to each challenge: First, an adaptive prompt guidance mechanism employing a pathological visual language model dynamically adjusts staining prompts to resolve semantic guidance limitations (Challenge 1). Second, our protein-aware learning strategy (PALS) maintains precise protein expression patterns by direct quantification and constraint of protein distributions (Challenge 2). Third, the prototype-consistent learning strategy (PCLS) establishes cross-image semantic interaction to correct spatial misalignments (Challenge 3).",
        "authors": [
          "Fuqiang Chen",
          "Ranran Zhang",
          "Wanming Hu",
          "Deboch Eyob Abera",
          "Yue Peng",
          "Boyun Zheng",
          "Yiwen Sun",
          "Jing Cai",
          "Wenjian Qin"
        ],
        "published": "2026-02-26T18:03:24Z",
        "updated": "2026-02-26T18:03:24Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23292v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23290v1",
        "title": "LineGraph2Road: Structural Graph Reasoning on Line Graphs for Road Network Extraction",
        "summary": "The accurate and automatic extraction of roads from satellite imagery is critical for applications in navigation and urban planning, significantly reducing the need for manual annotation. Many existing methods decompose this task into keypoint extraction and connectedness prediction, but often struggle to capture long-range dependencies and complex topologies. Here, we propose LineGraph2Road, a framework that improves connectedness prediction by formulating it as binary classification over edges in a constructed global but sparse Euclidean graph, where nodes are keypoints extracted from segmentation masks and edges connect node pairs within a predefined distance threshold, representing potential road segments. To better learn structural link representation, we transform the original graph into its corresponding line graph and apply a Graph Transformer on it for connectedness prediction. This formulation overcomes the limitations of endpoint-embedding fusion on set-isomorphic links, enabling rich link representations and effective relational reasoning over the global structure. Additionally, we introduce an overpass/underpass head to resolve multi-level crossings and a coupled NMS strategy to preserve critical connections. We evaluate LineGraph2Road on three benchmarks: City-scale, SpaceNet, and Global-scale, and show that it achieves state-of-the-art results on two key metrics, TOPO-F1 and APLS. It also captures fine visual details critical for real-world deployment. We will make our code publicly available.",
        "authors": [
          "Zhengyang Wei",
          "Renzhi Jing",
          "Yiyi He",
          "Jenny Suckale"
        ],
        "published": "2026-02-26T18:02:44Z",
        "updated": "2026-02-26T18:02:44Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23290v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23262v1",
        "title": "Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling",
        "summary": "Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks.",
        "authors": [
          "Jasmine Bayrooti",
          "Weiwei Kong",
          "Natalia Ponomareva",
          "Carlos Esteves",
          "Ameesh Makadia",
          "Amanda Prorok"
        ],
        "published": "2026-02-26T17:36:48Z",
        "updated": "2026-02-26T17:36:48Z",
        "categories": [
          "cs.CV",
          "cs.CR"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23262v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23231v1",
        "title": "Skarimva: Skeleton-based Action Recognition is a Multi-view Application",
        "summary": "Human action recognition plays an important role when developing intelligent interactions between humans and machines. While there is a lot of active research on improving the machine learning algorithms for skeleton-based action recognition, not much attention has been given to the quality of the input skeleton data itself. This work demonstrates that by making use of multiple camera views to triangulate more accurate 3D~skeletons, the performance of state-of-the-art action recognition models can be improved significantly. This suggests that the quality of the input data is currently a limiting factor for the performance of these models. Based on these results, it is argued that the cost-benefit ratio of using multiple cameras is very favorable in most practical use-cases, therefore future research in skeleton-based action recognition should consider multi-view applications as the standard setup.",
        "authors": [
          "Daniel Bermuth",
          "Alexander Poeppel",
          "Wolfgang Reif"
        ],
        "published": "2026-02-26T17:10:58Z",
        "updated": "2026-02-26T17:10:58Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23231v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23229v1",
        "title": "Large Multimodal Models as General In-Context Classifiers",
        "summary": "Which multimodal model should we use for classification? Previous studies suggest that the answer lies in CLIP-like contrastive Vision-Language Models (VLMs), due to their remarkable performance in zero-shot classification. In contrast, Large Multimodal Models (LMM) are more suitable for complex tasks. In this work, we argue that this answer overlooks an important capability of LMMs: in-context learning. We benchmark state-of-the-art LMMs on diverse datasets for closed-world classification and find that, although their zero-shot performance is lower than CLIP's, LMMs with a few in-context examples can match or even surpass contrastive VLMs with cache-based adapters, their \"in-context\" equivalent. We extend this analysis to the open-world setting, where the generative nature of LMMs makes them more suitable for the task. In this challenging scenario, LMMs struggle whenever provided with imperfect context information. To address this issue, we propose CIRCLE, a simple training-free method that assigns pseudo-labels to in-context examples, iteratively refining them with the available context itself. Through extensive experiments, we show that CIRCLE establishes a robust baseline for open-world classification, surpassing VLM counterparts and highlighting the potential of LMMs to serve as unified classifiers, and a flexible alternative to specialized models.",
        "authors": [
          "Marco Garosi",
          "Matteo Farina",
          "Alessandro Conti",
          "Massimiliano Mancini",
          "Elisa Ricci"
        ],
        "published": "2026-02-26T17:08:18Z",
        "updated": "2026-02-26T17:08:18Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23229v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23228v1",
        "title": "MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction",
        "summary": "With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external \"tool\" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to steer the VLM's reasoning, ensuring the generated scene descriptions are anchored to verifiable facts. Furthermore, our progressive abstraction pipeline decomposes the summarization of a full-length movie into a multi-stage process, effectively mitigating the context length limitations of current VLMs. Experiments demonstrate that our approach yields significant improvements in factual accuracy, character consistency, and overall narrative coherence compared to end-to-end baselines.",
        "authors": [
          "Yizhi Li",
          "Xiaohan Chen",
          "Miao Jiang",
          "Wentao Tang",
          "Gaoang Wang"
        ],
        "published": "2026-02-26T17:08:08Z",
        "updated": "2026-02-26T17:08:08Z",
        "categories": [
          "cs.CV",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23228v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23217v1",
        "title": "Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks",
        "summary": "This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.",
        "authors": [
          "Alaa El Ichi",
          "Khalide Jbilou"
        ],
        "published": "2026-02-26T17:00:45Z",
        "updated": "2026-02-26T17:00:45Z",
        "categories": [
          "cs.CV",
          "math.NA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23217v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23212v1",
        "title": "Through BrokenEyes: How Eye Disorders Impact Face Detection?",
        "summary": "Vision disorders significantly impact millions of lives, altering how visual information is processed and perceived. In this work, a computational framework was developed using the BrokenEyes system to simulate five common eye disorders: Age-related macular degeneration, cataract, glaucoma, refractive errors, and diabetic retinopathy and analyze their effects on neural-like feature representations in deep learning models. Leveraging a combination of human and non-human datasets, models trained under normal and disorder-specific conditions revealed critical disruptions in feature maps, particularly for cataract and glaucoma, which align with known neural processing challenges in these conditions. Evaluation metrics such as activation energy and cosine similarity quantified the severity of these distortions, providing insights into the interplay between degraded visual inputs and learned representations.",
        "authors": [
          "Prottay Kumar Adhikary"
        ],
        "published": "2026-02-26T16:56:51Z",
        "updated": "2026-02-26T16:56:51Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23212v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.23205v1",
        "title": "EmbodMocap: In-the-Wild 4D Human-Scene Reconstruction for Embodied Agents",
        "summary": "Human behaviors in the real world naturally encode rich, long-term contextual information that can be leveraged to train embodied agents for perception, understanding, and acting. However, existing capture systems typically rely on costly studio setups and wearable devices, limiting the large-scale collection of scene-conditioned human motion data in the wild. To address this, we propose EmbodMocap, a portable and affordable data collection pipeline using two moving iPhones. Our key idea is to jointly calibrate dual RGB-D sequences to reconstruct both humans and scenes within a unified metric world coordinate frame. The proposed method allows metric-scale and scene-consistent capture in everyday environments without static cameras or markers, bridging human motion and scene geometry seamlessly. Compared with optical capture ground truth, we demonstrate that the dual-view setting exhibits a remarkable ability to mitigate depth ambiguity, achieving superior alignment and reconstruction performance over single iphone or monocular models. Based on the collected data, we empower three embodied AI tasks: monocular human-scene-reconstruction, where we fine-tune on feedforward models that output metric-scale, world-space aligned humans and scenes; physics-based character animation, where we prove our data could be used to scale human-object interaction skills and scene-aware motion tracking; and robot motion control, where we train a humanoid robot via sim-to-real RL to replicate human motions depicted in videos. Experimental results validate the effectiveness of our pipeline and its contributions towards advancing embodied AI research.",
        "authors": [
          "Wenjia Wang",
          "Liang Pan",
          "Huaijin Pi",
          "Yuke Lou",
          "Xuqian Ren",
          "Yifan Wu",
          "Zhouyingcheng Liao",
          "Lei Yang",
          "Rishabh Dabral",
          "Christian Theobalt",
          "Taku Komura"
        ],
        "published": "2026-02-26T16:53:41Z",
        "updated": "2026-02-26T16:53:41Z",
        "categories": [
          "cs.CV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23205v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.20133v1",
        "title": "AdaEvolve: Adaptive LLM Driven Zeroth-Order Optimization",
        "summary": "The paradigm of automated program generation is shifting from one-shot generation to inference-time search, where Large Language Models (LLMs) function as semantic mutation operators within evolutionary loops. While effective, these systems are currently governed by static schedules that fail to account for the non-stationary dynamics of the search process. This rigidity results in substantial computational waste, as resources are indiscriminately allocated to stagnating populations while promising frontiers remain under-exploited. We introduce AdaEvolve, a framework that reformulates LLM-driven evolution as a hierarchical adaptive optimization problem. AdaEvolve uses an \"accumulated improvement signal\" to unify decisions across three levels: Local Adaptation, which dynamically modulates the exploration intensity within a population of solution candidates; Global Adaptation, which routes the global resource budget via bandit-based scheduling across different solution candidate populations; and Meta-Guidance which generates novel solution tactics based on the previously generated solutions and their corresponding improvements when the progress stalls. We demonstrate that AdaEvolve consistently outperforms the open-sourced baselines across 185 different open-ended optimization problems including combinatorial, systems optimization and algorithm design problems.",
        "authors": [
          "Mert Cemri",
          "Shubham Agrawal",
          "Akshat Gupta",
          "Shu Liu",
          "Audrey Cheng",
          "Qiuyang Mang",
          "Ashwin Naren",
          "Lutfi Eren Erdogan",
          "Koushik Sen",
          "Matei Zaharia",
          "Alex Dimakis",
          "Ion Stoica"
        ],
        "published": "2026-02-23T18:45:31Z",
        "updated": "2026-02-23T18:45:31Z",
        "categories": [
          "cs.NE",
          "cs.AI",
          "cs.CL"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20133v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.19268v1",
        "title": "CORVET: A CORDIC-Powered, Resource-Frugal Mixed-Precision Vector Processing Engine for High-Throughput AIoT applications",
        "summary": "This brief presents a runtime-adaptive, performance-enhanced vector engine featuring a low-resource, iterative CORDIC-based MAC unit for edge AI acceleration. The proposed design enables dynamic reconfiguration between approximate and accurate modes, exploiting the latency-accuracy trade-off for a wide range of workloads. Its resource-efficient approach further enables up to 4x throughput improvement within the same hardware resources by leveraging vectorised, time-multiplexed execution and flexible precision scaling. With a time-multiplexed multi-AF block and a lightweight pooling and normalisation unit, the proposed vector engine supports flexible precision (4/8/16-bit) and high MAC density. The ASIC implementation results show that each MAC stage can save up to 33% of time and 21% of power, with a 256-PE configuration that achieves higher compute density (4.83 TOPS/mm2 ) and energy efficiency (11.67 TOPS/W) than previous state-of-the-art work. A detailed hardware-software co-design methodology for object detection and classification tasks on Pynq-Z2 is discussed to assess the proposed architecture, demonstrating a scalable, energy-efficient solution for edge AI applications.",
        "authors": [
          "Sonu Kumar",
          "Mohd Faisal Khan",
          "Mukul Lokhande",
          "Santosh Kumar Vishvakarma"
        ],
        "published": "2026-02-22T16:51:17Z",
        "updated": "2026-02-22T16:51:17Z",
        "categories": [
          "cs.AR",
          "cs.AI",
          "cs.CV",
          "cs.NE",
          "eess.IV"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19268v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.16829v1",
        "title": "Learning under noisy supervision is governed by a feedback-truth gap",
        "summary": "When feedback is absorbed faster than task structure can be evaluated, the learner will favor feedback over truth. A two-timescale model shows this feedback-truth gap is inevitable whenever the two rates differ and vanishes only when they match. We test this prediction across neural networks trained with noisy labels (30 datasets, 2,700 runs), human probabilistic reversal learning (N = 292), and human reward/punishment learning with concurrent EEG (N = 25). In each system, truth is defined operationally: held-out labels, the objectively correct option, or the participant's pre-feedback expectation - the only non-circular reference decodable from post-feedback EEG. The gap appeared universally but was regulated differently: dense networks accumulated it as memorization; sparse-residual scaffolding suppressed it; humans generated transient over-commitment that was actively recovered. Neural over-commitment (~0.04-0.10) was amplified tenfold into behavioral commitment (d = 3.3-3.9). The gap is a fundamental constraint on learning under noisy supervision; its consequences depend on the regulation each system employs.",
        "authors": [
          "Elan Schonfeld",
          "Elias Wisnia"
        ],
        "published": "2026-02-18T19:50:56Z",
        "updated": "2026-02-18T19:50:56Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.16829v1.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.21262v2",
        "title": "Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models",
        "summary": "With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and persuasion (synthesizing the available evidence to make a convincing argument). While existing work has investigated these capacities in isolation, there has been little prior investigation of how these capacities may be linked. Here, we use a simple multi-turn puzzle-solving game, Sokoban, to study LLMs' abilities to persuade and be rationally vigilant towards other LLM agents. We find that puzzle-solving performance, persuasive capability, and vigilance are dissociable capacities in LLMs. Performing well on the game does not automatically mean a model can detect when it is being misled, even if the possibility of deception is explicitly mentioned. However, LLMs do consistently modulate their token use, using fewer tokens to reason when advice is benevolent and more when it is malicious, even if they are still persuaded to take actions leading them to failure. To our knowledge, our work presents the first investigation of the relationship between persuasion, vigilance, and task performance in LLMs, and suggests that monitoring all three independently will be critical for future work in AI safety.",
        "authors": [
          "Sasha Robinson",
          "Kerem Oktar",
          "Katherine M. Collins",
          "Ilia Sucholutsky",
          "Kelsey R. Allen"
        ],
        "published": "2026-02-24T04:09:21Z",
        "updated": "2026-02-26T06:37:29Z",
        "categories": [
          "cs.CL",
          "cs.LG",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21262v2.pdf",
        "category": "multimodal"
      },
      {
        "id": "2602.22974v1",
        "title": "An automatic counting algorithm for the quantification and uncertainty analysis of the number of microglial cells trainable in small and heterogeneous datasets",
        "summary": "Counting immunopositive cells on biological tissues generally requires either manual annotation or (when available) automatic rough systems, for scanning signal surface and intensity in whole slide imaging. In this work, we tackle the problem of counting microglial cells in lumbar spinal cord cross-sections of rats by omitting cell detection and focusing only on the counting task. Manual cell counting is, however, a time-consuming task and additionally entails extensive personnel training. The classic automatic color-based methods roughly inform about the total labeled area and intensity (protein quantification) but do not specifically provide information on cell number. Since the images to be analyzed have a high resolution but a huge amount of pixels contain just noise or artifacts, we first perform a pre-processing generating several filtered images {(providing a tailored, efficient feature extraction)}. Then, we design an automatic kernel counter that is a non-parametric and non-linear method. The proposed scheme can be easily trained in small datasets since, in its basic version, it relies only on one hyper-parameter. However, being non-parametric and non-linear, the proposed algorithm is flexible enough to express all the information contained in rich and heterogeneous datasets as well (providing the maximum overfit if required). Furthermore, the proposed kernel counter also provides uncertainty estimation of the given prediction, and can directly tackle the case of receiving several expert opinions over the same image. Different numerical experiments with artificial and real datasets show very promising results. Related Matlab code is also provided.",
        "authors": [
          "L. Martino",
          "M. M. Garcia",
          "P. S. Paradas",
          "E. Curbelo"
        ],
        "published": "2026-02-26T13:13:43Z",
        "updated": "2026-02-26T13:13:43Z",
        "categories": [
          "cs.CE",
          "cs.CV",
          "eess.IV",
          "eess.SP",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22974v1.pdf",
        "category": "multimodal"
      }
    ],
    "ml-theory": [
      {
        "id": "2602.23360v1",
        "title": "Model Agreement via Anchoring",
        "summary": "Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies. We develop a simple general technique for proving bounds on independent model disagreement based on $\\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss.",
        "authors": [
          "Eric Eaton",
          "Surbhi Goel",
          "Marcel Hussing",
          "Michael Kearns",
          "Aaron Roth",
          "Sikata Bela Sengupta",
          "Jessica Sorrell"
        ],
        "published": "2026-02-26T18:59:32Z",
        "updated": "2026-02-26T18:59:32Z",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23360v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23349v1",
        "title": "FlashOptim: Optimizers for Memory Efficient Training",
        "summary": "Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory. We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half. Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.",
        "authors": [
          "Jose Javier Gonzalez Ortiz",
          "Abhay Gupta",
          "Chris Renard",
          "Davis Blalock"
        ],
        "published": "2026-02-26T18:52:22Z",
        "updated": "2026-02-26T18:52:22Z",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23349v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23335v1",
        "title": "Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset",
        "summary": "AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation.",
        "authors": [
          "Dany Haddad",
          "Dan Bareket",
          "Joseph Chee Chang",
          "Jay DeYoung",
          "Jena D. Hwang",
          "Uri Katz",
          "Mark Polak",
          "Sangho Suh",
          "Harshit Surana",
          "Aryeh Tiktinsky",
          "Shriya Atmakuri",
          "Jonathan Bragg",
          "Mike D'Arcy",
          "Sergey Feldman",
          "Amal Hassan-Ali",
          "Rubén Lozano",
          "Bodhisattwa Prasad Majumder",
          "Charles McGrady",
          "Amanpreet Singh",
          "Brooke Vlahos",
          "Yoav Goldberg",
          "Doug Downey"
        ],
        "published": "2026-02-26T18:40:28Z",
        "updated": "2026-02-26T18:40:28Z",
        "categories": [
          "cs.HC",
          "cs.AI",
          "cs.IR"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23335v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23334v1",
        "title": "Bitwise Systolic Array Architecture for Runtime-Reconfigurable Multi-precision Quantized Multiplication on Hardware Accelerators",
        "summary": "Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc. Previous works have explored the quantization technologies in related lightweight accelerator designs to reduce hardware resource consumption. However, low precision leads to high accuracy loss in inference. Therefore, mixed-precision quantization becomes an alternative solution by applying different precision in different layers to trade off resource consumption and accuracy. Because regular designs for multiplication on hardware cannot support the precision reconfiguration for a multi-precision Quantized Neural Network (QNN) model in runtime, we propose a runtime reconfigurable multi-precision multi-channel bitwise systolic array design for QNN accelerators. We have implemented and evaluated our work on the Ultra96 FPGA platform. Results show that our work can achieve 1.3185 to 3.5671 times speedup in inferring mixed-precision models and has less critical path delay, supporting a higher clock frequency (250MHz).",
        "authors": [
          "Yuhao Liu",
          "Salim Ullah",
          "Akash Kumar"
        ],
        "published": "2026-02-26T18:40:02Z",
        "updated": "2026-02-26T18:40:02Z",
        "categories": [
          "cs.AR",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23334v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23330v1",
        "title": "Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks",
        "summary": "The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings.",
        "authors": [
          "Kunihiro Miyazaki",
          "Takanobu Kawahara",
          "Stephen Roberts",
          "Stefan Zohren"
        ],
        "published": "2026-02-26T18:37:36Z",
        "updated": "2026-02-26T18:37:36Z",
        "categories": [
          "cs.AI",
          "q-fin.TR"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23330v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23318v1",
        "title": "Generalized Rapid Action Value Estimation in Memory-Constrained Environments",
        "summary": "Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.",
        "authors": [
          "Aloïs Rautureau",
          "Tristan Cazenave",
          "Éric Piette"
        ],
        "published": "2026-02-26T18:25:59Z",
        "updated": "2026-02-26T18:25:59Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23318v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23315v1",
        "title": "Invariant Transformation and Resampling based Epistemic-Uncertainty Reduction",
        "summary": "An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces. Once designed and well trained, the AI model is applied for inference. However, even optimized AI models can produce inference errors due to aleatoric and epistemic uncertainties. Interestingly, we observed that when inferring multiple samples based on invariant transformations of an input, inference errors can show partial independences due to epistemic uncertainty. Leveraging this insight, we propose a \"resampling\" based inferencing that applies to a trained AI model with multiple transformed versions of an input, and aggregates inference outputs to a more accurate result. This approach has the potential to improve inference accuracy and offers a strategy for balancing model size and performance.",
        "authors": [
          "Sha Hu"
        ],
        "published": "2026-02-26T18:22:40Z",
        "updated": "2026-02-26T18:22:40Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23315v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23296v1",
        "title": "Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity",
        "summary": "Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.",
        "authors": [
          "Quang-Huy Nguyen",
          "Jiaqi Wang",
          "Wei-Shinn Ku"
        ],
        "published": "2026-02-26T18:07:45Z",
        "updated": "2026-02-26T18:07:45Z",
        "categories": [
          "cs.LG",
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23296v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23285v1",
        "title": "ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks",
        "summary": "Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.",
        "authors": [
          "Haohui Jia",
          "Zheng Chen",
          "Lingwei Zhu",
          "Rikuto Kotoge",
          "Jathurshan Pradeepkumar",
          "Yasuko Matsubara",
          "Jimeng Sun",
          "Yasushi Sakurai",
          "Takashi Matsubara"
        ],
        "published": "2026-02-26T17:59:10Z",
        "updated": "2026-02-26T17:59:10Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23285v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23276v1",
        "title": "CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays",
        "summary": "Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.",
        "authors": [
          "Hyungyung Lee",
          "Hangyul Yoon",
          "Edward Choi"
        ],
        "published": "2026-02-26T17:51:21Z",
        "updated": "2026-02-26T17:51:21Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23276v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23271v1",
        "title": "Evaluating Stochasticity in Deep Research Agents",
        "summary": "Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.",
        "authors": [
          "Haotian Zhai",
          "Elias Stengel-Eskin",
          "Pratik Patil",
          "Liu Leqi"
        ],
        "published": "2026-02-26T17:46:42Z",
        "updated": "2026-02-26T17:46:42Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23271v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23248v1",
        "title": "Mitigating Legibility Tax with Decoupled Prover-Verifier Games",
        "summary": "As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.",
        "authors": [
          "Yegon Kim",
          "Juho Lee"
        ],
        "published": "2026-02-26T17:25:22Z",
        "updated": "2026-02-26T17:25:22Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23248v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23242v1",
        "title": "A Model-Free Universal AI",
        "summary": "In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models. This paper introduces Universal AI with Q-Induction (AIQI), the first model-free agent proven to be asymptotically $\\varepsilon$-optimal in general RL. AIQI performs universal induction over distributional action-value functions, instead of policies or environments like previous works. Under a grain of truth condition, we prove that AIQI is strong asymptotically $\\varepsilon$-optimal and asymptotically $\\varepsilon$-Bayes-optimal. Our results significantly expand the diversity of known universal agents.",
        "authors": [
          "Yegon Kim",
          "Juho Lee"
        ],
        "published": "2026-02-26T17:21:16Z",
        "updated": "2026-02-26T17:21:16Z",
        "categories": [
          "cs.AI"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23242v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23239v1",
        "title": "Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive",
        "summary": "AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains. RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations. Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument.",
        "authors": [
          "Radha Sarma"
        ],
        "published": "2026-02-26T17:16:17Z",
        "updated": "2026-02-26T17:16:17Z",
        "categories": [
          "cs.AI",
          "cs.CY"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23239v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23234v1",
        "title": "Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments",
        "summary": "Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels.",
        "authors": [
          "Evangelia Christakopoulou",
          "Vivekkumar Patel",
          "Hemanth Velaga",
          "Sandip Gaikwad"
        ],
        "published": "2026-02-26T17:11:26Z",
        "updated": "2026-02-26T17:11:26Z",
        "categories": [
          "cs.IR",
          "cs.AI",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23234v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23341v1",
        "title": "Mean Estimation from Coarse Data: Characterizations and Efficient Algorithms",
        "summary": "Coarse data arise when learners observe only partial information about samples; namely, a set containing the sample rather than its exact value. This occurs naturally through measurement rounding, sensor limitations, and lag in economic systems. We study Gaussian mean estimation from coarse data, where each true sample $x$ is drawn from a $d$-dimensional Gaussian distribution with identity covariance, but is revealed only through the set of a partition containing $x$. When the coarse samples, roughly speaking, have ``low'' information, the mean cannot be uniquely recovered from observed samples (i.e., the problem is not identifiable). Recent work by Fotakis, Kalavasis, Kontonis, and Tzamos [FKKT21] established that sample-efficient mean estimation is possible when the unknown mean is identifiable and the partition consists of only convex sets. Moreover, they showed that without convexity, mean estimation becomes NP-hard. However, two fundamental questions remained open: (1) When is the mean identifiable under convex partitions? (2) Is computationally efficient estimation possible under identifiability and convex partitions? This work resolves both questions. [...]",
        "authors": [
          "Alkis Kalavasis",
          "Anay Mehrotra",
          "Manolis Zampetakis",
          "Felix Zhou",
          "Ziyu Zhu"
        ],
        "published": "2026-02-26T18:47:06Z",
        "updated": "2026-02-26T18:47:06Z",
        "categories": [
          "cs.LG",
          "cs.DS",
          "math.ST",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23341v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23336v1",
        "title": "Differentiable Zero-One Loss via Hypersimplex Projections",
        "summary": "Recent advances in machine learning have emphasized the integration of structured optimization components into end-to-end differentiable models, enabling richer inductive biases and tighter alignment with task-specific objectives. In this work, we introduce a novel differentiable approximation to the zero-one loss-long considered the gold standard for classification performance, yet incompatible with gradient-based optimization due to its non-differentiability. Our method constructs a smooth, order-preserving projection onto the n,k-dimensional hypersimplex through a constrained optimization framework, leading to a new operator we term Soft-Binary-Argmax. After deriving its mathematical properties, we show how its Jacobian can be efficiently computed and integrated into binary and multiclass learning systems. Empirically, our approach achieves significant improvements in generalization under large-batch training by imposing geometric consistency constraints on the output logits, thereby narrowing the performance gap traditionally observed in large-batch training.",
        "authors": [
          "Camilo Gomez",
          "Pengyang Wang",
          "Liansheng Tang"
        ],
        "published": "2026-02-26T18:41:31Z",
        "updated": "2026-02-26T18:41:31Z",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23336v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23321v1",
        "title": "Deep ensemble graph neural networks for probabilistic cosmic-ray direction and energy reconstruction in autonomous radio arrays",
        "summary": "Using advanced machine learning techniques, we developed a method for reconstructing precisely the arrival direction and energy of ultra-high-energy cosmic rays from the voltage traces they induced on ground-based radio detector arrays. In our approach, triggered antennas are represented as a graph structure, which serves as input for a graph neural network (GNN). By incorporating physical knowledge into both the GNN architecture and the input data, we improve the precision and reduce the required size of the training set with respect to a fully data-driven approach. This method achieves an angular resolution of 0.092° and an electromagnetic energy reconstruction resolution of 16.4% on simulated data with realistic noise conditions. We also employ uncertainty estimation methods to enhance the reliability of our predictions, quantifying the confidence of the GNN's outputs and providing confidence intervals for both direction and energy reconstruction. Finally, we investigate strategies to verify the model's consistency and robustness under real life variations, with the goal of identifying scenarios in which predictions remain reliable despite domain shifts between simulation and reality.",
        "authors": [
          "Arsène Ferrière",
          "Aurélien Benoit-Lévy",
          "Olivier Martineau-Huynh",
          "Matías Tueros"
        ],
        "published": "2026-02-26T18:29:48Z",
        "updated": "2026-02-26T18:29:48Z",
        "categories": [
          "astro-ph.IM",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23321v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23305v1",
        "title": "A Proper Scoring Rule for Virtual Staining",
        "summary": "Generative virtual staining (VS) models for high-throughput screening (HTS) can provide an estimated posterior distribution of possible biological feature values for each input and cell. However, when evaluating a VS model, the true posterior is unavailable. Existing evaluation protocols only check the accuracy of the marginal distribution over the dataset rather than the predicted posteriors. We introduce information gain (IG) as a cell-wise evaluation framework that enables direct assessment of predicted posteriors. IG is a strictly proper scoring rule and comes with a sound theoretical motivation allowing for interpretability, and for comparing results across models and features. We evaluate diffusion- and GAN-based models on an extensive HTS dataset using IG and other metrics and show that IG can reveal substantial performance differences other metrics cannot.",
        "authors": [
          "Samuel Tonks",
          "Steve Hood",
          "Ryan Musso",
          "Ceridwen Hopely",
          "Steve Titus",
          "Minh Doan",
          "Iain Styles",
          "Alexander Krull"
        ],
        "published": "2026-02-26T18:09:49Z",
        "updated": "2026-02-26T18:09:49Z",
        "categories": [
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23305v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23303v1",
        "title": "Inferential Mechanics Part 1: Causal Mechanistic Theories of Machine Learning in Chemical Biology with Implications",
        "summary": "Machine learning techniques are now routinely encountered in research laboratories across the globe. Impressive progress has been made through ML and AI techniques with regards to large data set processing. This progress has increased the ability of the experimenter to digest data and make novel predictions regarding phenomena of interest. However, machine learning predictors generated from data sets taken from the natural sciences are often treated as black boxes which are used broadly and generally without detailed consideration of the causal structure of the data set of interest. Work has been attempted to bring causality into discussions of machine learning models of natural phenomena; however, a firm and unified theoretical treatment is lacking. This series of three papers explores the union of chemical theory, biological theory, probability theory and causality that will correct current causal flaws of machine learning in the natural sciences. This paper, Part 1 of the series, provides the formal framework of the foundational causal structure of phenomena in chemical biology and is extended to machine learning through the novel concept of focus, defined here as the ability of a machine learning algorithm to narrow down to a hidden underpinning mechanism in large data sets. Initial proof of these principles on a family of Akt inhibitors is also provided. The second paper containing Part 2 will provide a formal exploration of chemical similarity, and Part 3 will present extensive experimental evidence of how hidden causal structures weaken all machine learning in chemical biology. This series serves to establish for chemical biology a new kind of mathematical framework for modeling mechanisms in Nature without the need for the tools of reductionism: inferential mechanics.",
        "authors": [
          "Ilya Balabin",
          "Thomas M. Kaiser"
        ],
        "published": "2026-02-26T18:09:16Z",
        "updated": "2026-02-26T18:09:16Z",
        "categories": [
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23303v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23277v1",
        "title": "Zeroth-Order Stackelberg Control in Combinatorial Congestion Games",
        "summary": "We study Stackelberg (leader--follower) tuning of network parameters (tolls, capacities, incentives) in combinatorial congestion games, where selfish users choose discrete routes (or other combinatorial strategies) and settle at a congestion equilibrium. The leader minimizes a system-level objective (e.g., total travel time) evaluated at equilibrium, but this objective is typically nonsmooth because the set of used strategies can change abruptly. We propose ZO-Stackelberg, which couples a projection-free Frank--Wolfe equilibrium solver with a zeroth-order outer update, avoiding differentiation through equilibria. We prove convergence to generalized Goldstein stationary points of the true equilibrium objective, with explicit dependence on the equilibrium approximation error, and analyze subsampled oracles: if an exact minimizer is sampled with probability $κ_m$, then the Frank--Wolfe error decays as $\\mathcal{O}(1/(κ_m T))$. We also propose stratified sampling as a practical way to avoid a vanishing $κ_m$ when the strategies that matter most for the Wardrop equilibrium concentrate in a few dominant combinatorial classes (e.g., short paths). Experiments on real-world networks demonstrate that our method achieves orders-of-magnitude speedups over a differentiation-based baseline while converging to follower equilibria.",
        "authors": [
          "Saeed Masiha",
          "Sepehr Elahi",
          "Negar Kiyavash",
          "Patrick Thiran"
        ],
        "published": "2026-02-26T17:52:08Z",
        "updated": "2026-02-26T17:52:08Z",
        "categories": [
          "cs.GT",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23277v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23219v1",
        "title": "Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime",
        "summary": "Generalization measures have been studied extensively in the machine learning community to better characterize generalization gaps. However, establishing a reliable generalization measure for statistically singular models such as deep neural networks (DNNs) is difficult due to their complex nature. This study focuses on Takeuchi's information criterion (TIC) to investigate the conditions under which this classical measure can effectively explain the generalization gaps of DNNs. Importantly, the developed theory indicates the applicability of TIC near the neural tangent kernel (NTK) regime. In a series of experiments, we trained more than 5,000 DNN models with 12 architectures, including large models (e.g., VGG-16), on four datasets, and estimated the corresponding TIC values to examine the relationship between the generalization gap and the TIC estimates. We applied several TIC approximation methods with feasible computational costs and assessed the accuracy trade-off. Our experimental results indicate that the estimated TIC values correlate well with the generalization gap under conditions close to the NTK regime. However, we show both theoretically and empirically that outside the NTK regime such correlation disappears. Finally, we demonstrate that TIC provides better trial pruning ability than existing methods for hyperparameter optimization.",
        "authors": [
          "Hiroki Naganuma",
          "Taiji Suzuki",
          "Rio Yokota",
          "Masahiro Nomura",
          "Kohta Ishikawa",
          "Ikuro Sato"
        ],
        "published": "2026-02-26T17:01:14Z",
        "updated": "2026-02-26T17:01:14Z",
        "categories": [
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23219v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23188v1",
        "title": "Efficient Real-Time Adaptation of ROMs for Unsteady Flows Using Data Assimilation",
        "summary": "We propose an efficient retraining strategy for a parameterized Reduced Order Model (ROM) that attains accuracy comparable to full retraining while requiring only a fraction of the computational time and relying solely on sparse observations of the full system. The architecture employs an encode-process-decode structure: a Variational Autoencoder (VAE) to perform dimensionality reduction, and a transformer network to evolve the latent states and model the dynamics. The ROM is parameterized by an external control variable, the Reynolds number in the Navier-Stokes setting, with the transformer exploiting attention mechanisms to capture both temporal dependencies and parameter effects. The probabilistic VAE enables stochastic sampling of trajectory ensembles, providing predictive means and uncertainty quantification through the first two moments. After initial training on a limited set of dynamical regimes, the model is adapted to out-of-sample parameter regions using only sparse data. Its probabilistic formulation naturally supports ensemble generation, which we employ within an ensemble Kalman filtering framework to assimilate data and reconstruct full-state trajectories from minimal observations. We further show that, for the dynamical system considered, the dominant source of error in out-of-sample forecasts stems from distortions of the latent manifold rather than changes in the latent dynamics. Consequently, retraining can be limited to the autoencoder, allowing for a lightweight, computationally efficient, real-time adaptation procedure with very sparse fine-tuning data.",
        "authors": [
          "Ismaël Zighed",
          "Andrea Nóvoa",
          "Luca Magri",
          "Taraneh Sayadi"
        ],
        "published": "2026-02-26T16:43:28Z",
        "updated": "2026-02-26T16:43:28Z",
        "categories": [
          "cs.LG",
          "physics.flu-dyn"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23188v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23182v1",
        "title": "Closing the gap on tabular data with Fourier and Implicit Categorical Features",
        "summary": "While Deep Learning has demonstrated impressive results in applications on various data types, it continues to lag behind tree-based methods when applied to tabular data, often referred to as the last \"unconquered castle\" for neural networks. We hypothesize that a significant advantage of tree-based methods lies in their intrinsic capability to model and exploit non-linear interactions induced by features with categorical characteristics. In contrast, neural-based methods exhibit biases toward uniform numerical processing of features and smooth solutions, making it challenging for them to effectively leverage such patterns. We address this performance gap by using statistical-based feature processing techniques to identify features that are strongly correlated with the target once discretized. We further mitigate the bias of deep models for overly-smooth solutions, a bias that does not align with the inherent properties of the data, using Learned Fourier. We show that our proposed feature preprocessing significantly boosts the performance of deep learning models and enables them to achieve a performance that closely matches or surpasses XGBoost on a comprehensive tabular data benchmark.",
        "authors": [
          "Marius Dragoi",
          "Florin Gogianu",
          "Elena Burceanu"
        ],
        "published": "2026-02-26T16:40:23Z",
        "updated": "2026-02-26T16:40:23Z",
        "categories": [
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23182v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21995v1",
        "title": "Outpatient Appointment Scheduling Optimization with a Genetic Algorithm Approach",
        "summary": "The optimization of complex medical appointment scheduling remains a significant operational challenge in multi-center healthcare environments, where clinical safety protocols and patient logistics must be reconciled. This study proposes and evaluates a Genetic Algorithm (GA) framework designed to automate the scheduling of multiple medical acts while adhering to rigorous inter-procedural incompatibility rules. Using a synthetic dataset encompassing 50 medical acts across four healthcare facilities, we compared two GA variants, Pre-Ordered and Unordered, against deterministic First-Come, First-Served (FCFS) and Random Choice baselines. Our results demonstrate that the GA framework achieved a 100% constraint fulfillment rate, effectively resolving temporal overlaps and clinical incompatibilities that the FCFS baseline failed to address in 60% and 40% of cases, respectively. Furthermore, the GA variants demonstrated statistically significant improvements (p &lt; 0.001) in patient-centric metrics, achieving an Idle Time Ratio (ITR) frequently below 0.4 and reducing inter-healthcenter trips. While the GA (Ordered) variant provided a superior initial search locus, both evolutionary models converged to comparable global optima by the 100th generation. These findings suggest that transitioning from manual, human-mediated scheduling to an automated metaheuristic approach enhances clinical integrity, reduces administrative overhead, and significantly improves the patient experience by minimizing wait times and logistical burdens.",
        "authors": [
          "Ana Rodrigues",
          "Rui Rego"
        ],
        "published": "2026-02-25T15:15:57Z",
        "updated": "2026-02-25T15:15:57Z",
        "categories": [
          "cs.NE",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21995v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21761v1",
        "title": "Survey on Neural Routing Solvers",
        "summary": "Neural routing solvers (NRSs) that leverage deep learning to tackle vehicle routing problems have demonstrated notable potential for practical applications. By learning implicit heuristic rules from data, NRSs replace the handcrafted counterparts in classic heuristic frameworks, thereby reducing reliance on costly manual design and trial-and-error adjustments. This survey makes two main contributions: (1) The heuristic nature of NRSs is highlighted, and existing NRSs are reviewed from the perspective of heuristics. A hierarchical taxonomy based on heuristic principles is further introduced. (2) A generalization-focused evaluation pipeline is proposed to address limitations of the conventional pipeline. Comparative benchmarking of representative NRSs across both pipelines uncovers a series of previously unreported gaps in current research.",
        "authors": [
          "Yunpeng Ba",
          "Xi Lin",
          "Changliang Zhou",
          "Ruihao Zheng",
          "Zhenkun Wang",
          "Xinyan Liang",
          "Zhichao Lu",
          "Jianyong Sun",
          "Yuhua Qian",
          "Qingfu Zhang"
        ],
        "published": "2026-02-25T10:24:43Z",
        "updated": "2026-02-25T10:24:43Z",
        "categories": [
          "math.OC",
          "cs.AI",
          "cs.LG",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21761v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22260v1",
        "title": "Code World Models for Parameter Control in Evolutionary Algorithms",
        "summary": "Can an LLM learn how an optimizer behaves -- and use that knowledge to control it? We extend Code World Models (CWMs), LLM-synthesized Python programs that predict environment dynamics, from deterministic games to stochastic combinatorial optimization. Given suboptimal trajectories of $(1{+}1)$-$\\text{RLS}_k$, the LLM synthesizes a simulator of the optimizer's dynamics; greedy planning over this simulator then selects the mutation strength $k$ at each step. On \\lo{} and \\onemax{}, CWM-greedy performs within 6\\% of the theoretically optimal policy -- without ever seeing optimal-policy trajectories. On \\jump{$_k$}, where a deceptive valley causes all adaptive baselines to fail (0\\% success rate), CWM-greedy achieves 100\\% success rate -- without any collection policy using oracle knowledge of the gap parameter. On the NK-Landscape, where no closed-form model exists, CWM-greedy outperforms all baselines across fifteen independently generated instances ($36.94$ vs.\\ $36.32$; $p&lt;0.001$) when the prompt includes empirical transition statistics. The CWM also outperforms DQN in sample efficiency (200 offline trajectories vs.\\ 500 online episodes), success rate (100\\% vs.\\ 58\\%), and generalization ($k{=}3$: 78\\% vs.\\ 0\\%). Robustness experiments confirm stable synthesis across 5 independent runs.",
        "authors": [
          "Camilo Chacón Sartori",
          "Guillem Rodríguez Corominas"
        ],
        "published": "2026-02-25T01:49:29Z",
        "updated": "2026-02-25T01:49:29Z",
        "categories": [
          "cs.LG",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22260v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.19785v1",
        "title": "Unsupervised Anomaly Detection in NSL-KDD Using $β$-VAE: A Latent Space and Reconstruction Error Approach",
        "summary": "As Operational Technology increasingly integrates with Information Technology, the need for Intrusion Detection Systems becomes more important. This paper explores an unsupervised approach to anomaly detection in network traffic using $β$-Variational Autoencoders on the NSL-KDD dataset. We investigate two methods: leveraging the latent space structure by measuring distances from test samples to the training data projections, and using the reconstruction error as a conventional anomaly detection metric. By comparing these approaches, we provide insights into their respective advantages and limitations in an unsupervised setting. Experimental results highlight the effectiveness of latent space exploitation for classification tasks.",
        "authors": [
          "Dylan Baptiste",
          "Ramla Saddem",
          "Alexandre Philippot",
          "François Foyer"
        ],
        "published": "2026-02-23T12:42:00Z",
        "updated": "2026-02-23T12:42:00Z",
        "categories": [
          "cs.LG",
          "cs.NE",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19785v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.19331v1",
        "title": "Partial Soft-Matching Distance for Neural Representational Comparison with Partial Unit Correspondence",
        "summary": "Representational similarity metrics typically force all units to be matched, making them susceptible to noise and outliers common in neural representations. We extend the soft-matching distance to a partial optimal transport setting that allows some neurons to remain unmatched, yielding rotation-sensitive but robust correspondences. This partial soft-matching distance provides theoretical advantages -- relaxing strict mass conservation while maintaining interpretable transport costs -- and practical benefits through efficient neuron ranking in terms of cross-network alignment without costly iterative recomputation. In simulations, it preserves correct matches under outliers and reliably selects the correct model in noise-corrupted identification tasks. On fMRI data, it automatically excludes low-reliability voxels and produces voxel rankings by alignment quality that closely match computationally expensive brute-force approaches. It achieves higher alignment precision across homologous brain areas than standard soft-matching, which is forced to match all units regardless of quality. In deep networks, highly matched units exhibit similar maximally exciting images, while unmatched units show divergent patterns. This ability to partition by match quality enables focused analyses, e.g., testing whether networks have privileged axes even within their most aligned subpopulations. Overall, partial soft-matching provides a principled and practical method for representational comparison under partial correspondence.",
        "authors": [
          "Chaitanya Kapoor",
          "Alex H. Williams",
          "Meenakshi Khosla"
        ],
        "published": "2026-02-22T20:31:35Z",
        "updated": "2026-02-22T20:31:35Z",
        "categories": [
          "cs.LG",
          "cs.NE",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19331v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.19261v1",
        "title": "DGPO: RL-Steered Graph Diffusion for Neural Architecture Generation",
        "summary": "Reinforcement learning fine-tuning has proven effective for steering generative diffusion models toward desired properties in image and molecular domains. Graph diffusion models have similarly been applied to combinatorial structure generation, including neural architecture search (NAS). However, neural architectures are directed acyclic graphs (DAGs) where edge direction encodes functional semantics such as data flow-information that existing graph diffusion methods, designed for undirected structures, discard. We propose Directed Graph Policy Optimization (DGPO), which extends reinforcement learning fine-tuning of discrete graph diffusion models to DAGs via topological node ordering and positional encoding. Validated on NAS-Bench-101 and NAS-Bench-201, DGPO matches the benchmark optimum on all three NAS-Bench-201 tasks (91.61%, 73.49%, 46.77%). The central finding is that the model learns transferable structural priors: pretrained on only 7% of the search space, it generates near-oracle architectures after fine-tuning, within 0.32 percentage points of the full-data model and extrapolating 7.3 percentage points beyond its training ceiling. Bidirectional control experiments confirm genuine reward-driven steering, with inverse optimization reaching near random-chance accuracy (9.5%). These results demonstrate that reinforcement learning-steered discrete diffusion, once extended to handle directionality, provides a controllable generative framework for directed combinatorial structures.",
        "authors": [
          "Aleksei Liuliakov",
          "Luca Hermes",
          "Barbara Hammer"
        ],
        "published": "2026-02-22T16:23:42Z",
        "updated": "2026-02-22T16:23:42Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19261v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.19253v1",
        "title": "Alternating Bi-Objective Optimization for Explainable Neuro-Fuzzy Systems",
        "summary": "Fuzzy systems show strong potential in explainable AI due to their rule-based architecture and linguistic variables. Existing approaches navigate the accuracy-explainability trade-off either through evolutionary multi-objective optimization (MOO), which is computationally expensive, or gradient-based scalarization, which cannot recover non-convex Pareto regions. We propose X-ANFIS, an alternating bi-objective gradient-based optimization scheme for explainable adaptive neuro-fuzzy inference systems. Cauchy membership functions are used for stable training under semantically controlled initializations, and a differentiable explainability objective is introduced and decoupled from the performance objective through alternating gradient passes. Validated in approximately 5,000 experiments on nine UCI regression datasets, X-ANFIS consistently achieves target distinguishability while maintaining competitive predictive accuracy, recovering solutions beyond the convex hull of the MOO Pareto front.",
        "authors": [
          "Qusai Khaled",
          "Uzay Kaymak",
          "Laura Genga"
        ],
        "published": "2026-02-22T16:08:06Z",
        "updated": "2026-02-22T16:08:06Z",
        "categories": [
          "cs.LG",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19253v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.18960v1",
        "title": "Modularity is the Bedrock of Natural and Artificial Intelligence",
        "summary": "The remarkable performance of modern AI systems has been driven by unprecedented scales of data, computation, and energy -- far exceeding the resources required by human intelligence. This disparity highlights the need for new guiding principles and motivates drawing inspiration from the fundamental organizational principles of brain computation. Among these principles, modularity has been shown to be critical for supporting the efficient learning and strong generalization abilities consistently exhibited by humans. Furthermore, modularity aligns well with the No Free Lunch Theorem, which highlights the need for problem-specific inductive biases and motivates architectures composed of specialized components that solve subproblems. However, despite its fundamental role in natural intelligence and its demonstrated benefits across a range of seemingly disparate AI subfields, modularity remains relatively underappreciated in mainstream AI research. In this work, we review several research threads in artificial intelligence and neuroscience through a conceptual framework that highlights the central role of modularity in supporting both artificial and natural intelligence. In particular, we examine what computational advantages modularity provides, how it has emerged as a solution across several AI research areas, which modularity principles the brain exploits, and how modularity can help bridge the gap between natural and artificial intelligence.",
        "authors": [
          "Alessandro Salatiello"
        ],
        "published": "2026-02-21T21:47:09Z",
        "updated": "2026-02-21T21:47:09Z",
        "categories": [
          "cs.AI",
          "cs.NE",
          "q-bio.NC"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18960v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.18948v1",
        "title": "Toward Manifest Relationality in Transformers via Symmetry Reduction",
        "summary": "Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.",
        "authors": [
          "J. François",
          "L. Ravera"
        ],
        "published": "2026-02-21T19:43:17Z",
        "updated": "2026-02-21T19:43:17Z",
        "categories": [
          "cs.LG",
          "cs.NE",
          "hep-th",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18948v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.18674v1",
        "title": "Robustness of Deep ReLU Networks to Misclassification of High-Dimensional Data",
        "summary": "We present a theoretical study of the robustness of parameterized networks to random input perturbations. Specifically, we analyze local robustness at a given network input by quantifying the probability that a small additive random perturbation of the input leads to misclassification. For deep networks with rectified linear units, we derive lower bounds on local robustness in terms of the input dimensionality and the total number of network units.",
        "authors": [
          "Věra Kůrková"
        ],
        "published": "2026-02-21T00:55:47Z",
        "updated": "2026-02-21T00:55:47Z",
        "categories": [
          "cs.LG",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18674v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22786v1",
        "title": "QSIM: Mitigating Overestimation in Multi-Agent Reinforcement Learning via Action Similarity Weighted Q-Learning",
        "summary": "Value decomposition (VD) methods have achieved remarkable success in cooperative multi-agent reinforcement learning (MARL). However, their reliance on the max operator for temporal-difference (TD) target calculation leads to systematic Q-value overestimation. This issue is particularly severe in MARL due to the combinatorial explosion of the joint action space, which often results in unstable learning and suboptimal policies. To address this problem, we propose QSIM, a similarity weighted Q-learning framework that reconstructs the TD target using action similarity. Instead of using the greedy joint action directly, QSIM forms a similarity weighted expectation over a structured near-greedy joint action space. This formulation allows the target to integrate Q-values from diverse yet behaviorally related actions while assigning greater influence to those that are more similar to the greedy choice. By smoothing the target with structurally relevant alternatives, QSIM effectively mitigates overestimation and improves learning stability. Extensive experiments demonstrate that QSIM can be seamlessly integrated with various VD methods, consistently yielding superior performance and stability compared to the original algorithms. Furthermore, empirical analysis confirms that QSIM significantly mitigates the systematic value overestimation in MARL. Code is available at https://github.com/MaoMaoLYJ/pymarl-qsim.",
        "authors": [
          "Yuanjun Li",
          "Bin Zhang",
          "Hao Chen",
          "Zhouyang Jiang",
          "Dapeng Li",
          "Zhiwei Xu"
        ],
        "published": "2026-02-26T09:20:46Z",
        "updated": "2026-02-26T09:20:46Z",
        "categories": [
          "cs.MA",
          "cs.AI",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22786v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22302v1",
        "title": "Agent Behavioral Contracts: Formal Specification and Runtime Enforcement for Reliable Autonomous AI Agents",
        "summary": "Traditional software relies on contracts -- APIs, type systems, assertions -- to specify and enforce correct behavior. AI agents, by contrast, operate on prompts and natural language instructions with no formal behavioral specification. This gap is the root cause of drift, governance failures, and frequent project failures in agentic AI deployments. We introduce Agent Behavioral Contracts (ABC), a formal framework that brings Design-by-Contract principles to autonomous AI agents. An ABC contract C = (P, I, G, R) specifies Preconditions, Invariants, Governance policies, and Recovery mechanisms as first-class, runtime-enforceable components. We define (p, delta, k)-satisfaction -- a probabilistic notion of contract compliance that accounts for LLM non-determinism and recovery -- and prove a Drift Bounds Theorem showing that contracts with recovery rate gamma &gt; alpha (the natural drift rate) bound behavioral drift to D* = alpha/gamma in expectation, with Gaussian concentration in the stochastic setting. We establish sufficient conditions for safe contract composition in multi-agent chains and derive probabilistic degradation bounds. We implement ABC in AgentAssert, a runtime enforcement library, and evaluate on AgentContract-Bench, a benchmark of 200 scenarios across 7 models from 6 vendors. Results across 1,980 sessions show that contracted agents detect 5.2-6.8 soft violations per session that uncontracted baselines miss entirely (p &lt; 0.0001, Cohen's d = 6.7-33.8), achieve 88-100% hard constraint compliance, and bound behavioral drift to D* &lt; 0.27 across extended sessions, with 100% recovery for frontier models and 17-100% across all models, at overhead &lt; 10 ms per action.",
        "authors": [
          "Varun Pratap Bhardwaj"
        ],
        "published": "2026-02-25T18:42:56Z",
        "updated": "2026-02-25T18:42:56Z",
        "categories": [
          "cs.AI",
          "cs.MA",
          "cs.SE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22302v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21680v1",
        "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning",
        "summary": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.",
        "authors": [
          "David Eckel",
          "Henri Meeß"
        ],
        "published": "2026-02-25T08:33:39Z",
        "updated": "2026-02-25T08:33:39Z",
        "categories": [
          "cs.LG",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21680v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21634v1",
        "title": "AgentLTV: An Agent-Based Unified Search-and-Evolution Framework for Automated Lifetime Value Prediction",
        "summary": "Lifetime Value (LTV) prediction is critical in advertising, recommender systems, and e-commerce. In practice, LTV data patterns vary across decision scenarios. As a result, practitioners often build complex, scenario-specific pipelines and iterate over feature processing, objective design, and tuning. This process is expensive and hard to transfer. We propose AgentLTV, an agent-based unified search-and-evolution framework for automated LTV modeling. AgentLTV treats each candidate solution as an {executable pipeline program}. LLM-driven agents generate code, run and repair pipelines, and analyze execution feedback. Two decision agents coordinate a two-stage search. The Monte Carlo Tree Search (MCTS) stage explores a broad space of modeling choices under a fixed budget, guided by the Polynomial Upper Confidence bounds for Trees criterion and a Pareto-aware multi-metric value function. The Evolutionary Algorithm (EA) stage refines the best MCTS program via island-based evolution with crossover, mutation, and migration. Experiments on a large-scale proprietary dataset and a public benchmark show that AgentLTV consistently discovers strong models across ranking and error metrics. Online bucket-level analysis further indicates improved ranking consistency and value calibration, especially for high-value and negative-LTV segments. We summarize practitioner-oriented takeaways: use MCTS for rapid adaptation to new data patterns, use EA for stable refinement, and validate deployment readiness with bucket-level ranking and calibration diagnostics. The proposed AgentLTV has been successfully deployed online.",
        "authors": [
          "Chaowei Wu",
          "Huazhu Chen",
          "Congde Yuan",
          "Qirui Yang",
          "Guoqing Song",
          "Yue Gao",
          "Li Luo",
          "Frank Youhua Chen",
          "Mengzhuo Guo"
        ],
        "published": "2026-02-25T06:58:18Z",
        "updated": "2026-02-25T06:58:18Z",
        "categories": [
          "cs.LG",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21634v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21515v1",
        "title": "Training Generalizable Collaborative Agents via Strategic Risk Aversion",
        "summary": "Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.",
        "authors": [
          "Chengrui Qu",
          "Yizhou Zhang",
          "Nicholas Lanzetti",
          "Eric Mazumdar"
        ],
        "published": "2026-02-25T03:06:59Z",
        "updated": "2026-02-25T03:06:59Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21515v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21351v1",
        "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
        "summary": "The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.",
        "authors": [
          "Dmitrii Pantiukhin",
          "Ivan Kuznetsov",
          "Boris Shapkin",
          "Antonia Anna Jost",
          "Thomas Jung",
          "Nikolay Koldunov"
        ],
        "published": "2026-02-24T20:37:38Z",
        "updated": "2026-02-24T20:37:38Z",
        "categories": [
          "cs.AI",
          "cs.IR",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21351v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21020v1",
        "title": "Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning",
        "summary": "Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing examples where even exact measure matching fails, and demonstrating a new hardness result on characterizing the Nash gap given a fixed measure matching error. We then show how these challenges can be overcome using strategic dominance assumptions on the expert equilibrium. Specifically, for the case of dominant strategy expert equilibria, assuming Behavioral Cloning error $ε_{\\text{BC}}$, this provides a Nash imitation gap of $\\mathcal{O}\\left(nε_{\\text{BC}}/(1-γ)^2\\right)$ for a discount factor $γ$. We generalize this result with a new notion of best-response continuity, and argue that this is implicitly encouraged by standard regularization techniques.",
        "authors": [
          "Antoine Bergerault",
          "Volkan Cevher",
          "Negar Mehr"
        ],
        "published": "2026-02-24T15:38:11Z",
        "updated": "2026-02-24T15:38:11Z",
        "categories": [
          "cs.LG",
          "cs.GT",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21020v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.20804v1",
        "title": "Probing Dec-POMDP Reasoning in Cooperative MARL",
        "summary": "Cooperative multi-agent reinforcement learning (MARL) is typically framed as a decentralised partially observable Markov decision process (Dec-POMDP), a setting whose hardness stems from two key challenges: partial observability and decentralised coordination. Genuinely solving such tasks requires Dec-POMDP reasoning, where agents use history to infer hidden states and coordinate based on local information. Yet it remains unclear whether popular benchmarks actually demand this reasoning or permit success via simpler strategies. We introduce a diagnostic suite combining statistically grounded performance comparisons and information-theoretic probes to audit the behavioural complexity of baseline policies (IPPO and MAPPO) across 37 scenarios spanning MPE, SMAX, Overcooked, Hanabi, and MaBrax. Our diagnostics reveal that success on these benchmarks rarely requires genuine Dec-POMDP reasoning. Reactive policies match the performance of memory-based agents in over half the scenarios, and emergent coordination frequently relies on brittle, synchronous action coupling rather than robust temporal influence. These findings suggest that some widely used benchmarks may not adequately test core Dec-POMDP assumptions under current training paradigms, potentially leading to over-optimistic assessments of progress. We release our diagnostic tooling to support more rigorous environment design and evaluation in cooperative MARL.",
        "authors": [
          "Kale-ab Tessera",
          "Leonard Hinckeldey",
          "Riccardo Zamboni",
          "David Abel",
          "Amos Storkey"
        ],
        "published": "2026-02-24T11:44:46Z",
        "updated": "2026-02-24T11:44:46Z",
        "categories": [
          "cs.LG",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20804v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.20684v1",
        "title": "Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery",
        "summary": "Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gates. We evaluate three hypotheses: (H1) audit-ready artifacts emerge as a by-product of development, (H2) 100% requirement-level verification is achievable with independent test generation, and (H3) verified increments can be delivered with single-digit human interactions per cycle. A feasibility case study on a Hardware-in-the-Loop system (about 500 LOC, 8 requirements, 54 tests) supports all three hypotheses: audit-ready documentation was generated automatically (H1), 100% requirement-level pass rate was achieved (H2), and only 6 prompts per cycle were required (H3), yielding an estimated 10-50x cost reduction versus a COCOMO II baseline (sensitivity range from pessimistic to optimistic assumptions). We invite independent replication to validate generalizability.",
        "authors": [
          "Christopher Koch",
          "Joshua Andreas Wellbrock"
        ],
        "published": "2026-02-24T08:41:05Z",
        "updated": "2026-02-24T08:41:05Z",
        "categories": [
          "cs.SE",
          "cs.AI",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20684v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23116v1",
        "title": "Regularized Online RLHF with Generalized Bilinear Preferences",
        "summary": "We consider the problem of contextual online RLHF with general preferences, where the goal is to identify the Nash Equilibrium. We adopt the Generalized Bilinear Preference Model (GBPM) to capture potentially intransitive preferences via low-rank, skew-symmetric matrices. We investigate general preference learning with any strongly convex regularizer (where $η^{-1}$ is the regularization strength), generalizing beyond prior works limited to reverse KL-regularization. Central to our analysis is proving that the dual gap of the greedy policy is bounded by the square of the estimation error - a result derived solely from strong convexity and the skew-symmetricity of GBPM.Building on this insight and a feature diversity assumption, we establish two regret bounds via two simple algorithms: (1) Greedy Sampling achieves polylogarithmic, $e^{O(η)}$-free regret $\\tilde{O}(ηd^4 (\\log T)^2)$. (2) Explore-Then-Commit achieves $\\mathrm{poly}(d)$-free regret $\\tilde{O}(\\sqrt{ηr T})$ by exploiting the low-rank structure; this is the first statistically efficient guarantee for online RLHF in high-dimensions.",
        "authors": [
          "Junghyun Lee",
          "Minju Hong",
          "Kwang-Sung Jun",
          "Chulhee Yun",
          "Se-Young Yun"
        ],
        "published": "2026-02-26T15:27:53Z",
        "updated": "2026-02-26T15:27:53Z",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23116v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23023v1",
        "title": "Low-degree Lower bounds for clustering in moderate dimension",
        "summary": "We study the fundamental problem of clustering $n$ points into $K$ groups drawn from a mixture of isotropic Gaussians in $\\mathbb{R}^d$. Specifically, we investigate the requisite minimal distance $Δ$ between mean vectors to partially recover the underlying partition. While the minimax-optimal threshold for $Δ$ is well-established, a significant gap exists between this information-theoretic limit and the performance of known polynomial-time procedures. Although this gap was recently characterized in the high-dimensional regime ($n \\leq dK$), it remains largely unexplored in the moderate-dimensional regime ($n \\geq dK$). In this manuscript, we address this regime by establishing a new low-degree polynomial lower bound for the moderate-dimensional case when $d \\geq K$. We show that while the difficulty of clustering for $n \\leq dK$ is primarily driven by dimension reduction and spectral methods, the moderate-dimensional regime involves more delicate phenomena leading to a \"non-parametric rate\". We provide a novel non-spectral algorithm matching this rate, shedding new light on the computational limits of the clustering problem in moderate dimension.",
        "authors": [
          "Alexandra Carpentier",
          "Nicolas Verzelen"
        ],
        "published": "2026-02-26T14:03:55Z",
        "updated": "2026-02-26T14:03:55Z",
        "categories": [
          "math.ST",
          "cs.LG",
          "math.PR",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23023v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.23006v1",
        "title": "Regular Fourier Features for Nonstationary Gaussian Processes",
        "summary": "Simulating a Gaussian process requires sampling from a high-dimensional Gaussian distribution, which scales cubically with the number of sample locations. Spectral methods address this challenge by exploiting the Fourier representation, treating the spectral density as a probability distribution for Monte Carlo approximation. Although this probabilistic interpretation works for stationary processes, it is overly restrictive for the nonstationary case, where spectral densities are generally not probability measures. We propose regular Fourier features for harmonizable processes that avoid this limitation. Our method discretizes the spectral representation directly, preserving the correlation structure among spectral weights without requiring probability assumptions. Under a finite spectral support assumption, this yields an efficient low-rank approximation that is positive semi-definite by construction. When the spectral density is unknown, the framework extends naturally to kernel learning from data. We demonstrate the method on locally stationary kernels and on harmonizable mixture kernels with complex-valued spectral densities.",
        "authors": [
          "Arsalan Jawaid",
          "Abdullah Karatas",
          "Jörg Seewig"
        ],
        "published": "2026-02-26T13:50:28Z",
        "updated": "2026-02-26T13:50:28Z",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.23006v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22985v1",
        "title": "Kernel Integrated $R^2$: A Measure of Dependence",
        "summary": "We introduce kernel integrated $R^2$, a new measure of statistical dependence that combines the local normalization principle of the recently introduced integrated $R^2$ with the flexibility of reproducing kernel Hilbert spaces (RKHSs). The proposed measure extends integrated $R^2$ from scalar responses to responses taking values on general spaces equipped with a characteristic kernel, allowing to measure dependence of multivariate, functional, and structured data, while remaining sensitive to tail behaviour and oscillatory dependence structures. We establish that (i) this new measure takes values in $[0,1]$, (ii) equals zero if and only if independence holds, and (iii) equals one if and only if the response is almost surely a measurable function of the covariates. Two estimators are proposed: a graph-based method using $K$-nearest neighbours and an RKHS-based method built on conditional mean embeddings. We prove consistency and derive convergence rates for the graph-based estimator, showing its adaptation to intrinsic dimensionality. Numerical experiments on simulated data and a real data experiment in the context of dependency testing for media annotations demonstrate competitive power against state-of-the-art dependence measures, particularly in settings involving non-linear and structured relationships.",
        "authors": [
          "Pouya Roudaki",
          "Shakeel Gavioli-Akilagun",
          "Florian Kalinke",
          "Mona Azadkia",
          "Zoltán Szabó"
        ],
        "published": "2026-02-26T13:29:12Z",
        "updated": "2026-02-26T13:29:12Z",
        "categories": [
          "stat.ML",
          "cs.IT",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22985v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22925v1",
        "title": "Beyond NNGP: Large Deviations and Feature Learning in Bayesian Neural Networks",
        "summary": "We study wide Bayesian neural networks focusing on the rare but statistically dominant fluctuations that govern posterior concentration, beyond Gaussian-process limits. Large-deviation theory provides explicit variational objectives-rate functions-on predictors, providing an emerging notion of complexity and feature learning directly at the functional level. We show that the posterior output rate function is obtained by a joint optimization over predictors and internal kernels, in contrast with fixed-kernel (NNGP) theory. Numerical experiments demonstrate that the resulting predictions accurately describe finite-width behavior for moderately sized networks, capturing non-Gaussian tails, posterior deformation, and data-dependent kernel selection effects.",
        "authors": [
          "Katerina Papagiannouli",
          "Dario Trevisan",
          "Giuseppe Pio Zitto"
        ],
        "published": "2026-02-26T12:15:11Z",
        "updated": "2026-02-26T12:15:11Z",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22925v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22884v1",
        "title": "Unsupervised Continual Learning for Amortized Bayesian Inference",
        "summary": "Amortized Bayesian Inference (ABI) enables efficient posterior estimation using generative neural networks trained on simulated data, but often suffers from performance degradation under model misspecification. While self-consistency (SC) training on unlabeled empirical data can enhance network robustness, current approaches are limited to static, single-task settings and fail to handle sequentially arriving data or distribution shifts. We propose a continual learning framework for ABI that decouples simulation-based pre-training from unsupervised sequential SC fine-tuning on real-world data. To address the challenge of catastrophic forgetting, we introduce two adaptation strategies: (1) SC with episodic replay, utilizing a memory buffer of past observations, and (2) SC with elastic weight consolidation, which regularizes updates to preserve task-critical parameters. Across three diverse case studies, our methods significantly mitigate forgetting and yield posterior estimates that outperform standard simulation-based training, achieving estimates closer to MCMC reference, providing a viable path for trustworthy ABI across a range of different tasks.",
        "authors": [
          "Aayush Mishra",
          "Šimon Kucharský",
          "Paul-Christian Bürkner"
        ],
        "published": "2026-02-26T11:22:46Z",
        "updated": "2026-02-26T11:22:46Z",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22884v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22847v1",
        "title": "Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus",
        "summary": "The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i.e., when all the ranking data to be aggregated can be brought together in a single computing unit. For many technologies (e.g. peer-to-peer networks, IoT, multi-agent systems), extending the ability to calculate consensus rankings with guarantees in a decentralized setting, i.e., when preference data is initially distributed across a communicating network, remains a major methodological challenge. Indeed, in recent years, the literature on decentralized computation has mainly focused on computing or optimizing statistics such as arithmetic means using gossip algorithms. The purpose of this article is precisely to study how to achieve reliable consensus on collective rankings using classical rules (e.g. Borda, Copeland) in a decentralized setting, thereby raising new questions, robustness to corrupted nodes, and scalability through reduced communication costs in particular. The approach proposed and analyzed here relies on random gossip communication, allowing autonomous agents to compute global ranking consensus using only local interactions, without coordination or central authority. We provide rigorous convergence guarantees, including explicit rate bounds, for the Borda and Copeland consensus methods. Beyond these rules, we also provide a decentralized implementation of consensus according to the median rank rule and local Kemenization. Extensive empirical evaluations on various network topologies and real and synthetic ranking datasets demonstrate that our algorithms converge quickly and reliably to the correct ranking aggregation.",
        "authors": [
          "Anna Van Elst",
          "Kerrian Le Caillec",
          "Igor Colin",
          "Stephan Clémençon"
        ],
        "published": "2026-02-26T10:37:23Z",
        "updated": "2026-02-26T10:37:23Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22847v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22505v1",
        "title": "Sharp Convergence Rates for Masked Diffusion Models",
        "summary": "Discrete diffusion models have achieved strong empirical performance in text and other symbolic domains, with masked (absorbing-rate) variants emerging as competitive alternatives to autoregressive models. Among existing samplers, the Euler method remains the standard choice in many applications, and more recently, the First-Hitting Sampler (FHS) has shown considerable promise for masked diffusion models. Despite their practical success, the theoretical understanding of these samplers remains limited. Existing analyses are conducted in Kullback-Leibler (KL) divergence, which often yields loose parameter dependencies and requires strong assumptions on score estimation. Moreover, these guarantees do not cover recently developed high-performance sampler of FHS. In this work, we first develop a direct total-variation (TV) based analysis for the Euler method that overcomes these limitations. Our results relax assumptions on score estimation, improve parameter dependencies, and establish convergence guarantees without requiring any surrogate initialization. Also for this setting, we provide the first convergence lower bound for the Euler sampler, establishing tightness with respect to both the data dimension $d$ and the target accuracy $\\varepsilon$. Finally, we analyze the FHS sampler and show that it incurs no sampling error beyond that induced by score estimation, which we show to be tight with a matching lower error bound. Overall, our analysis introduces a direct TV-based error decomposition along the CTMC trajectory and a decoupling-based path-wise analysis for FHS, which may be of independent interest.",
        "authors": [
          "Yuchen Liang",
          "Zhiheng Tan",
          "Ness Shroff",
          "Yingbin Liang"
        ],
        "published": "2026-02-26T00:47:51Z",
        "updated": "2026-02-26T00:47:51Z",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22505v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22492v1",
        "title": "From Shallow Bayesian Neural Networks to Gaussian Processes: General Convergence, Identifiability and Scalable Inference",
        "summary": "In this work, we study scaling limits of shallow Bayesian neural networks (BNNs) via their connection to Gaussian processes (GPs), with an emphasis on statistical modeling, identifiability, and scalable inference. We first establish a general convergence result from BNNs to GPs by relaxing assumptions used in prior formulations, and we compare alternative parameterizations of the limiting GP model. Building on this theory, we propose a new covariance function defined as a convex mixture of components induced by four widely used activation functions, and we characterize key properties including positive definiteness and both strict and practical identifiability under different input designs. For computation, we develop a scalable maximum a posterior (MAP) training and prediction procedure using a Nyström approximation, and we show how the Nyström rank and anchor selection control the cost-accuracy trade-off. Experiments on controlled simulations and real-world tabular datasets demonstrate stable hyperparameter estimates and competitive predictive performance at realistic computational cost.",
        "authors": [
          "Gracielle Antunes de Araújo",
          "Flávio B. Gonçalves"
        ],
        "published": "2026-02-26T00:02:54Z",
        "updated": "2026-02-26T00:02:54Z",
        "categories": [
          "stat.ML",
          "cs.AI",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22492v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22486v1",
        "title": "Flow Matching is Adaptive to Manifold Structures",
        "summary": "Flow matching has emerged as a simulation-free alternative to diffusion-based generative modeling, producing samples by solving an ODE whose time-dependent velocity field is learned along an interpolation between a simple source distribution (e.g., a standard normal) and a target data distribution. Flow-based methods often exhibit greater training stability and have achieved strong empirical performance in high-dimensional settings where data concentrate near a low-dimensional manifold, such as text-to-image synthesis, video generation, and molecular structure generation. Despite this success, existing theoretical analyses of flow matching assume target distributions with smooth, full-dimensional densities, leaving its effectiveness in manifold-supported settings largely unexplained. To this end, we theoretically analyze flow matching with linear interpolation when the target distribution is supported on a smooth manifold. We establish a non-asymptotic convergence guarantee for the learned velocity field, and then propagate this estimation error through the ODE to obtain statistical consistency of the implicit density estimator induced by the flow-matching objective. The resulting convergence rate is near minimax-optimal, depends only on the intrinsic dimension, and reflects the smoothness of both the manifold and the target distribution. Together, these results provide a principled explanation for how flow matching adapts to intrinsic data geometry and circumvents the curse of dimensionality.",
        "authors": [
          "Shivam Kumar",
          "Yixin Wang",
          "Lizhen Lin"
        ],
        "published": "2026-02-25T23:52:32Z",
        "updated": "2026-02-25T23:52:32Z",
        "categories": [
          "stat.ML",
          "cs.LG",
          "math.ST"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22486v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22432v1",
        "title": "LoBoost: Fast Model-Native Local Conformal Prediction for Gradient-Boosted Trees",
        "summary": "Gradient-boosted decision trees are among the strongest off-the-shelf predictors for tabular regression, but point predictions alone do not quantify uncertainty. Conformal prediction provides distribution-free marginal coverage, yet split conformal uses a single global residual quantile and can be poorly adaptive under heteroscedasticity. Methods that improve adaptivity typically fit auxiliary nuisance models or introduce additional data splits/partitions to learn the conformal score, increasing cost and reducing data efficiency. We propose LoBoost, a model-native local conformal method that reuses the fitted ensemble's leaf structure to define multiscale calibration groups. Each input is encoded by its sequence of visited leaves; at resolution level k, we group points by matching prefixes of leaf indices across the first k trees and calibrate residual quantiles within each group. LoBoost requires no retraining, auxiliary models, or extra splitting beyond the standard train/calibration split. Experiments show competitive interval quality, improved test MSE on most datasets, and large calibration speedups.",
        "authors": [
          "Vagner Santos",
          "Victor Coscrato",
          "Luben Cabezas",
          "Rafael Izbicki",
          "Thiago Ramos"
        ],
        "published": "2026-02-25T21:44:19Z",
        "updated": "2026-02-25T21:44:19Z",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22432v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22334v1",
        "title": "A 1/R Law for Kurtosis Contrast in Balanced Mixtures",
        "summary": "Kurtosis-based Independent Component Analysis (ICA) weakens in wide, balanced mixtures. We prove a sharp redundancy law: for a standardized projection with effective width $R_{\\mathrm{eff}}$ (participation ratio), the population excess kurtosis obeys $|κ(y)|=O(κ_{\\max}/R_{\\mathrm{eff}})$, yielding the order-tight $O(c_bκ_{\\max}/R)$ under balance (typically $c_b=O(\\log R)$). As an impossibility screen, under standard finite-moment conditions for sample kurtosis estimation, surpassing the $O(1/\\sqrt{T})$ estimation scale requires $R\\lesssim κ_{\\max}\\sqrt{T}$. We also show that \\emph{purification} -- selecting $m\\!\\ll\\!R$ sign-consistent sources -- restores $R$-independent contrast $Ω(1/m)$, with a simple data-driven heuristic. Synthetic experiments validate the predicted decay, the $\\sqrt{T}$ crossover, and contrast recovery.",
        "authors": [
          "Yuda Bi",
          "Wenjun Xiao",
          "Linhao Bai",
          "Vince D Calhoun"
        ],
        "published": "2026-02-25T19:01:01Z",
        "updated": "2026-02-25T19:01:01Z",
        "categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22334v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22122v1",
        "title": "Probing the Geometry of Diffusion Models with the String Method",
        "summary": "Understanding the geometry of learned distributions is fundamental to improving and interpreting diffusion models, yet systematic tools for exploring their landscape remain limited. Standard latent-space interpolations fail to respect the structure of the learned distribution, often traversing low-density regions. We introduce a framework based on the string method that computes continuous paths between samples by evolving curves under the learned score function. Operating on pretrained models without retraining, our approach interpolates between three regimes: pure generative transport, which yields continuous sample paths; gradient-dominated dynamics, which recover minimum energy paths (MEPs); and finite-temperature string dynamics, which compute principal curves -- self-consistent paths that balance energy and entropy. We demonstrate that the choice of regime matters in practice. For image diffusion models, MEPs contain high-likelihood but unrealistic ''cartoon'' images, confirming prior observations that likelihood maxima appear unrealistic; principal curves instead yield realistic morphing sequences despite lower likelihood. For protein structure prediction, our method computes transition pathways between metastable conformers directly from models trained on static structures, yielding paths with physically plausible intermediates. Together, these results establish the string method as a principled tool for probing the modal structure of diffusion models -- identifying modes, characterizing barriers, and mapping connectivity in complex learned distributions.",
        "authors": [
          "Elio Moreau",
          "Florentin Coeurdoux",
          "Grégoire Ferre",
          "Eric Vanden-Eijnden"
        ],
        "published": "2026-02-25T17:10:59Z",
        "updated": "2026-02-25T17:10:59Z",
        "categories": [
          "stat.ML",
          "cs.LG"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22122v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22083v1",
        "title": "Coarsening Bias from Variable Discretization in Causal Functionals",
        "summary": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation.",
        "authors": [
          "Xiaxian Ou",
          "Razieh Nabi"
        ],
        "published": "2026-02-25T16:32:04Z",
        "updated": "2026-02-25T16:32:04Z",
        "categories": [
          "stat.ME",
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22083v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.22003v1",
        "title": "Neural solver for Wasserstein Geodesics and optimal transport dynamics",
        "summary": "In recent years, the machine learning community has increasingly embraced the optimal transport (OT) framework for modeling distributional relationships. In this work, we introduce a sample-based neural solver for computing the Wasserstein geodesic between a source and target distribution, along with the associated velocity field. Building on the dynamical formulation of the optimal transport (OT) problem, we recast the constrained optimization as a minimax problem, using deep neural networks to approximate the relevant functions. This approach not only provides the Wasserstein geodesic but also recovers the OT map, enabling direct sampling from the target distribution. By estimating the OT map, we obtain velocity estimates along particle trajectories, which in turn allow us to learn the full velocity field. The framework is flexible and readily extends to general cost functions, including the commonly used quadratic cost. We demonstrate the effectiveness of our method through experiments on both synthetic and real datasets.",
        "authors": [
          "Hailiang Liu",
          "Yan-Han Chen"
        ],
        "published": "2026-02-25T15:21:24Z",
        "updated": "2026-02-25T15:21:24Z",
        "categories": [
          "cs.LG",
          "math.OC",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22003v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21948v1",
        "title": "Bayesian Generative Adversarial Networks via Gaussian Approximation for Tabular Data Synthesis",
        "summary": "Generative Adversarial Networks (GAN) have been used in many studies to synthesise mixed tabular data. Conditional tabular GAN (CTGAN) have been the most popular variant but struggle to effectively navigate the risk-utility trade-off. Bayesian GAN have received less attention for tabular data, but have been explored with unstructured data such as images and text. The most used technique employed in Bayesian GAN is Markov Chain Monte Carlo (MCMC), but it is computationally intensive, particularly in terms of weight storage. In this paper, we introduce Gaussian Approximation of CTGAN (GACTGAN), an integration of the Bayesian posterior approximation technique using Stochastic Weight Averaging-Gaussian (SWAG) within the CTGAN generator to synthesise tabular data, reducing computational overhead after the training phase. We demonstrate that GACTGAN yields better synthetic data compared to CTGAN, achieving better preservation of tabular structure and inferential statistics with less privacy risk. These results highlight GACTGAN as a simpler, effective implementation of Bayesian tabular synthesis.",
        "authors": [
          "Bahrul Ilmi Nasution",
          "Mark Elliot",
          "Richard Allmendinger"
        ],
        "published": "2026-02-25T14:32:58Z",
        "updated": "2026-02-25T14:32:58Z",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21948v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21928v1",
        "title": "Learning Unknown Interdependencies for Decentralized Root Cause Analysis in Nonlinear Dynamical Systems",
        "summary": "Root cause analysis (RCA) in networked industrial systems, such as supply chains and power networks, is notoriously difficult due to unknown and dynamically evolving interdependencies among geographically distributed clients. These clients represent heterogeneous physical processes and industrial assets equipped with sensors that generate large volumes of nonlinear, high-dimensional, and heterogeneous IoT data. Classical RCA methods require partial or full knowledge of the system's dependency graph, which is rarely available in these complex networks. While federated learning (FL) offers a natural framework for decentralized settings, most existing FL methods assume homogeneous feature spaces and retrainable client models. These assumptions are not compatible with our problem setting. Different clients have different data features and often run fixed, proprietary models that cannot be modified. This paper presents a federated cross-client interdependency learning methodology for feature-partitioned, nonlinear time-series data, without requiring access to raw sensor streams or modifying proprietary client models. Each proprietary local client model is augmented with a Machine Learning (ML) model that encodes cross-client interdependencies. These ML models are coordinated via a global server that enforces representation consistency while preserving privacy through calibrated differential privacy noise. RCA is performed using model residuals and anomaly flags. We establish theoretical convergence guarantees and validate our approach on extensive simulations and a real-world industrial cybersecurity dataset.",
        "authors": [
          "Ayush Mohanty",
          "Paritosh Ramanan",
          "Nagi Gebraeel"
        ],
        "published": "2026-02-25T14:05:38Z",
        "updated": "2026-02-25T14:05:38Z",
        "categories": [
          "cs.LG",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21928v1.pdf",
        "category": "ml-theory"
      },
      {
        "id": "2602.21846v1",
        "title": "Scalable Kernel-Based Distances for Statistical Inference and Integration",
        "summary": "Representing, comparing, and measuring the distance between probability distributions is a key task in computational statistics and machine learning. The choice of representation and the associated distance determine properties of the methods in which they are used: for example, certain distances can allow one to encode robustness or smoothness of the problem. Kernel methods offer flexible and rich Hilbert space representations of distributions that allow the modeller to enforce properties through the choice of kernel, and estimate associated distances at efficient nonparametric rates. In particular, the maximum mean discrepancy (MMD), a kernel-based distance constructed by comparing Hilbert space mean functions, has received significant attention due to its computational tractability and is favoured by practitioners. In this thesis, we conduct a thorough study of kernel-based distances with a focus on efficient computation, with core contributions in Chapters 3 to 6. Part I of the thesis is focused on the MMD, specifically on improved MMD estimation. In Chapter 3 we propose a theoretically sound, improved estimator for MMD in simulation-based inference. Then, in Chapter 4, we propose an MMD-based estimator for conditional expectations, a ubiquitous task in statistical computation. Closing Part I, in Chapter 5 we study the problem of calibration when MMD is applied to the task of integration. In Part II, motivated by the recent developments in kernel embeddings beyond the mean, we introduce a family of novel kernel-based discrepancies: kernel quantile discrepancies. These address some of the pitfalls of MMD, and are shown through both theoretical results and an empirical study to offer a competitive alternative to MMD and its fast approximations. We conclude with a discussion on broader lessons and future work emerging from the thesis.",
        "authors": [
          "Masha Naslidnyk"
        ],
        "published": "2026-02-25T12:25:34Z",
        "updated": "2026-02-25T12:25:34Z",
        "categories": [
          "stat.ML",
          "cs.LG",
          "math.ST",
          "stat.ME"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21846v1.pdf",
        "category": "ml-theory"
      }
    ],
    "other": [
      {
        "id": "2602.22804v1",
        "title": "Communication-Guided Multi-Mutation Differential Evolution for Crop Model Calibration",
        "summary": "In this paper, we propose a multi-mutation optimization algorithm, Differential Evolution with Multi-Mutation Operator-Guided Communication (DE-MMOGC), implemented to improve the performance and convergence abilities of standard differential evolution in uncertain environments. DE-MMOGC introduces a communication-guided scheme integrated with multiple mutation operators to encourage exploration and avoid premature convergence. Along with this, it includes a dynamic operator selection mechanism to use the best-performing operator over successive generations. To assimilate real-world uncertainties and missing observations into the predictive model, the proposed algorithm is combined with the Ensemble Kalman Filter. To evaluate the efficacy of the proposed DE-MMOGC in uncertain systems, the unified framework is applied to improve the predictive accuracy of crop simulation models. These simulation models are essential to precision agriculture, as they make it easier to estimate crop growth in a variety of unpredictable weather scenarios. Additionally, precisely calibrating these models raises a challenge due to missing observations. Hence, the simplified WOFOST crop simulation model is incorporated in this study for leaf area index (LAI)-based crop yield estimation. DE-MMOGC enhances the WOFOST performance by optimizing crucial weather parameters (temperature and rainfall), since these parameters are highly uncertain across different crop varieties, such as wheat, rice, and cotton. The experimental study shows that DE-MMOGC outperforms the traditional evolutionary optimizers and achieves better correlation with real LAI values. We found that DE-MMOGC is a resilient solution for crop monitoring.",
        "authors": [
          "Sakshi Aggarwal",
          "Mudasir Ganaie",
          "Mukesh Saini"
        ],
        "published": "2026-02-26T09:40:58Z",
        "updated": "2026-02-26T09:40:58Z",
        "categories": [
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22804v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22173v1",
        "title": "Applying a Random-Key Optimizer on Mixed Integer Programs",
        "summary": "Mixed-Integer Programs (MIPs) are NP-hard optimization models that arise in a broad range of decision-making applications, including finance, logistics, energy systems, and network design. Although modern commercial solvers have achieved remarkable progress and perform effectively on many small- and medium-sized instances, their performance often degrades when confronted with large-cale or highly constrained formulations. This paper explores the use of the Random-Key Optimizer (RKO) framework as a flexible, metaheuristic alternative for computing high-quality solutions to MIPs through the design of problem-specific decoders. The proposed approach separates the search process from feasibility enforcement by operating in a continuous random-key space while mapping candidate solutions to feasible integer solutions via efficient decoding procedures. We evaluate the methodology on two representative and structurally distinct benchmark problems: the mean-variance Markowitz portfolio optimization problem with buy-in and cardinality constraints, and the Time-Dependent Traveling Salesman Problem. For each formulation, tailored decoders are developed to reduce the effective search space, promote feasibility, and accelerate convergence. Computational experiments demonstrate that RKO consistently produces competitive, and in several cases superior, solutions compared to a state-of-the-art commercial MIP solver, both in terms of solution quality and computational time. These results highlight the potential of RKO as a scalable and versatile heuristic framework for tackling challenging large-scale MIPs.",
        "authors": [
          "Antonio A. Chaves",
          "Mauricio G. C. Resende",
          "Carise E. Schmidt",
          "J. Kyle Brubaker",
          "Helmut G. Katzgraber"
        ],
        "published": "2026-02-25T18:20:03Z",
        "updated": "2026-02-25T18:20:03Z",
        "categories": [
          "math.OC",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22173v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22152v1",
        "title": "Stream Neural Networks: Epoch-Free Learning with Persistent Temporal State",
        "summary": "Most contemporary neural learning systems rely on epoch-based optimization and repeated access to historical data, implicitly assuming reversible computation. In contrast, real-world environments often present information as irreversible streams, where inputs cannot be replayed or revisited. Under such conditions, conventional architectures degrade into reactive filters lacking long-horizon coherence. This paper introduces Stream Neural Networks (StNN), an execution paradigm designed for irreversible input streams. StNN operates through a stream-native execution algorithm, the Stream Network Algorithm (SNA), whose fundamental unit is the stream neuron. Each stream neuron maintains a persistent temporal state that evolves continuously across inputs. We formally establish three structural guarantees: (1) stateless mappings collapse under irreversibility and cannot encode temporal dependencies; (2) persistent state dynamics remain bounded under mild activation constraints; and (3) the state transition operator is contractive for λ &lt; 1, ensuring stable long-horizon execution. Empirical phase-space analysis and continuous tracking experiments validate these theoretical results. The execution principles introduced in this work define a minimal substrate for neural computation under irreversible streaming constraints.",
        "authors": [
          "Amama Pathan"
        ],
        "published": "2026-02-25T18:00:17Z",
        "updated": "2026-02-25T18:00:17Z",
        "categories": [
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22152v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.20846v1",
        "title": "Body-Reservoir Governance in Repeated Games: Embodied Decision-Making, Dynamic Sentinel Adaptation, and Complexity-Regularized Optimization",
        "summary": "Standard game theory explains cooperation in repeated games through conditional strategies such as Tit-for-Tat (TfT), but these require continuous computation that imposes physical costs on embodied agents. We propose a three-layer Body-Reservoir Governance (BRG) architecture: (1) a body reservoir (echo state network) whose $d$-dimensional state performs implicit inference over interaction history, serving as both decision-maker and anomaly detector, (2) a cognitive filter providing costly strategic tools activated on demand, and (3) a metacognitive governance layer with receptivity parameter $α\\in [0,1]$. At full body governance ($α=1$), closed-loop dynamics satisfy a self-consistency equation: cooperation is expressed as the reservoir's fixed point, not computed. Strategy complexity cost is defined as the KL divergence between the reservoir's state distribution and its habituated baseline. Body governance reduces this cost, with action variance decreasing up to $1600\\times$ with dimension $d$. A dynamic sentinel generates a composite discomfort signal from the reservoir's own state, driving adaptive $α(t)$: near baseline during cooperation, rapidly dropping upon defection to activate cognitive retaliation. Overriding the body incurs thermodynamic cost proportional to internal state distortion. The sentinel achieves the highest payoff across all conditions, outperforming static body governance, TfT, and EMA baselines. A dimension sweep ($d \\in \\{5,\\ldots,100\\}$) shows implicit inference scales with bodily richness ($23\\times$ to $1600\\times$ variance reduction), attributable to reservoir dynamics. A phase diagram in $(d, τ_{\\mathrm{env}})$ space reveals governance regime transitions near $d \\approx 20$. The framework reinterprets cooperation as the minimum-dissipation response of an adapted dynamical system -- emergent from embodied dynamics rather than computed.",
        "authors": [
          "Yuki Nakamura"
        ],
        "published": "2026-02-24T12:36:41Z",
        "updated": "2026-02-24T12:36:41Z",
        "categories": [
          "cs.GT",
          "cs.MA",
          "cs.NE",
          "nlin.AO"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20846v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.19802v1",
        "title": "Linear Reservoir: A Diagonalization-Based Optimization",
        "summary": "We introduce a diagonalization-based optimization for Linear Echo State Networks (ESNs) that reduces the per-step computational complexity of reservoir state updates from O(N^2) to O(N). By reformulating reservoir dynamics in the eigenbasis of the recurrent matrix, the recurrent update becomes a set of independent element-wise operations, eliminating the matrix multiplication. We further propose three methods to use our optimization depending on the situation: (i) Eigenbasis Weight Transformation (EWT), which preserves the dynamics of standard and trained Linear ESNs, (ii) End-to-End Eigenbasis Training (EET), which directly optimizes readout weights in the transformed space and (iii) Direct Parameter Generation (DPG), that bypasses matrix diagonalization by directly sampling eigenvalues and eigenvectors, achieving comparable performance than standard Linear ESNs. Across all experiments, both our methods preserve predictive accuracy while offering significant computational speedups, making them a replacement of standard Linear ESNs computations and training, and suggesting a shift of paradigm in linear ESN towards the direct selection of eigenvalues.",
        "authors": [
          "Romain de Coudenhove",
          "Yannis Bendi-Ouis",
          "Anthony Strock",
          "Xavier Hinaut"
        ],
        "published": "2026-02-23T12:58:34Z",
        "updated": "2026-02-23T12:58:34Z",
        "categories": [
          "cs.DC",
          "cs.NE",
          "math.CV",
          "math.DS"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.19802v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18989v1",
        "title": "All Constant Mutation Rates for the $(1+1)$ Evolutionary Algorithm",
        "summary": "For every mutation rate $p \\in (0, 1)$, and for all $\\varepsilon &gt; 0$, there is a fitness function $f : \\{0,1\\}^n \\to \\mathbb{R}$ with a unique maximum for which the optimal mutation rate for the $(1+1)$ evolutionary algorithm on $f$ is in $(p-\\varepsilon, p+\\varepsilon)$. In other words, the set of optimal mutation rates for the $(1+1)$ EA is dense in the interval $[0, 1]$. To show that, this paper introduces DistantSteppingStones, a fitness function which consists of large plateaus separated by large fitness valleys.",
        "authors": [
          "Andrew James Kelley"
        ],
        "published": "2026-02-22T00:30:45Z",
        "updated": "2026-02-22T00:30:45Z",
        "categories": [
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18989v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18635v1",
        "title": "Musical Training, but not Mere Exposure to Music, Drives the Emergence of Chroma Equivalence in Artificial Neural Networks",
        "summary": "Pitch is a fundamental aspect of auditory perception. Pitch perception is commonly described across two perceptual dimensions: pitch height is the sense that tones with varying frequencies seem to be higher or lower, and chroma equivalence is the cyclical similarity of notes octaves, corresponding to a doubling of fundamental frequency. Existing research is divided on whether chroma equivalence is a learned percept that varies according to musical experience and culture, or is an innate percept that develops automatically. Building on a recent framework that proposes to use ANNs to ask 'why' questions about the brain, we evaluated recent auditory ANNs using representational similarity analysis to test the emergence of pitch height and chroma equivalence in their learned representations. Additionally, we fine-tuned two models, Wav2Vec 2.0 and Data2Vec, on a self-supervised learning task using speech and music, and a supervised music transcription task. We found that all models exhibited varying degrees of pitch height representation, but that only models trained on the supervised music transcription task exhibited chroma equivalence. Mere exposure to music through self-supervised learning was not sufficient for chroma equivalence to emerge. This supports the view that chroma equivalence is a higher-order cognitive computation that emerges to support the specific task of music perception, distinct from other auditory perception such as speech listening. This work also highlights the usefulness of ANNs for probing the developmental conditions that give rise to perceptual representations in humans.",
        "authors": [
          "Lukas Grasse",
          "Matthew S. Tata"
        ],
        "published": "2026-02-20T22:07:01Z",
        "updated": "2026-02-20T22:07:01Z",
        "categories": [
          "cs.SD",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18635v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18140v1",
        "title": "Flexi-NeurA: A Configurable Neuromorphic Accelerator with Adaptive Bit-Precision Exploration for Edge SNNs",
        "summary": "Neuromorphic accelerators promise unparalleled energy efficiency and computational density for spiking neural networks (SNNs), especially in edge intelligence applications. However, most existing platforms exhibit rigid architectures with limited configurability, restricting their adaptability to heterogeneous workloads and diverse design objectives. To address these limitations, we present Flexi-NeurA -- a parameterizable neuromorphic accelerator (core) that unifies configurability, flexibility, and efficiency. Flexi-NeurA allows users to customize neuron models, network structures, and precision settings at design time. By pairing these design-time configurability and flexibility features with a time-multiplexed and event-driven processing approach, Flexi-NeurA substantially reduces the required hardware resources and total power while preserving high efficiency and low inference latency. Complementing this, we introduce Flex-plorer, a heuristic-guided design-space exploration (DSE) tool that determines cost-effective fixed-point precisions for critical parameters -- such as decay factors, synaptic weights, and membrane potentials -- based on user-defined trade-offs between accuracy and resource usage. Based on the configuration selected through the Flex-plorer process, RTL code is configured to match the specified design. Comprehensive evaluations across MNIST, SHD, and DVS benchmarks demonstrate that the Flexi-NeurA and Flex-plorer co-framework achieves substantial improvements in accuracy, latency, and energy efficiency. A three-layer 256--128--10 fully connected network with LIF neurons mapped onto two processing cores achieves 97.23% accuracy on MNIST with 1.1~ms inference latency, utilizing only 1,623 logic cells, 7 BRAMs, and 111~mW of total power -- establishing Flexi-NeurA as a scalable, edge-ready neuromorphic platform.",
        "authors": [
          "Mohammad Farahani",
          "Mohammad Rasoul Roshanshah",
          "Saeed Safari"
        ],
        "published": "2026-02-20T11:01:09Z",
        "updated": "2026-02-20T11:01:09Z",
        "categories": [
          "cs.AR",
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18140v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18042v1",
        "title": "PINEAPPLE: Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter Inference in Lithium-Ion Battery Electrodes",
        "summary": "Accurate, real-time, yet non-destructive estimation of internal states in lithium-ion batteries is critical for predicting degradation, optimizing usage strategies, and extending operational lifespan. Here, we introduce PINEAPPLE (Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter inference in Lithium-ion battery Electrodes), a novel framework that integrates physics-informed neural networks (PINNs) with an evolutionary search algorithm to enable rapid, scalable, and interpretable parameter inference with potential for application to next-generation batteries. The meta-learned PINN utilizes fundamental physics principles to achieve accurate zero-shot prediction of electrode behavior with test errors below 0.1$\\%$ while maintaining an order-of-magnitude speed-up over conventional solvers. PINEAPPLE demonstrates robust parameter inference solely from voltage-time discharge curves across multiple batteries from the open-source CALCE repository, recovering the evolution of key internal state parameters such as Li-ion diffusion coefficients across usage cycles. Notably, the inferred cycle-dependent evolution of these parameters exhibit consistent trends across different batteries without any customized degradation physics-embedded heuristic, highlighting the effective regularizing effect and robustness that can be conferred through incorporation of fundamental physics in PINEAPPLE. By enabling computationally efficient, real-time parameter estimation, PINEAPPLE offers a promising route towards the non-destructive, physics-based characterization of inter-cell and intra-cell variability of battery modules and battery packs, thereby unlocking new opportunities for downstream on-the-fly needs in next-generation battery management systems such as individual cell-scale state-of-health diagnostics.",
        "authors": [
          "Karkulali Pugalenthi",
          "Jian Cheng Wong",
          "Qizheng Yang",
          "Pao-Hsiung Chiu",
          "My Ha Dao",
          "Nagarajan Raghavan",
          "Chinchun Ooi"
        ],
        "published": "2026-02-20T07:51:59Z",
        "updated": "2026-02-20T07:51:59Z",
        "categories": [
          "cs.CE",
          "cs.NE",
          "physics.comp-ph"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18042v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18508v1",
        "title": "Parallelizable Neural Turing Machines",
        "summary": "We introduce a parallelizable simplification of Neural Turing Machine (NTM), referred to as P-NTM, which redesigns the core operations of the original architecture to enable efficient scan-based parallel execution. We evaluate the proposed architecture on a synthetic benchmark of algorithmic problems involving state tracking, memorization, and basic arithmetic, solved via autoregressive decoding. We compare it against a revisited stable implementation of the standard NTM, as well as conventional recurrent and attention-based architectures. Results show that, despite its simplifications, the proposed model attains length generalization performance comparable to the original, learning to solve all problems, including unseen sequence lengths, with perfect accuracy. It also improves training efficiency, with parallel execution of P-NTM being up to an order of magnitude faster than the standard NTM. Ultimately, this work contributes toward the development of efficient neural architectures capable of expressing a broad class of algorithms.",
        "authors": [
          "Gabriel Faria",
          "Arnaldo Candido Junior"
        ],
        "published": "2026-02-18T17:43:51Z",
        "updated": "2026-02-18T17:43:51Z",
        "categories": [
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18508v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.18507v1",
        "title": "Fine-Pruning: A Biologically Inspired Algorithm for Personalization of Machine Learning Models",
        "summary": "Neural networks have long strived to emulate the learning capabilities of the human brain. While deep neural networks (DNNs) draw inspiration from the brain in neuron design, their training methods diverge from biological foundations. Backpropagation, the primary training method for DNNs, requires substantial computational resources and fully labeled datasets, presenting major bottlenecks in development and application. This work demonstrates that by returning to biomimicry, specifically mimicking how the brain learns through pruning, we can solve various classical machine learning problems while utilizing orders of magnitude fewer computational resources and no labels. Our experiments successfully personalized multiple speech recognition and image classification models, including ResNet50 on ImageNet, resulting in increased sparsity of approximately 70\\% while simultaneously improving model accuracy to around 90\\%, all without the limitations of backpropagation. This biologically inspired approach offers a promising avenue for efficient, personalized machine learning models in resource-constrained environments.",
        "authors": [
          "Joseph Bingham",
          "Saman Zonouz",
          "Dvir Aran"
        ],
        "published": "2026-02-18T13:23:56Z",
        "updated": "2026-02-18T13:23:56Z",
        "categories": [
          "cs.NE",
          "q-bio.NC"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.18507v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.16321v1",
        "title": "End-user validation of BRIGHT with custom-developed graphical user interface applied to cervical cancer brachytherapy",
        "summary": "Multi-objective optimisation using BRIGHT has proven insightful and effective in prostate cancer brachytherapy treatment planning. BRachytherapy via artificially Intelligent GOMEA-Heuristic based Treatment planning (BRIGHT) generates multiple treatment plans, each with a different trade-off between tumour coverage and organs-at-risk sparing. BRIGHT was recently extended to cervical cancer brachytherapy. In this study, we present a novel, custom-developed graphical user interface (GUI) that enables plan navigation, pairwise comparisons, dose distribution visualisation, and possibility for adjustments - essential for efficient clinical use of BRIGHT. End-user validation of BRIGHT with the dedicated GUI was conducted for cervical cancer brachytherapy by emulating clinical practice in ten previously treated patients. A multidisciplinary brachytherapy team used BRIGHT to create new treatment plans. GUI usability was assessed using the System Usability Scale (SUS). BRIGHT plan quality was compared to clinical practice via blinded one-on-one comparisons. The GUI offered helpful features for plan navigation and evaluation, giving users quick insight into whether planning aims are achievable and what treatment options are available. The overall SUS score was 83.3, indicating an 'excellent' system. BRIGHT outperformed clinical practice in five out of ten patients regarding the coverage-sparing trade-off and performed equally well in the remaining five. The BRIGHT plan was preferred over the clinical plan in eight out of ten patients, four of which showed clinically relevant differences. The clinical plan was preferred in two patients, neither with clinically relevant differences. In conclusion, BRIGHT, with its dedicated GUI, is a clinically viable and user-friendly tool for treatment planning in cervical cancer brachytherapy.",
        "authors": [
          "Leah R. M. Dickhoff",
          "Ellen M. Kerkhof",
          "Heloisa H. Deuzeman",
          "Laura A. Velema",
          "Stephanie M. de Boer",
          "Lavinia A. L. Verhagen",
          "Danique L. J. Barten",
          "Bradley R. Pieters",
          "Lukas J. A. Stalpers",
          "Renzo J. Scholman",
          "Pedro M. Matos",
          "Anton Bouter",
          "Carien L. Creutzberg",
          "Peter A. N. Bosman",
          "Tanja Alderliesten"
        ],
        "published": "2026-02-18T10:01:21Z",
        "updated": "2026-02-18T10:01:21Z",
        "categories": [
          "cs.NE"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.16321v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22942v1",
        "title": "ClawMobile: Rethinking Smartphone-Native Agentic Systems",
        "summary": "Smartphones represent a uniquely challenging environment for agentic systems. Unlike cloud or desktop settings, mobile devices combine constrained execution contexts, fragmented control interfaces, and rapidly changing application states. As large language models (LLMs) evolve from conversational assistants to action-oriented agents, achieving reliable smartphone-native autonomy requires rethinking how reasoning and control are composed. We introduce ClawMobile as a concrete exploration of this design space. ClawMobile adopts a hierarchical architecture that separates high-level language reasoning from structured, deterministic control pathways, improving execution stability and reproducibility on real devices. Using ClawMobile as a case study, we distill the design principles for mobile LLM runtimes and identify key challenges in efficiency, adaptability, and stability. We argue that building robust smartphone-native agentic systems demands principled coordination between probabilistic planning and deterministic system interfaces. The implementation is open-sourced~\\footnote{https://github.com/ClawMobile/ClawMobile} to facilitate future exploration.",
        "authors": [
          "Hongchao Du",
          "Shangyu Wu",
          "Qiao Li",
          "Riwei Pan",
          "Jinheng Li",
          "Youcheng Sun",
          "Chun Jason Xue"
        ],
        "published": "2026-02-26T12:34:57Z",
        "updated": "2026-02-26T12:34:57Z",
        "categories": [
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22942v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22915v1",
        "title": "Robust Information Design for Multi-Agent Systems with Complementarities: Smallest-Equilibrium Threshold Policies",
        "summary": "We study information design in multi-agent systems (MAS) with binary actions and strategic complementarities, where an external designer influences behavior only through signals. Agents play the smallest-equilibrium of the induced Bayesian game, reflecting conservative, coordination-averse behavior typical in distributed systems. We show that when utilities admit a convex potential and welfare is convex, the robustly implementable optimum has a remarkably simple form: perfect coordination at each state: either everyone acts or no one does. We provide a constructive threshold rule: compute a one-dimensional score for each state, sort states, and pick a single threshold (with a knife-edge lottery for at most one state). This rule is an explicit optimal vertex of a linear program (LP) characterized by feasibility and sequential obedience constraints. Empirically, in both vaccination and technology-adoption domains, our constructive policy matches LP optima, scales as $O(|Θ|\\log|Θ|)$, and avoids the inflated welfare predicted by obedience-only designs that assume the designer can dictate the (best) equilibrium. The result is a general, scalable recipe for robust coordination in MAS with complementarities.",
        "authors": [
          "Farzaneh Farhadi",
          "Maria Chli"
        ],
        "published": "2026-02-26T12:03:16Z",
        "updated": "2026-02-26T12:03:16Z",
        "categories": [
          "cs.GT",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22915v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22365v1",
        "title": "Sustainable Multi-Agent Crowdsourcing via Physics-Informed Bandits",
        "summary": "Crowdsourcing platforms face a four-way tension between allocation quality, workforce sustainability, operational feasibility, and strategic contractor behaviour--a dilemma we formalise as the Cold-Start, Burnout, Utilisation, and Strategic Agency Dilemma. Existing methods resolve at most two of these tensions simultaneously: greedy heuristics and multi-criteria decision making (MCDM) methods achieve Day-1 quality but cause catastrophic burnout, while bandit algorithms eliminate burnout only through operationally infeasible 100% workforce utilisation.To address this, we introduce FORGE, a physics-grounded $K+1$ multi-agent simulator in which each contractor is a rational agent that declares its own load-acceptance threshold based on its fatigue state, converting the standard passive Restless Multi-Armed Bandit (RMAB) into a genuine Stackelberg game. Operating within FORGE, we propose a Neural-Linear UCB allocator that fuses a Two-Tower embedding network with a Physics-Informed Covariance Prior derived from offline simulator interactions. The prior simultaneously warm-starts skill-cluster geometry and UCB exploration landscape, providing a geometry-aware belief state from episode 1 that measurably reduces cold-start regret.Over $T = 200$ cold-start episodes, the proposed method achieves the highest reward of all non-oracle methods ($\\text{LRew} = 0.555 \\pm 0.041$) at only 7.6% workforce utilisation--a combination no conventional baseline achieves--while maintaining robustness to workforce turnover up to 50% and observation noise up to $σ= 0.20$.",
        "authors": [
          "Chayan Banerjee"
        ],
        "published": "2026-02-25T19:52:00Z",
        "updated": "2026-02-25T19:52:00Z",
        "categories": [
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22365v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22041v1",
        "title": "Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions",
        "summary": "Heralding the advent of autonomous vehicles and mobile robots that interact with humans, responsibility in spatial interaction is burgeoning as a research topic. Even though metrics of responsibility tailored to spatial interactions have been proposed, they are mostly focused on the responsibility of individual agents. Metrics of causal responsibility focusing on individuals fail in cases of causal overdeterminism -- when many actors simultaneously cause an outcome. To fill the gaps in causal responsibility left by individual-focused metrics, we formulate a metric for the causal responsibility of groups. To identify assertive agents that are causally responsible for the trajectory of an affected agent, we further formalise the types of assertive influences and propose a tiering algorithm for systematically identifying assertive agents. Finally, we use scenario-based simulations to illustrate the benefits of considering groups and how the emergence of group effects vary with interaction dynamics and the proximity of agents.",
        "authors": [
          "Vassil Guenov",
          "Ashwin George",
          "Arkady Zgonnikov",
          "David A. Abbink",
          "Luciano Cavalcante Siebert"
        ],
        "published": "2026-02-25T15:48:52Z",
        "updated": "2026-02-25T15:48:52Z",
        "categories": [
          "cs.MA",
          "cs.CY"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22041v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.21477v1",
        "title": "Pancake: Hierarchical Memory System for Multi-Agent LLM Serving",
        "summary": "In this work, we identify and address the core challenges of agentic memory management in LLM serving, where large-scale storage, frequent updates, and multiple coexisting agents jointly introduce complex and high-cost approximate nearest neighbor (ANN) searching problems. We present Pancake, a multi-tier agentic memory system that unifies three key techniques: (i) multi-level index caching for single agents, (ii) coordinated index management across multiple agents, and (iii) collaborative GPU-CPU acceleration. Pancake exposes easy-to-use interface that can be integrated into memory-based agents like Mem-GPT, and is compatible with agentic frameworks such as LangChain and LlamaIndex. Experiments on realistic agent workloads show that Pancake substantially outperforms existing frameworks, achieving more than 4.29x end-to-end throughput improvement.",
        "authors": [
          "Zhengding Hu",
          "Zaifeng Pan",
          "Prabhleen Kaur",
          "Vibha Murthy",
          "Zhongkai Yu",
          "Yue Guan",
          "Zhen Wang",
          "Steven Swanson",
          "Yufei Ding"
        ],
        "published": "2026-02-25T01:09:04Z",
        "updated": "2026-02-25T01:09:04Z",
        "categories": [
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21477v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.21404v1",
        "title": "From Cooperation to Hierarchy: A Study of Dynamics of Hierarchy Emergence in a Multi-Agent System",
        "summary": "A central premise in evolutionary biology is that individual variation can generate information asymmetries that facilitate the emergence of hierarchical organisation. To examine this process, we develop an agent-based model (ABM) to identify the minimal conditions under which hierarchy arises in dynamic multi-agent systems, focusing on the roles of initial heterogeneity and mutation amplitude across generations. Hierarchical organisation is quantified using the Trophic Incoherence (TI) metric, which captures directional asymmetries in interaction networks. Our results show that even small individual differences can be amplified through repeated local interactions involving reproduction, competition, and cooperation, but that hierarchical order is markedly more sensitive to mutation amplitude than to initial heterogeneity. Across repeated trials, stable hierarchies reliably emerge only when mutation amplitude is sufficiently high, while initial heterogeneity primarily affects early formation rather than long-term persistence. Overall, these findings demonstrate how simple interaction rules can give rise to both the emergence and persistence of hierarchical organisation, providing a quantitative account of how structured inequality can develop from initially homogeneous populations.",
        "authors": [
          "Shanshan Mao",
          "Peter Tino"
        ],
        "published": "2026-02-24T22:17:19Z",
        "updated": "2026-02-24T22:17:19Z",
        "categories": [
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21404v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.21041v1",
        "title": "Stability Under Valuation Updates in Coalition Formation",
        "summary": "Coalition formation studies how to partition a set of agents into disjoint coalitions under consideration of their preferences. We study the classical objective of stability in a variant of additively separable hedonic games where agents can change their valuations. Our objective is to find a stable partition after each change. To minimize the reconfiguration cost, we search for nearby stable coalition structures. Our focus is on stability concepts based on single-agent deviations. We present a detailed picture of the complexity of finding nearby stable coalition structures in additively separable hedonic games, for both symmetric and non-symmetric valuations. Our results show that the problem is NP-complete for Nash stability, individual stability, contractual Nash stability, and contractual individual stability. We complement these results by presenting polynomial-time algorithms for contractual Nash stability and contractual individual stability under restricted symmetric valuations. Finally, we show that these algorithms guarantee a bounded average distance over long sequences of updates.",
        "authors": [
          "Fabian Frank",
          "Matija Novaković",
          "René Romen"
        ],
        "published": "2026-02-24T16:02:36Z",
        "updated": "2026-02-24T16:02:36Z",
        "categories": [
          "cs.GT",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.21041v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.20603v1",
        "title": "The Tragedy of the Commons in Multi-Population Resource Games",
        "summary": "Self-optimizing behaviors can lead to outcomes where collective benefits are ultimately destroyed, a well-known phenomenon known as the ``tragedy of the commons\". These scenarios are widely studied using game-theoretic approaches to analyze strategic agent decision-making. In this paper, we examine this phenomenon in a bi-level decision-making hierarchy, where low-level agents belong to multiple distinct populations, and high-level agents make decisions that impact the choices of the local populations they represent. We study strategic interactions in a context where the populations benefit from a common environmental resource that degrades with higher extractive efforts made by high-level agents. We characterize a unique symmetric Nash equilibrium in the high-level game, and investigate its consequences on the common resource. While the equilibrium resource level degrades as the number of populations grows large, there are instances where it does not become depleted. We identify such regions, as well as the regions where the resource does deplete.",
        "authors": [
          "Yamin Vahmian",
          "Keith Paarporn"
        ],
        "published": "2026-02-24T06:53:04Z",
        "updated": "2026-02-24T06:53:04Z",
        "categories": [
          "cs.GT",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20603v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.20493v1",
        "title": "AWCP: A Workspace Delegation Protocol for Deep-Engagement Collaboration across Remote Agents",
        "summary": "The rapid evolution of Large Language Model (LLM)-based autonomous agents is reshaping the digital landscape toward an emerging Agentic Web, where increasingly specialized agents must collaborate to accomplish complex tasks. However, existing collaboration paradigms are constrained to message passing, leaving execution environments as isolated silos. This creates a context gap: agents cannot directly manipulate files or invoke tools in a peer's environment, and must instead resort to costly, error-prone environment reconstruction. We introduce the Agent Workspace Collaboration Protocol (AWCP), which bridges this gap through temporary workspace delegation inspired by the Unix philosophy that everything is a file. AWCP decouples a lightweight control plane from pluggable transport mechanisms, allowing a Delegator to project its workspace to a remote Executor, who then operates on the shared files directly with unmodified local toolchains. We provide a fully open-source reference implementation with MCP tool integration and validate the protocol through live demonstrations of asymmetric collaboration, where agents with complementary capabilities cooperate through delegated workspaces. By establishing the missing workspace layer in the agentic protocol stack, AWCP paves the way for a universally interoperable agent ecosystem in which collaboration transcends message boundaries. The protocol and reference implementation are publicly available at https://github.com/SII-Holos/awcp.",
        "authors": [
          "Xiaohang Nie",
          "Zihan Guo",
          "Youliang Chen",
          "Yuanjian Zhou",
          "Weinan Zhang"
        ],
        "published": "2026-02-24T02:49:08Z",
        "updated": "2026-02-24T02:49:08Z",
        "categories": [
          "cs.NI",
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20493v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.20229v1",
        "title": "HieraMAS: Optimizing Intra-Node LLM Mixtures and Inter-Node Topology for Multi-Agent Systems",
        "summary": "Multi-agent systems (MAS) built on large language models (LLMs) have shown strong performance across many tasks. Most existing approaches improve only one aspect at a time, such as the communication topology, role assignment, or LLM routing, while treating each agent as a single, indivisible unit. This misses the opportunity to use mixtures of LLMs within an agent to strengthen role-specific abilities. We propose HieraMAS, a hierarchical collaboration framework that combines intra-node LLM mixtures with an inter-node communication topology. HieraMAS introduces supernodes, where each functional role is implemented by multiple heterogeneous LLMs using a propose-synthesis structure. Optimizing HieraMAS creates unique credit-assignment challenges: final task performance depends heavily on the underlying LLMs' capabilities, which can lead reinforcement methods to incorrectly reward suboptimal configurations. To address this, we use a two-stage algorithm: (1) multi-level reward attribution, which provides fine-grained feedback at both the node level and the overall system level; (2) graph classification for topology selection, which treats choosing the communication structure as a holistic decision rather than optimizing edges one by one. Experiments on reasoning and coding benchmarks show that HieraMAS substantially outperforms existing methods while also delivering better cost-performance trade-offs.",
        "authors": [
          "Tianjun Yao",
          "Zhaoyi Li",
          "Zhiqiang Shen"
        ],
        "published": "2026-02-23T18:36:04Z",
        "updated": "2026-02-23T18:36:04Z",
        "categories": [
          "cs.MA"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.20229v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22965v1",
        "title": "A note on the area under the likelihood and the fake evidence for model selection",
        "summary": "Improper priors are not allowed for the computation of the Bayesian evidence $Z=p({\\bf y})$ (a.k.a., marginal likelihood), since in this case $Z$ is not completely specified due to an arbitrary constant involved in the computation. However, in this work, we remark that they can be employed in a specific type of model selection problem: when we have several (possibly infinite) models belonging to the same parametric family (i.e., for tuning parameters of a parametric model). However, the quantities involved in this type of selection cannot be considered as Bayesian evidences: we suggest to use the name ``fake evidences'' (or ``areas under the likelihood'' in the case of uniform improper priors). We also show that, in this model selection scenario, using a diffuse prior and increasing its scale parameter asymptotically to infinity, we cannot recover the value of the area under the likelihood, obtained with a uniform improper prior. We first discuss it from a general point of view. Then we provide, as an applicative example, all the details for Bayesian regression models with nonlinear bases, considering two cases: the use of a uniform improper prior and the use of a Gaussian prior, respectively. A numerical experiment is also provided confirming and checking all the previous statements.",
        "authors": [
          "L. Martino",
          "F. Llorente"
        ],
        "published": "2026-02-26T13:01:50Z",
        "updated": "2026-02-26T13:01:50Z",
        "categories": [
          "stat.ME",
          "cs.CE",
          "eess.SP",
          "stat.CO",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22965v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22954v1",
        "title": "Effective sample size approximations as entropy measures",
        "summary": "In this work, we analyze alternative effective sample size (ESS) metrics for importance sampling algorithms, and discuss a possible extended range of applications. We show the relationship between the ESS expressions used in the literature and two entropy families, the Rényi and Tsallis entropy. The Rényi entropy is connected to the Huggins-Roy's ESS family introduced in \\cite{Huggins15}. We prove that that all the ESS functions included in the Huggins-Roy's family fulfill all the desirable theoretical conditions. We analyzed and remark the connections with several other fields, such as the Hill numbers introduced in ecology, the Gini inequality coefficient employed in economics, and the Gini impurity index used mainly in machine learning, to name a few. Finally, by numerical simulations, we study the performance of different ESS expressions contained in the previous ESS families in terms of approximation of the theoretical ESS definition, and show the application of ESS formulas in a variable selection problem.",
        "authors": [
          "L. Martino",
          "V. Elvira"
        ],
        "published": "2026-02-26T12:48:33Z",
        "updated": "2026-02-26T12:48:33Z",
        "categories": [
          "math.ST",
          "cs.CE",
          "eess.SP",
          "stat.CO",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22954v1.pdf",
        "category": "other"
      },
      {
        "id": "2602.22369v1",
        "title": "Sampling from Constrained Gibbs Measures: with Applications to High-Dimensional Bayesian Inference",
        "summary": "This paper considers a non-standard problem of generating samples from a low-temperature Gibbs distribution with \\emph{constrained} support, when some of the coordinates of the mode lie on the boundary. These coordinates are referred to as the non-regular part of the model. We show that in a ``pre-asymptotic'' regime in which the limiting Laplace approximation is not yet valid, the low-temperature Gibbs distribution concentrates on a neighborhood of its mode. Within this region, the distribution is a bounded perturbation of a product measure: a strongly log-concave distribution in the regular part and a one-dimensional exponential-type distribution in each coordinate of the non-regular part. Leveraging this structure, we provide a non-asymptotic sampling guarantee by analyzing the spectral gap of Langevin dynamics. Key examples of low-temperature Gibbs distributions include Bayesian posteriors, and we demonstrate our results on three canonical examples: a high-dimensional logistic regression model, a Poisson linear model, and a Gaussian mixture model.",
        "authors": [
          "Ruixiao Wang",
          "Xiaohong Chen",
          "Sinho Chewi"
        ],
        "published": "2026-02-25T20:06:07Z",
        "updated": "2026-02-25T20:06:07Z",
        "categories": [
          "math.ST",
          "math.PR",
          "stat.ML"
        ],
        "pdfUrl": "http://arxiv.org/pdf/2602.22369v1.pdf",
        "category": "other"
      }
    ]
  }
}