# Toward Manifest Relationality in Transformers via Symmetry Reduction

> **arXiv ID:** 2602.18948
> **åˆ†ç±»:** cs.LG, cs.NE, hep-th, stat.ML
> **å‘å¸ƒæ—¶é—´:** 2026-02-21

## ğŸ“„ è®ºæ–‡ä¿¡æ¯

- **ä½œè€…:** J. FranÃ§ois, L. Ravera
- **PDF:** [ä¸‹è½½](https://arxiv.org/pdf/2602.18948)
- **arXiv é“¾æ¥:** [æŸ¥çœ‹](https://arxiv.org/abs/2602.18948)

## ğŸ“ æ‘˜è¦

Transformer models contain substantial internal redundancy arising from coordinate-dependent representations and continuous symmetries, in model space and in head space, respectively. While recent approaches address this by explicitly breaking symmetry, we propose a complementary framework based on symmetry reduction. We reformulate representations, attention mechanisms, and optimization dynamics in terms of invariant relational quantities, eliminating redundant degrees of freedom by construction. This perspective yields architectures that operate directly on relational structures, providing a principled geometric framework for reducing parameter redundancy and analyzing optimization.

## ğŸ·ï¸ æ ‡ç­¾

`æœºå™¨å­¦ä¹ ` `ç†è®º` `ä¼˜åŒ–`

---

**æ³¨æ„ï¼š** æœ¬æ€»ç»“åŸºäº arXiv åŸå§‹æ‘˜è¦ã€‚AI æ·±åº¦è§£è¯»æ­£åœ¨ç”Ÿæˆä¸­...

