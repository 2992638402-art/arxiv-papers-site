# Bayesian Preference Elicitation: Human-In-The-Loop Optimization of An Active Prosthesis

> **arXiv ID:** 2602.22922
> **åˆ†ç±»:** cs.RO
> **å‘å¸ƒæ—¶é—´:** 2026-02-26

## ğŸ“„ è®ºæ–‡ä¿¡æ¯

- **ä½œè€…:** Sophia Taddei, Wouter Koppen, Eligia Alfio, Stefano Nuzzo, Louis Flynn, Maria Alejandra Diaz, Sebastian Rojas Gonzalez, Tom Dhaene, Kevin De Pauw, Ivo Couckuyt, Tom Verstraten
- **PDF:** [ä¸‹è½½](https://arxiv.org/pdf/2602.22922)
- **arXiv é“¾æ¥:** [æŸ¥çœ‹](https://arxiv.org/abs/2602.22922)

## ğŸ“ æ‘˜è¦

Tuning active prostheses for people with amputation is time-consuming and relies on metrics that may not fully reflect user needs. We introduce a human-in-the-loop optimization (HILO) approach that leverages direct user preferences to personalize a standard four-parameter prosthesis controller efficiently. Our method employs preference-based Multiobjective Bayesian Optimization that uses a state-or-the-art acquisition function especially designed for preference learning, and includes two algorithmic variants: a discrete version (\textit{EUBO-LineCoSpar}), and a continuous version (\textit{BPE4Prost}). Simulation results on benchmark functions and real-application trials demonstrate efficient convergence, robust preference elicitation, and measurable biomechanical improvements, illustrating the potential of preference-driven tuning for user-centered prosthesis control.

## ğŸ·ï¸ æ ‡ç­¾

`æœºå™¨äºº` `æ§åˆ¶` `å…·èº«æ™ºèƒ½`

---

**æ³¨æ„ï¼š** æœ¬æ€»ç»“åŸºäº arXiv åŸå§‹æ‘˜è¦ã€‚AI æ·±åº¦è§£è¯»æ­£åœ¨ç”Ÿæˆä¸­...

