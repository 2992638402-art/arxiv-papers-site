<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Hierarchical Lead Critic based Multi-Agent Reinforcement Learning - arXiv 2602.21680 è®ºæ–‡æ€»ç»“">
    <title>Hierarchical Lead Critic based Multi-Agent Reinforcement Learning | arXiv AI è®ºæ–‡æ¯æ—¥ç²¾é€‰</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header>
        <div class="header-content">
            <h1>ğŸ“š arXiv AI è®ºæ–‡æ¯æ—¥ç²¾é€‰</h1>
            <p class="subtitle">ç²¾é€‰ AI/ML å‰æ²¿è®ºæ–‡ï¼Œæ·±åº¦è§£è¯»ï¼ŒåŠ©ä½ æŠŠæ¡ç ”ç©¶åŠ¨æ€</p>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="../index.html">ğŸ  é¦–é¡µ</a></li>
            <li><a href="../daily/2026-02-28.html">ğŸ“… æ¯æ—¥æ€»ç»“</a></li>
            <li><a href="#categories">ğŸ·ï¸ åˆ†ç±»æµè§ˆ</a></li>
            <li><a href="https://github.com" target="_blank">ğŸ’» GitHub</a></li>
        </ul>
    </nav>

    <main>
        <div class="paper-content">
            <h1>Hierarchical Lead Critic based Multi-Agent Reinforcement Learning</h1>
<blockquote>
<p><strong>arXiv ID:</strong> 2602.21680<br><strong>åˆ†ç±»:</strong> cs.LG, cs.MA<br><strong>å‘å¸ƒæ—¶é—´:</strong> 2026-02-25</p>
</blockquote>
<h2>ğŸ“„ è®ºæ–‡ä¿¡æ¯</h2>
<ul>
<li><strong>ä½œè€…:</strong> David Eckel, Henri MeeÃŸ</li>
<li><strong>PDF:</strong> <a href="https://arxiv.org/pdf/2602.21680">ä¸‹è½½</a></li>
<li><strong>arXiv é“¾æ¥:</strong> <a href="https://arxiv.org/abs/2602.21680">æŸ¥çœ‹</a></li>
</ul>
<h2>ğŸ“ æ‘˜è¦</h2>
<p>Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty.</p>
<h2>ğŸ·ï¸ æ ‡ç­¾</h2>
<p><code>æœºå™¨å­¦ä¹ </code> <code>ç†è®º</code> <code>ä¼˜åŒ–</code></p>
<hr>
<p><strong>æ³¨æ„ï¼š</strong> æœ¬æ€»ç»“åŸºäº arXiv åŸå§‹æ‘˜è¦ã€‚AI æ·±åº¦è§£è¯»æ­£åœ¨ç”Ÿæˆä¸­...</p>

        </div>

        <div style="margin-top: 2rem; text-align: center;">
            <a href="../index.html" class="btn btn-secondary">â† è¿”å›é¦–é¡µ</a>
            <a href="https://arxiv.org/abs/2602.21680" class="btn" target="_blank">ğŸ“„ æŸ¥çœ‹ arXiv åŸæ–‡</a>
        </div>
    </main>

    <footer>
        <p>Â© 2026 arXiv AI è®ºæ–‡æ¯æ—¥ç²¾é€‰ | æ•°æ®æ¥æºï¼š<a href="https://arxiv.org" target="_blank">arXiv.org</a></p>
    </footer>

    <script src="../js/main.js"></script>
</body>
</html>